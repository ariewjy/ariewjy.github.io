{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: ' Malaysia Property Pricing - Webscraping & Machine Learning Model'\n",
        "description: |\n",
        "  Web-scraping property ads listing in Kuala Lumpur, Malaysia, and built a machine learning model to predict the rent price.\n",
        "title-block-banner: true\n",
        "date: '2023-02-10'\n",
        "categories:\n",
        "  - project\n",
        "  - data-science\n",
        "  - python\n",
        "  - webscraping\n",
        "code-fold: true\n",
        "draft: false\n",
        "citation-location: document\n",
        "bibliography: references.bib\n",
        "---"
      ],
      "id": "7ffb652c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Machine Learning Project\n",
        "\n",
        "Pacmann Batch 8 Capstone by Aditya Arie Wijaya (aditya-66kK)\n",
        "\n",
        "### Introduction\n",
        "\n",
        "This is a machine learning project to predict unit/property monthly rent price in Kuala Lumpur region, Malaysia. The project uses a dataset from an online ads listing for property [mudah.my](https://www.mudah.my/). This project outlines the process of web-scraping/ data gathering, data cleaning-wrangling, and machine learning modeling.\n",
        "\n",
        "This project aims to answers question about how much a unit monthly rent would be if given information such as location, number of bedrooms, parking, furnished, etc? This would help potential tenant and also the owner to get the best price of their rental unit, comparable to the market value.\n",
        "\n",
        "Some previous work about house pricing was listed below, however most of them are targeting a dataset of house pricing or an Airbnb pricing. There are difference such as in Airbnb, the booking rarely took more than 2 weeks, let alone a year. Therefore the pricing may be different. Additionally, in Airbnb, there is text feature coming from the review given by the tenant and the owner.The better the review, the higher the rent prices -- which was not available in this current project dataset.\n",
        "\n",
        "Previous work by [@madhuri2019], [@xu2022], [@zhao2022] highlight the importance feature selection, and the choice of machine learning model. Based on the previous works, the most consistently performed machine learning model are Random Forest and Gradient boosting, and the MAE and R2 score usually used in evaluating the performance of the model. Although the above work are all not about apartment rent pricing, similar method can be applied to this project.\n",
        "\n",
        "### Data Gathering\n",
        "\n",
        "The data will use a scraped data from the website mentioned before, focusing on property-to-rent surrounding Kuala Lumpur, Malaysia. ![Website](mudah_my.png)\n"
      ],
      "id": "b5274b15"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('max_colwidth', 200)\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "import datetime\n",
        "import smtplib\n",
        "import json\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import time    # to be used in loop iterations\n",
        "\n",
        "!jupyter nbextension enable --py widgetsnbextension #enabling progress bar"
      ],
      "id": "45289441",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Web-Scraping Process\n",
        "\n",
        "The process started out by gathering data from the website. We are using python library for web-scraping: BeautifulSoup as depicted below. \n",
        "The first process is generating a list of webpage address for a given page number.\n"
      ],
      "id": "a8688506"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#generate list address of n_page\n",
        "def page_number(start, end):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to generate a list of webpage address for a given page number\n",
        "\n",
        "    Parameters:\n",
        "        start (int) : starting page number\n",
        "        end (int)   : ending page number\n",
        "    Returns:\n",
        "        a list of listing web address \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    page_url = 'https://www.mudah.my/kuala-lumpur/apartment-condominium-for-rent?o='\n",
        "    list_page = []\n",
        "    for i in range(start,end+1):\n",
        "        list_page.append(page_url+str(i))\n",
        "    return list_page\n",
        "page_number(2,4)"
      ],
      "id": "87b21b5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then generate a list of ads listing on a single page.\n"
      ],
      "id": "e5417024"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#setting up list of page from \n",
        "def get_list_html(page_url):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to get every listing ads in a given url (page_url)\n",
        "\n",
        "    Parameters:\n",
        "        page_url (str): website url\n",
        "        \n",
        "    Returns:\n",
        "        a list of listing ads\n",
        "    \n",
        "    \"\"\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"}\n",
        "    page = requests.get(url=page_url, headers=headers)\n",
        "    soup = bs(page.text, \"html.parser\")\n",
        "\n",
        "    script_tag = soup.find('script', type='application/ld+json')\n",
        "    data = json.loads(script_tag.text)\n",
        "    dict_query = data[2]['itemListElement']\n",
        "\n",
        "    n_query = data[2]['numberOfItems']\n",
        "    list_html = []\n",
        "\n",
        "    for i in range(n_query):\n",
        "        link = data[2]['itemListElement'][i]['item']['url']\n",
        "        list_html.append(link)\n",
        "        \n",
        "    return list_html\n",
        "\n",
        "\n",
        "#getting listing property from the 1st-5th in the list\n",
        "get_list_html('https://www.mudah.my/neighbouring-kuala-lumpur/apartment-for-rent?o=2')[0:5]"
      ],
      "id": "2380aa4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combining the previous two functions, generate a list of url for all pages.\n"
      ],
      "id": "704ed255"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#generate listing property from each page of n_page\n",
        "def get_list_url(n_page):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to get every listing ads in every page (n_page)\n",
        "\n",
        "    Parameters:\n",
        "        n_page (int): number of page\n",
        "        \n",
        "    Returns:\n",
        "        a list of listing ads\n",
        "    \n",
        "    \"\"\"\n",
        "    list_html=[]\n",
        "    for i in tqdm(range(n_page)):\n",
        "        list_html.extend(get_list_html(page_number(1, n_page)[i]))\n",
        "    return list_html\n",
        "\n",
        "get_list_url(2)[:10]"
      ],
      "id": "2aade249",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then extract the attributes inside the listing ads in a form of nested dictionary.\n"
      ],
      "id": "37ca09cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#extract data from url\n",
        "def get_list_dict(n_page):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to get dataset (atribut of units) in a form of dictionary. \n",
        "\n",
        "    Parameters:\n",
        "        n_page (int): number of page\n",
        "        \n",
        "    Returns:\n",
        "        a dictionaries of attributes inside a list\n",
        "    \n",
        "    \"\"\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"}\n",
        "    list_html = get_list_url(n_page)\n",
        "    list_dict = []\n",
        "    for url in tqdm(list_html):\n",
        "        try:\n",
        "            page = requests.get(url=url, headers=headers)\n",
        "            soup1 = bs(page.text, \"html.parser\")\n",
        "            soup2 = bs(soup1.prettify(), 'html.parser')\n",
        "\n",
        "            id_html = re.search(r'(\\d+).htm', url).group(1)\n",
        "            title = soup2.find(itemprop='name').text.strip()\n",
        "\n",
        "            script_tag = soup2.find(\"script\", id=\"__NEXT_DATA__\")\n",
        "            script_content = script_tag.text\n",
        "            data = json.loads(script_content)\n",
        "            props = data.get(\"props\", {})\n",
        "            id_listing = re.search(r'-(\\d+)\\.htm', url).group(1)\n",
        "\n",
        "            dict_id = [{'realValue': '', 'id': 'ads_id', 'value': id_listing, 'label': 'id ads'}]\n",
        "            dict_building = props[\"initialState\"][\"adDetails\"][\"byID\"][id_listing][\"attributes\"]['propertyParams'][2]['params']\n",
        "            dict_prop = props[\"initialState\"][\"adDetails\"][\"byID\"][id_listing][\"attributes\"]['categoryParams']\n",
        "            dict_unit = dict_id + dict_building + dict_prop\n",
        "        except:\n",
        "            None\n",
        "        \n",
        "        list_dict.append(dict_unit)\n",
        "        \n",
        "    return list_dict"
      ],
      "id": "8d29aaab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting the values inside the dictionary for each attributes.\n"
      ],
      "id": "693f6622"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#getting values out of dictionary\n",
        "def get_values(list_dict):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to values of the previous dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        list_dict (list): list of dictionary where attributes stored\n",
        "        \n",
        "    Returns:\n",
        "        a list of values (unit/property) attributes\n",
        "    \n",
        "    \"\"\"\n",
        "    keys = [\n",
        "        'ads_id',\n",
        "        'prop_name',\n",
        "        # 'developer_name', \n",
        "        # 'address', \n",
        "        'completion_year', \n",
        "        # 'num_floors', \n",
        "        # 'num_units',\n",
        "        'monthly_rent', \n",
        "        # 'category_id', \n",
        "        'location', \n",
        "        'property_type', \n",
        "        # 'floor_range', \n",
        "        'rooms', \n",
        "        'parking',\n",
        "        'bathroom', \n",
        "        'size', \n",
        "        'furnished',\n",
        "        'facilities', \n",
        "        'additional_facilities', \n",
        "       ]\n",
        "\n",
        "    values = {}\n",
        "    for key in keys:\n",
        "        try:\n",
        "            values[key] = next(item['value'] for item in list_dict if item[\"id\"] == key)\n",
        "        except StopIteration:\n",
        "            values[key] = None\n",
        "    return values"
      ],
      "id": "9a5daf87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#get df from list\n",
        "def get_df_final(n_page):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "        Function to generate dataframe from the list.\n",
        "\n",
        "    Parameters:\n",
        "        n_page (int): number of page\n",
        "        \n",
        "    Returns:\n",
        "        a dataframe of the list of attributes on each listings.\n",
        "    \n",
        "    \"\"\"\n",
        "    list_data = get_list_dict(n_page)\n",
        "    list_new = []\n",
        "    for i in range(0,len(list_data)):\n",
        "            dic = get_values(list_data[i])\n",
        "            list_new.append(dic)\n",
        "    \n",
        "    df = pd.DataFrame(list_new)\n",
        "    return df"
      ],
      "id": "e4a7937b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract dataset from 250 pages. File is then saved into a csv, to be reloaded again.\n"
      ],
      "id": "fc614ca3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# df_=get_df_final(250)\n",
        "# df_.to_csv('mudah-apartment-raw.csv', index=False)\n",
        "## already run, and file is saved"
      ],
      "id": "2d9ee932",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "### Data Understanding\n",
        "\n",
        "Reload the original dataset. \n"
      ],
      "id": "f618e33b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: show\n",
        "\n",
        "#read it back\n",
        "df = pd.read_csv('./mudah-apartment-raw.csv')\n",
        "df.head(3).T"
      ],
      "id": "23e0dde2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Description\n"
      ],
      "id": "634c206e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: show\n",
        "\n",
        "df.info()"
      ],
      "id": "12ed7685",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following feature is available in the dataset:\n",
        "\n",
        "-   `ads_id`: ads listing ID, unique to each ads\n",
        "-   `prop_name`: the building name of the property\n",
        "-   `completion_year`: year of the building/property completed\n",
        "-   `monthly_rent`: monthly rent price in Malaysian Ringgit (RM)\n",
        "-   `location`: the location (region) of the property\n",
        "-   `property_type`: property type, such as flat, apartment, etc\n",
        "-   `rooms`: number of rooms\n",
        "-   `parking`: number of parking spot\n",
        "-   `bathroom`: number of bathroom\n",
        "-   `size`: total area of the unit in sq.ft\n",
        "-   `furnished`: furnishin status of the unit, fully-partial-non\n",
        "-   `facilities`: main facilities within the unit\n",
        "-   `additional_facilities`: additional facilities\n",
        "\n",
        "#### Drop Duplicate\n"
      ],
      "id": "6275e53b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#cek duplikat\n",
        "df.duplicated().sum()\n",
        "\n",
        "#drop duplikat\n",
        "df1 = df.drop_duplicates()"
      ],
      "id": "98c7aeb1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saving the file to csv after remove duplicated values.\n"
      ],
      "id": "43bfb6e6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# #saving to csv\n",
        "# df1.to_csv(\"mudah-apartment-clean.csv\", index=False)\n",
        "# #saved already"
      ],
      "id": "dbbee4c6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reload the data after drop duplicates\n"
      ],
      "id": "7f07420c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#reload the data\n",
        "df = pd.read_csv(\"./mudah-apartment-clean.csv\")"
      ],
      "id": "da4bdbb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "df.duplicated().sum()"
      ],
      "id": "3813895f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Extracting Number and Keyword\n"
      ],
      "id": "9b000e5d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#removing RM from monthly rent\n",
        "df['monthly_rent'] = df['monthly_rent'].apply(lambda x: int(re.search(r'RM (.*?) per', x).group(1).replace(' ', '')))\n",
        "df = df.rename(columns={'monthly_rent': 'monthly_rent_rm'})\n",
        "\n",
        "#dropping sq.ft from size\n",
        "df['size'] = df['size'].apply(lambda x: int(re.search(r'(.*?) sq', x).group(1).replace(' ', '')))\n",
        "df = df.rename(columns={'size': 'size_sqft'})\n",
        "\n",
        "#dropping kuala lumpur from the location\n",
        "df['location'] = df['location'].apply(lambda x: re.findall(\"\\w+$\", x)[0])\n",
        "df.head(4).T"
      ],
      "id": "22b444af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Extracting Near KTM/LRT\n",
        "\n",
        "Hypotheses: closer access to KTM/LRT = higher monthly rent\n"
      ],
      "id": "142f0e17"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#extracting near KTM/LRT from the additional facilities\n",
        "def extract_near_ktm_lrt(text):\n",
        "    pattern = re.compile(r'\\bNear KTM/LRT\\b')\n",
        "    try:\n",
        "        match = pattern.search(text)\n",
        "        if match:\n",
        "            return 'yes'\n",
        "        return 'no'\n",
        "    except TypeError:\n",
        "        return text"
      ],
      "id": "8c761222",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting \"near KTM/LRT\" into its own column.\n"
      ],
      "id": "01f30179"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df['nearby_railways'] = df.additional_facilities.apply(lambda x: extract_near_ktm_lrt(x))\n",
        "df.head(4).T"
      ],
      "id": "6a6dd5c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the difference between nearby KTM/LRT or not:\n"
      ],
      "id": "c46b27a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-nearbyktm\n",
        "#| fig-cap: Boxplot between Nearby KTM/LRT or Not\n",
        "\n",
        "sns.boxplot(data=df, x='monthly_rent_rm', y='nearby_railways')\n",
        "plt.xlim(0,4000);\n",
        "\n",
        "near_ktmlrt = df.query(\" nearby_railways == 'yes' \")\n",
        "not_near_ktmlrt = df.query(\" nearby_railways == 'no' \")\n",
        "\n",
        "print(f\"\"\" \n",
        "Median:\n",
        "Nearby KTM/LRT: {near_ktmlrt.monthly_rent_rm.median():.0f}RM\n",
        "Not nearby KTM/LRT: {not_near_ktmlrt.monthly_rent_rm.median():.0f}RM\n",
        "      \"\"\")"
      ],
      "id": "fig-nearbyktm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sanity check:\n"
      ],
      "id": "520c845f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df[df['prop_name'] == 'Majestic Maxim'][['nearby_railways']].value_counts()"
      ],
      "id": "5683b0e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen above, @fig-nearbyktm shows that it sligthly increases the median monthly rent by 50RM. However, near KTM/LRT is not appearing in all row even though the property is the same\n",
        "\n",
        "**Conclusion: Near KTM/LRT may be used, but it can be improved as the listing is inconsistent**\n",
        "\n",
        "#### Drop Missing Values in Facilities and Additional Facilities\n"
      ],
      "id": "48e742bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.isna().sum()"
      ],
      "id": "5c6819fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#dropping some columns\n",
        "df = df.drop(columns=[\n",
        "    'ads_id', \n",
        "    'prop_name', \n",
        "    'facilities', \n",
        "    'additional_facilities',\n",
        "    # 'nearby_railways',\n",
        "    # 'completion_year'\n",
        "])\n",
        "df"
      ],
      "id": "82cdc96c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#checking dtypes from all columns\n",
        "df.info()"
      ],
      "id": "33da01eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#converting rooms from object to int64\n",
        "df['rooms'] = pd.to_numeric(df['rooms'], downcast='integer', errors='coerce')\n",
        "df.info()"
      ],
      "id": "da460d39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Outlier Removal\n",
        "\n",
        "To remove some unexplainable data such as 0 monthly rent, 0 size, the rent that is way too old (1970), including the monthly rent that is way too high and/or size too big. \n"
      ],
      "id": "19ba36ae"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-size-rent\n",
        "#| fig-cap: Monthly Rent\n",
        "\n",
        "df[['size_sqft', 'monthly_rent_rm']].plot(kind='scatter', x='size_sqft', y='monthly_rent_rm');\n",
        "plt.ylim(100,5500) #batas harga rent\n",
        "plt.xlim(50,3000)  #batas size\n",
        "plt.show()"
      ],
      "id": "fig-size-rent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Monthly Rent\n"
      ],
      "id": "14b3bee6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-compare-rent\n",
        "#| fig-cap: Comparison between Different Scale\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "axs[0].boxplot(data=df, x='monthly_rent_rm')\n",
        "axs[0].set_ylim(0,20000)\n",
        "axs[0].set_title('all data')\n",
        "\n",
        "axs[1].boxplot(data=df, x='monthly_rent_rm')\n",
        "axs[1].set_ylim(0,5000)\n",
        "axs[1].set_title('croped at 5,000 RM')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-compare-rent",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on EDA on @fig-size-rent and @fig-compare-rent, author decided to filter the data between 100-5500 RM as follows:\n"
      ],
      "id": "efe54c06"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#removing all rows with monthly rent above 5500 RM and below 100RM\n",
        "dfx = df.query(\" monthly_rent_rm > 100 & monthly_rent_rm < 5500 \")\n",
        "dfx.describe()"
      ],
      "id": "5b66f8c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sanity check after removal as shown in @fig-rent-final belo:\n"
      ],
      "id": "a3bceb99"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-rent-final\n",
        "#| fig-cap: Data after Outlier Removal\n",
        "\n",
        "dfx.monthly_rent_rm.plot(kind='box', x='monthly_rent_rm');"
      ],
      "id": "fig-rent-final",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Size\n",
        "\n",
        "Checking the dataset in terms of size."
      ],
      "id": "d7e3b411"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-size-comparison\n",
        "#| fig-cap: Raw Data Size sq.ft\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "axs[0].boxplot(data=dfx, x='size_sqft')\n",
        "axs[0].set_ylim(0,20000)\n",
        "axs[0].set_title('all data')\n",
        "\n",
        "axs[1].boxplot(data=dfx, x='size_sqft')\n",
        "axs[1].set_ylim(0,2000)\n",
        "axs[1].set_title('croped at 0-2,000 square feet')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-size-comparison",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Still based on @fig-size-rent, outliers are removed."
      ],
      "id": "4cbc0800"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#removing outliers below 500, and higher than 3000 sqft and below 50 sqft\n",
        "dfx = \\\n",
        "(dfx.query(\" size_sqft > 50 & size_sqft < 3000 \")\n",
        " # .size_sqft\n",
        " # .plot(kind='box')\n",
        ")\n",
        "dfx"
      ],
      "id": "9c08702b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sanity check:"
      ],
      "id": "d1bea1ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx.size_sqft.plot(kind='box');"
      ],
      "id": "66234965",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: fig-complete-outliers\n",
        "#| fig-cap: Final Data after Outlier Removal\n",
        "\n",
        "fig, axs = plt.subplots(1,5, figsize=(12,4))\n",
        "axs[0].boxplot(data=dfx.dropna(), x='size_sqft')\n",
        "axs[1].boxplot(data=dfx.dropna(), x='rooms')\n",
        "axs[2].boxplot(data=dfx.dropna(), x='parking')\n",
        "axs[3].boxplot(data=dfx.dropna(), x='bathroom')\n",
        "# axs[4].boxplot(data=dfx.dropna(), x='completion_year')\n",
        "\n",
        "axs[0].set_title('Size')\n",
        "axs[1].set_title('Rooms')\n",
        "axs[2].set_title('Parking')\n",
        "axs[3].set_title('Bathrooms')\n",
        "# axs[4].set_title('Completion Year')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "fig-complete-outliers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "#### Input-Output\n"
      ],
      "id": "93724c4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def extractInputOutput(data,\n",
        "                       output_column_name):\n",
        "    \"\"\"\n",
        "    Fungsi untuk memisahkan data input dan output\n",
        "    :param data: <pandas dataframe> data seluruh sample\n",
        "    :param output_column_name: <string> nama kolom output\n",
        "    :return input_data: <pandas dataframe> data input\n",
        "    :return output_data: <pandas series> data output\n",
        "    \"\"\"\n",
        "    output_data = data[output_column_name]\n",
        "    input_data = data.drop(output_column_name,\n",
        "                           axis = 1)\n",
        "    \n",
        "    return input_data, output_data"
      ],
      "id": "72ab1ff9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X, y = extractInputOutput(data=dfx, output_column_name='monthly_rent_rm')"
      ],
      "id": "1ddde0af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X"
      ],
      "id": "b5009cf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y"
      ],
      "id": "55f7c2d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train-Test Split Data\n"
      ],
      "id": "273b0d52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#import libraries\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "c791b8e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 123)"
      ],
      "id": "d4be8fad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "len(X_test)/len(X)"
      ],
      "id": "0a4c3ea1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "X_train"
      ],
      "id": "077a0124",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Preprocessing Original Data for Categorical Dtypes**\n",
        "\n",
        "One must paying attention to the number of categorical observation in the original data, with respect to the sampling train-test value. If, the test_size = 0.3, that means any categorical observation with a total of 3 and less, would not be distributed evenly among train and test data.\n"
      ],
      "id": "bb01df21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(dfx.location.nunique())\n",
        "print(X_train.location.nunique())\n",
        "print(X_test.location.nunique())"
      ],
      "id": "d4029d70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(dfx.property_type.nunique())\n",
        "print(X_train.property_type.nunique())\n",
        "print(X_test.property_type.nunique())"
      ],
      "id": "8a5faba8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(set(X_train.furnished.to_list()) - set(X_test.furnished.to_list()))\n",
        "print(set(X_train.location.to_list()) - set(X_test.location.to_list()))\n",
        "print(set(X_train.property_type.to_list()) - set(X_test.property_type.to_list()))\n",
        "print(set(X_train.nearby_railways.to_list()) - set(X_test.nearby_railways.to_list()))"
      ],
      "id": "6f705267",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Dropping Data\n"
      ],
      "id": "81270621"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx"
      ],
      "id": "00dfbaa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx.location.value_counts()"
      ],
      "id": "94620987",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx.property_type.value_counts()"
      ],
      "id": "61b0b106",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx_new = dfx[\n",
        "    (dfx.location != 'Jinjang') \n",
        "    & (dfx.location != 'Serdang') & \n",
        "    (dfx.location != 'Sentral') & \n",
        "    (dfx.location != 'Others') & \n",
        "    (dfx.location != 'Tunku') & \n",
        "    (dfx.location != 'Penchala') & \n",
        "    (dfx.location != 'Lin') &\n",
        "    # (dfx.property_type != 'Others') &\n",
        "    (dfx.property_type != 'Condo / Services residence / Penthouse / Townhouse') &\n",
        "    (dfx.property_type != 'Townhouse Condo')\n",
        "]"
      ],
      "id": "24db5ea2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dfx_new.property_type.value_counts()"
      ],
      "id": "69af36ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Re-split Training-Test\n"
      ],
      "id": "d7f97b99"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X, y = extractInputOutput(data=dfx_new, output_column_name='monthly_rent_rm')"
      ],
      "id": "353ff270",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#import libraries\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "d8a3f9d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 123)"
      ],
      "id": "641a6224",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "len(X_test)/len(X)"
      ],
      "id": "63d4b96c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train"
      ],
      "id": "db5b81a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(set(X_train.furnished.to_list()) - set(X_test.furnished.to_list()))\n",
        "print(set(X_train.location.to_list()) - set(X_test.location.to_list()))\n",
        "print(set(X_train.property_type.to_list()) - set(X_test.property_type.to_list()))\n",
        "# print(set(X_train.nearby_railways.to_list()) - set(X_test.nearby_railways.to_list()))"
      ],
      "id": "3e215edb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(dfx_new.location.nunique())\n",
        "print(X_train.location.nunique())\n",
        "print(X_test.location.nunique())"
      ],
      "id": "ace7a2bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "X_train"
      ],
      "id": "db385aa0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#export data training\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "y_train.to_csv('y_train.csv', index=False)"
      ],
      "id": "d7cfb323",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#export data testing\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "y_test.to_csv('y_test.csv', index=False)"
      ],
      "id": "3b3dc266",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Data Imputation\n"
      ],
      "id": "19dfd0dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#checking null data\n",
        "X_train.isna().sum()"
      ],
      "id": "8c8a75a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Numerical Data\n"
      ],
      "id": "08cb284d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_num =  X_train.select_dtypes(exclude='object')\n",
        "X_train_num"
      ],
      "id": "6192cf37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_num.isna().sum()"
      ],
      "id": "fa0bc9db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   We can fill completion year, rooms, parking and bathroom with mode\n"
      ],
      "id": "e23391bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def numericalImputation(X_train_num, strategy = 'most_frequent'):\n",
        "    \"\"\"\n",
        "    Fungsi untuk melakukan imputasi data numerik NaN\n",
        "    :param data: <pandas dataframe> sample data input\n",
        "\n",
        "    :return X_train_numerical: <pandas dataframe> data numerik\n",
        "    :return imputer_numerical: numerical imputer method\n",
        "    \"\"\"\n",
        "    #buat imputer\n",
        "    imputer_num = SimpleImputer(missing_values = np.nan, strategy = strategy)\n",
        "    \n",
        "    #fitting\n",
        "    imputer_num.fit(X_train_num)\n",
        "\n",
        "    # transform\n",
        "    imputed_data = imputer_num.transform(X_train_num)\n",
        "    X_train_num_imputed = pd.DataFrame(imputed_data)\n",
        "\n",
        "    #pastikan index dan nama kolom antara imputed dan non-imputed SAMA\n",
        "    X_train_num_imputed.columns = X_train_num.columns\n",
        "    X_train_num_imputed.index = X_train_num.index\n",
        "\n",
        "    return X_train_num_imputed, imputer_num"
      ],
      "id": "6f74d573",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_num, imputer_num = numericalImputation(X_train_num, strategy='most_frequent')\n",
        "X_train_num.isna().sum()"
      ],
      "id": "ab6fd4bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imputer_num"
      ],
      "id": "49ba970e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Categorical Data\n"
      ],
      "id": "105ea28e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cat = X_train.select_dtypes(include='object')\n",
        "X_train_cat"
      ],
      "id": "4f609c1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cat.isna().sum()"
      ],
      "id": "58382149",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Impute with mode\n"
      ],
      "id": "c15eb67d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cat, imputer_num = numericalImputation(X_train_cat, strategy='most_frequent')\n",
        "X_train_cat.isna().sum()"
      ],
      "id": "19834b71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Preprocessing Categorical Variable\n"
      ],
      "id": "93d9359a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cat_ohe =  pd.get_dummies(X_train_cat)\n",
        "X_train_cat_ohe.head(2)"
      ],
      "id": "9f978d5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ohe_columns = X_train_cat_ohe.columns\n",
        "ohe_columns"
      ],
      "id": "15b899b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_cat_ohe.isna().sum()"
      ],
      "id": "5173d371",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_num.isna().sum()"
      ],
      "id": "35ce4344",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Penggabungan Numerical dan Categorical data\n"
      ],
      "id": "3a48eaf7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_concat = pd.concat([X_train_num,\n",
        "                            X_train_cat_ohe],\n",
        "                           axis = 1)"
      ],
      "id": "4002dbf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_concat.head(2)"
      ],
      "id": "9d63b92a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "X_train_concat.isnull().sum()"
      ],
      "id": "ea0ecf28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standarisasi\n"
      ],
      "id": "b8879f5b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Buat fungsi\n",
        "def standardizerData(data):\n",
        "    \"\"\"\n",
        "    Fungsi untuk melakukan standarisasi data\n",
        "    :param data: <pandas dataframe> sampel data\n",
        "    :return standardized_data: <pandas dataframe> sampel data standard\n",
        "    :return standardizer: method untuk standardisasi data\n",
        "    \"\"\"\n",
        "    data_columns = data.columns  # agar nama kolom tidak hilang\n",
        "    data_index = data.index  # agar index tidak hilang\n",
        "\n",
        "    # buat (fit) standardizer\n",
        "    standardizer = StandardScaler()\n",
        "    standardizer.fit(data)\n",
        "\n",
        "    # transform data\n",
        "    standardized_data_raw = standardizer.transform(data)\n",
        "    standardized_data = pd.DataFrame(standardized_data_raw)\n",
        "    standardized_data.columns = data_columns\n",
        "    standardized_data.index = data_index\n",
        "\n",
        "    return standardized_data, standardizer"
      ],
      "id": "ca202604",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_clean, standardizer = standardizerData(data = X_train_concat)"
      ],
      "id": "be5af958",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train_clean.head()"
      ],
      "id": "e54f74e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Machine Learning\n",
        "\n",
        "Since this is a regression model, R2 score and mean absolute error (MAE) will be used as a performance metrics.\n",
        "\n",
        "The machine learning model will use baseline from average value of the target columns (monthly rent) and also result from linear regression model. After that, author used some of the recommended model based on previous works, which are random forest and gradient boosting to better improve the performance of the model.\n",
        "\n",
        "#### Baseline-Average Value\n",
        "\n",
        "The concept here is to use average value of the target as the easiest way to predict the monhtly rent of a unit.\n"
      ],
      "id": "16de8d86"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_baseline = np.ones(len(y_train)) * y_train.mean()\n",
        "y_baseline"
      ],
      "id": "77ee5dc0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Train the linear regression model\n",
        "lin_reg = LinearRegression().fit(X_train_clean, y_train)\n",
        "\n",
        "# Predict using the train data\n",
        "y_pred_train = y_baseline\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_baseline = r2_score(y_train, y_pred_train)\n",
        "\n",
        "#calculate MAE\n",
        "mae_baseline = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_baseline:.4f} and MAE score: {mae_baseline:.4f}\")"
      ],
      "id": "aecca7e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.scatter(x=y_train, y=y_pred_train);"
      ],
      "id": "9834582b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Baseline-Linear Regression\n",
        "\n",
        "The second method is using linear regression, which simply put is finding the minum total error (distance) between predicted value and the target value, using linear equation. \n"
      ],
      "id": "8edd057f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Train the linear regression model\n",
        "lin_reg = LinearRegression().fit(X_train_clean, y_train)\n",
        "\n",
        "# Predict using the train data\n",
        "# y_pred = y_baseline\n",
        "y_pred_train = lin_reg.predict(X_train_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_linreg = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_linreg = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_linreg:.4f} and MAE score: {mae_linreg:.4f}\")"
      ],
      "id": "d757f64d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.jointplot(x=y_train, y=y_pred_train);"
      ],
      "id": "784b281e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GradientBoosting\n",
        "\n",
        "The gradient boosting, is one of the recommendation from previous works, is a model where each sample would be given a different weights (boosts) depending on its performance in predicting the value/ target. \n"
      ],
      "id": "bcdffab8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "# Build random forest\n",
        "grad_tree = GradientBoostingRegressor(random_state = 123)"
      ],
      "id": "c82fba79",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit random forest\n",
        "grad_tree.fit(X_train_clean, y_train)"
      ],
      "id": "5cbacb22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict\n",
        "y_pred_train = grad_tree.predict(X_train_clean)\n",
        "# y_pred_test = grad_tree.predict(X_test_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_gb = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_gb = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_gb:.4f} and MAE score: {mae_gb:.4f}\")"
      ],
      "id": "7c2e014d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.jointplot(x=y_train, y=y_pred_train);"
      ],
      "id": "7cd91db7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#gridsearch\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "\n",
        "\n",
        "params = {'n_estimators': [100, 200, 300, 400, 500],\n",
        "              'learning_rate': [0.1, 0.05, 0.01]}\n",
        "\n",
        "# Buat gridsearch\n",
        "grad_tree = GradientBoostingRegressor(random_state = 123)\n",
        "\n",
        "grad_tree_cv = GridSearchCV(estimator = grad_tree,\n",
        "                           param_grid = params,\n",
        "                           cv = 5,\n",
        "                           scoring = \"neg_mean_absolute_error\")"
      ],
      "id": "b9f32f5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit grid search cv\n",
        "grad_tree_cv.fit(X_train_clean, y_train)"
      ],
      "id": "d10e114b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best params\n",
        "grad_tree_cv.best_params_"
      ],
      "id": "a383727b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Refit the Adaboost\n",
        "grad_tree = GradientBoostingRegressor(n_estimators = grad_tree_cv.best_params_[\"n_estimators\"],\n",
        "                                      random_state = 123)\n",
        "\n",
        "grad_tree.fit(X_train_clean, y_train)"
      ],
      "id": "d796e5e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict\n",
        "y_pred_train = grad_tree.predict(X_train_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_gb_cv = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_gb_cv = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_gb_cv:.4f} and MAE score: {mae_gb_cv:.4f}\")"
      ],
      "id": "2a7410b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.jointplot(x=y_train, y=y_pred_train);"
      ],
      "id": "4064d957",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Random Forest\n",
        "\n",
        "The last model, which was also recommended by previous works, is a model where not only it has weights based on its performance, but the feature selection in which the sample is measured was done at **random**. Therefore, reduces not only the variance, but also the bias. \n"
      ],
      "id": "df8bbe43"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "id": "4fe6b498",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build random forest\n",
        "rf_tree = RandomForestRegressor(n_estimators = 100,\n",
        "                                criterion = \"squared_error\",\n",
        "                                max_features = \"sqrt\",\n",
        "                                random_state = 123)"
      ],
      "id": "9bf81d02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit random forest\n",
        "rf_tree.fit(X_train_clean, y_train)"
      ],
      "id": "d9361bd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict\n",
        "y_pred_train = rf_tree.predict(X_train_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_rf = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# Calculate R-squared\n",
        "r2_rf = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_rf:.4f} and MAE score: {mae_rf:.4f}\")"
      ],
      "id": "5c13eb89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.jointplot(x=y_train, y=y_pred_train);"
      ],
      "id": "af5ed8b4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "params = {\"n_estimators\": [100, 200, 300, 500 ],\n",
        "          \"max_features\": [\"sqrt\", \"log2\"]}\n",
        "\n",
        "# Buat gridsearch\n",
        "rf_tree = RandomForestRegressor(criterion = \"squared_error\",\n",
        "                                random_state = 123)\n",
        "\n",
        "rf_tree_cv = GridSearchCV(estimator = rf_tree,\n",
        "                          param_grid = params,\n",
        "                          cv = 5,\n",
        "                          scoring = \"neg_mean_absolute_error\")"
      ],
      "id": "eb478fe0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fit grid search cv\n",
        "rf_tree_cv.fit(X_train_clean, y_train)"
      ],
      "id": "09dd48d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best params\n",
        "rf_tree_cv.best_params_"
      ],
      "id": "da909a68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Refit the Random Forest\n",
        "rf_tree = RandomForestRegressor(criterion = \"squared_error\",\n",
        "                                max_features = rf_tree_cv.best_params_[\"max_features\"],\n",
        "                                n_estimators = rf_tree_cv.best_params_[\"n_estimators\"],\n",
        "                                random_state = 123)\n",
        "\n",
        "rf_tree.fit(X_train_clean, y_train)"
      ],
      "id": "81f56f0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Predict\n",
        "y_pred_train = rf_tree.predict(X_train_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_rf_cv = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# # Calculate R-squared\n",
        "r2_rf_cv = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_rf_cv:.4f} and MAE score: {mae_rf_cv:.4f}\")"
      ],
      "id": "b7cda8b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sns.jointplot(x=y_train, y=y_pred_train);"
      ],
      "id": "02020777",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mae_score = [mae_baseline, mae_linreg, mae_gb, mae_gb_cv, mae_rf, mae_rf_cv]\n",
        "r2_score = [r2_baseline, r2_linreg, r2_gb, r2_gb_cv, r2_rf, r2_rf_cv]\n",
        "indexes = [\"baseline\", \"linear regression\", \"gradient boosting\", \"gradient boosting with CV\", \"random forest\",  \"random forest with CV\"]\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    \"MAE Train\": mae_score,\n",
        "    \"R2-Score\": r2_score,\n",
        "},index = indexes)\n",
        "\n",
        "summary_df.sort_values(by='R2-Score', ascending=False)"
      ],
      "id": "55068e64",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the above table, it can be seen that Random Forest model performs the best, and Gradient Boosting at the second place. This is similar to the previous work done by others, on house pricing.\n",
        "\n",
        "### Best Model\n"
      ],
      "id": "ca6979e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "#setting up\n",
        "rf_tree = RandomForestRegressor(n_estimators = 500,\n",
        "                                criterion = \"squared_error\",\n",
        "                                max_features = \"sqrt\",\n",
        "                                random_state = 123)\n",
        "\n",
        "#fit model train\n",
        "rf_tree.fit(X_train_clean, y_train)\n",
        "\n",
        "# Predict model train\n",
        "y_pred_train = rf_tree.predict(X_train_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_rf_cv_train = mean_absolute_error(y_train, y_pred_train)\n",
        "\n",
        "# # Calculate R-squared\n",
        "r2_rf_cv_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "print(f\"R2-score: {r2_rf_cv_train:.3f} and MAE score: +/-{mae_rf_cv_train:.2f} RM\")\n",
        "\n",
        "sns.scatterplot(x=y_train, y=y_pred_train )\n",
        "plt.plot([0, 5500], [0,5500], \"--r\")\n",
        "plt.xlim(0, 5500)\n",
        "plt.xlabel(\"Actual Monthly Rent\")\n",
        "plt.ylim(0,5500)\n",
        "plt.ylabel(\"Predicted Monthly Rent\")\n",
        "plt.suptitle(\"Random Forest - Best Regression Model\")\n",
        "plt.show()"
      ],
      "id": "adb9e5c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Prediction\n",
        "\n",
        "### Test Data Preprocessing\n",
        "\n",
        "Simlar process done in train dataset need to be repeated on test dataset.\n"
      ],
      "id": "42591c8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#checking null data\n",
        "X_test.isna().sum()"
      ],
      "id": "6bf1686f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Numerical Data\n"
      ],
      "id": "e481c311"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_num =  X_test.select_dtypes(exclude='object')\n",
        "X_test_num"
      ],
      "id": "2a6da593",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_num.isna().sum()"
      ],
      "id": "9aac421e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_num, imputer_num = numericalImputation(X_test_num, strategy='most_frequent')\n",
        "X_test_num.isna().sum()"
      ],
      "id": "95540007",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Categorical Data\n"
      ],
      "id": "dcf7f440"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_cat = X_test.select_dtypes(include='object')\n",
        "X_test_cat"
      ],
      "id": "588c659e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_cat.isna().sum()"
      ],
      "id": "d1490b39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_cat, imputer_num = numericalImputation(X_test_cat, strategy='most_frequent')\n",
        "X_test_cat.isna().sum()"
      ],
      "id": "95a6986d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Categorical OHE\n"
      ],
      "id": "3cd5f79b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_cat_ohe =  pd.get_dummies(X_test_cat)\n",
        "X_test_cat_ohe.head(2)"
      ],
      "id": "dfb2e908",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ohe_columns = X_test_cat_ohe.columns\n",
        "ohe_columns"
      ],
      "id": "a8bbdcc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Penggabungan Numerical dan Categorical data\n"
      ],
      "id": "3dd584f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_concat = pd.concat([X_test_num,\n",
        "                            X_test_cat_ohe],\n",
        "                           axis = 1)"
      ],
      "id": "65e5bd18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_concat.head(2)"
      ],
      "id": "8f3395a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#sanity check\n",
        "X_test_concat.isnull().sum()"
      ],
      "id": "2c72eaf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Standarisasi\n"
      ],
      "id": "5cc25374"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Buat fungsi\n",
        "def standardizerData(data):\n",
        "    \"\"\"\n",
        "    Fungsi untuk melakukan standarisasi data\n",
        "    :param data: <pandas dataframe> sampel data\n",
        "    :return standardized_data: <pandas dataframe> sampel data standard\n",
        "    :return standardizer: method untuk standardisasi data\n",
        "    \"\"\"\n",
        "    data_columns = data.columns  # agar nama kolom tidak hilang\n",
        "    data_index = data.index  # agar index tidak hilang\n",
        "\n",
        "    # buat (fit) standardizer\n",
        "    standardizer = StandardScaler()\n",
        "    standardizer.fit(data)\n",
        "\n",
        "    # transform data\n",
        "    standardized_data_raw = standardizer.transform(data)\n",
        "    standardized_data = pd.DataFrame(standardized_data_raw)\n",
        "    standardized_data.columns = data_columns\n",
        "    standardized_data.index = data_index\n",
        "\n",
        "    return standardized_data, standardizer"
      ],
      "id": "6d267b12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_clean, standardizer = standardizerData(data = X_test_concat)"
      ],
      "id": "53ab435d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_test_clean.head()"
      ],
      "id": "f9cea2a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Data Result\n"
      ],
      "id": "9a0cfe10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# libraries\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "#setting up\n",
        "rf_tree = RandomForestRegressor(n_estimators = 500,\n",
        "                                criterion = \"squared_error\",\n",
        "                                max_features = \"sqrt\",\n",
        "                                random_state = 123)\n",
        "\n",
        "#fit model train\n",
        "rf_tree.fit(X_train_clean, y_train)\n",
        "\n",
        "# Predict model\n",
        "y_pred_test = rf_tree.predict(X_test_clean)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae_rf_cv_test = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "# # Calculate R-squared\n",
        "r2_rf_cv_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(f\"R2-score: {r2_rf_cv_test:.3f} and MAE score: +/-{mae_rf_cv_test:.2f} RM\")\n",
        "\n",
        "sns.scatterplot(x=y_test, y=y_pred_test )\n",
        "plt.plot([0, 5500], [0,5500], \"--r\")\n",
        "plt.xlim(0, 5500)\n",
        "plt.xlabel(\"Actual Monthly Rent\")\n",
        "plt.ylim(0,5500)\n",
        "plt.ylabel(\"Predicted Monthly Rent\")\n",
        "plt.suptitle(\"Random Forest - Best Regression Model\")\n",
        "plt.show()"
      ],
      "id": "04e7acf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mae_score = [mae_rf_cv_train, mae_rf_cv_test]\n",
        "r2_score = [r2_rf_cv_train, r2_rf_cv_test]\n",
        "indexes = [\"train\", \"test\"]\n",
        "\n",
        "summary_df_train_test = pd.DataFrame({\n",
        "    \"MAE Train\": mae_score,\n",
        "    \"R2-Score\": r2_score,\n",
        "},index = indexes)\n",
        "\n",
        "summary_df_train_test"
      ],
      "id": "4e182898",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Feature Importance\n"
      ],
      "id": "1d1aec80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# calculate the feature importances\n",
        "importances = rf_tree.feature_importances_\n",
        "\n",
        "# rescale the importances back to the original scale of the features\n",
        "importances = importances * X_train_clean.std()\n",
        "\n",
        "# sort the feature importances in descending order\n",
        "sorted_index = importances.argsort()[::-1]\n",
        "\n",
        "# print the feature importances\n",
        "dict_feature_importance = {}\n",
        "for i in sorted_index:\n",
        "    # print(\"{}: {}\".format(X_train_clean.columns[i], importances[i]))\n",
        "    dict_feature_importance.update({X_train_clean.columns[i]: importances[i]})\n",
        "    \n",
        "# Create a DataFrame from the dictionary\n",
        "df = pd.DataFrame.from_dict(dict_feature_importance, orient='index', columns=['values'])\n",
        "\n",
        "# Reset the index to become a column\n",
        "df = df.reset_index()\n",
        "\n",
        "# Rename the columns\n",
        "df.columns = ['feature', 'importance_value']\n",
        "\n",
        "df.sort_values(by='importance_value', ascending=False).head(10)"
      ],
      "id": "880615ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results\n",
        "\n",
        "1.  Result indicates that the best model for prediction is Random Forest with hyperparameter tuning, scoring 95% on R2-score, and a shy 100 RM on MAE. This proves to be a good model since the test dataset gives a scoring of 80% on R2, and 240 RM on MAE.\n",
        "\n",
        "2.  There are some factors that author believed to be affecting the result/ performance of the model:\n",
        "\n",
        "    1.  Dropping missing value reduces the performance! Initial model uses half of the data (4-5k rows) and gives poorer performance on R2 and MAE. Imputation and keeping the number of rows close to the original dataset (9k rows) proves to be improving the model. Especially on test dataset.\n",
        "    2.  Feature selection importance can be seen on the last table, but initially the selection was based on paper and intuition of the author (author lives and work in KL, Malaysia for 5 years). Feature such as `completion_year` and `nearby_railways` are important in improving the model.\n",
        "    3.  Last but not least is the outlier identification. The best practice for me is using jointplot to see not only the distribution of the data in 2-dimension, but also in the third dimension (the density) of the data.\n",
        "\n",
        "3.  Some of the feature that were believed to be quite important even before doing the modeling is size, furnished and location. All three is available within the 10-most features affecting the modeling. As a context, location in KLCC is like Pondok Indah in South Jakarta. Location in Kiara is like BSD in South Tangerang.\n",
        "\n",
        "### Discussions\n",
        "\n",
        "1.  One of the feature that author thinks is significant but not appearing on the 10-best important feature is nearby_railways. This column is showing if a certain property has a close proximity to a railways (KTM/LRT). The issue is, half of the data is missing, hence the imputation. Author belives, the proximity to nearby railways line can be approximated using manhanttan distance of railways line to each property unit.\n"
      ],
      "id": "26ba7dc2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "minids",
      "language": "python",
      "display_name": "minids"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}