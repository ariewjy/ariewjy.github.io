[
  {
    "objectID": "posts/005-webscraping-machinelearning-rent-pricing/index.html",
    "href": "posts/005-webscraping-machinelearning-rent-pricing/index.html",
    "title": "Malaysia Property Pricing - Webscraping & Machine Learning Model",
    "section": "",
    "text": "Pacmann Batch 8 Capstone by Aditya Arie Wijaya (aditya-66kK)\n\n\nThis is a machine learning project to predict unit/property monthly rent price in Kuala Lumpur region, Malaysia. The project uses a dataset from an online ads listing for property mudah.my. This project outlines the process of web-scraping/ data gathering, data cleaning-wrangling, and machine learning modeling.\nThis project aims to answers question about how much a unit monthly rent would be if given information such as location, number of bedrooms, parking, furnished, etc? This would help potential tenant and also the owner to get the best price of their rental unit, comparable to the market value.\nSome previous work about house pricing was listed below, however most of them are targeting a dataset of house pricing or an Airbnb pricing. There are difference such as in Airbnb, the booking rarely took more than 2 weeks, let alone a year. Therefore the pricing may be different. Additionally, in Airbnb, there is text feature coming from the review given by the tenant and the owner.The better the review, the higher the rent prices – which was not available in this current project dataset.\nPrevious work by (Madhuri, Anuradha, and Pujitha 2019), (Xu and Nguyen 2022), (Zhao et al. 2022) highlight the importance feature selection, and the choice of machine learning model. Based on the previous works, the most consistently performed machine learning model are Random Forest and Gradient boosting, and the MAE and R2 score usually used in evaluating the performance of the model. Although the above work are all not about apartment rent pricing, similar method can be applied to this project.\n\n\n\nThe data will use a scraped data from the website mentioned before, focusing on property-to-rent surrounding Kuala Lumpur, Malaysia. \n\n\nShow Code\n#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_colwidth', 200)\nfrom bs4 import BeautifulSoup as bs\nimport requests\nimport re\nimport time\nimport datetime\nimport smtplib\nimport json\nfrom tqdm.notebook import tqdm, trange\nimport time    # to be used in loop iterations\n\n!jupyter nbextension enable --py widgetsnbextension #enabling progress bar\n\n\nEnabling notebook extension jupyter-js-widgets/extension...\n      - Validating: problems found:\n        - require?  X jupyter-js-widgets/extension\n\n\n\n\nThe process started out by gathering data from the website. We are using python library for web-scraping: BeautifulSoup as depicted below. The first process is generating a list of webpage address for a given page number.\n\n\nShow Code\n#generate list address of n_page\ndef page_number(start, end):\n    \"\"\"\n    Description:\n        Function to generate a list of webpage address for a given page number\n\n    Parameters:\n        start (int) : starting page number\n        end (int)   : ending page number\n    Returns:\n        a list of listing web address \n    \n    \"\"\"\n    \n    page_url = 'https://www.mudah.my/kuala-lumpur/apartment-condominium-for-rent?o='\n    list_page = []\n    for i in range(start,end+1):\n        list_page.append(page_url+str(i))\n    return list_page\npage_number(2,4)\n\n\n['https://www.mudah.my/kuala-lumpur/apartment-condominium-for-rent?o=2',\n 'https://www.mudah.my/kuala-lumpur/apartment-condominium-for-rent?o=3',\n 'https://www.mudah.my/kuala-lumpur/apartment-condominium-for-rent?o=4']\n\n\nThen generate a list of ads listing on a single page.\n\n\nShow Code\n#setting up list of page from \ndef get_list_html(page_url):\n    \"\"\"\n    Description:\n        Function to get every listing ads in a given url (page_url)\n\n    Parameters:\n        page_url (str): website url\n        \n    Returns:\n        a list of listing ads\n    \n    \"\"\"\n    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"}\n    page = requests.get(url=page_url, headers=headers)\n    soup = bs(page.text, \"html.parser\")\n\n    script_tag = soup.find('script', type='application/ld+json')\n    data = json.loads(script_tag.text)\n    dict_query = data[2]['itemListElement']\n\n    n_query = data[2]['numberOfItems']\n    list_html = []\n\n    for i in range(n_query):\n        link = data[2]['itemListElement'][i]['item']['url']\n        list_html.append(link)\n        \n    return list_html\n\n\n#getting listing property from the 1st-5th in the list\nget_list_html('https://www.mudah.my/neighbouring-kuala-lumpur/apartment-for-rent?o=2')[0:5]\n\n\n['https://www.mudah.my/Suria+Court+Mahkota+Cheras+-100450215.htm',\n 'https://www.mudah.my/Cemara+Apartment+Bandar+Sri+Permaisuri+Cheras+actual+pic-98750544.htm',\n 'https://www.mudah.my/Seasons+Garden+PV21+850sf+3R2B+Fully+Furnished+Actual+Pics+-100449939.htm',\n 'https://www.mudah.my/Pangsapuri+palma+puteri+with+fully+furnished+seksyen+6-92222541.htm',\n 'https://www.mudah.my/STUDENT+Danau+Perintis+Fully+Furnish+WIFI+PUNCAK+ALAM-100143070.htm']\n\n\nCombining the previous two functions, generate a list of url for all pages.\n\n\nShow Code\n#generate listing property from each page of n_page\ndef get_list_url(n_page):\n    \"\"\"\n    Description:\n        Function to get every listing ads in every page (n_page)\n\n    Parameters:\n        n_page (int): number of page\n        \n    Returns:\n        a list of listing ads\n    \n    \"\"\"\n    list_html=[]\n    for i in tqdm(range(n_page)):\n        list_html.extend(get_list_html(page_number(1, n_page)[i]))\n    return list_html\n\nget_list_url(2)[:10]\n\n\n\n\n\n['https://www.mudah.my/Pertiwi+Indah+1285sf+fully+furnished-98377671.htm',\n 'https://www.mudah.my/PPA1M+Kepong+2+Parking+FULLY+FURNISHED+-95301490.htm',\n 'https://www.mudah.my/PPA1M+Kepong+MARCH+2023+FULLY+FURNISHED+-98845611.htm',\n 'https://www.mudah.my/Ixora+Apartment+Kepong+yang+lengkap+dengan+Time+Internet+Access-100451938.htm',\n 'https://www.mudah.my/Pangsapuri+Permai+Sungai+Besi+3R2B+near+TBS+Bandar+Tasik+Selatan-98987533.htm',\n 'https://www.mudah.my/Inspirasi+Mont+Kiara+BRAND+NEW+RENOVATED+MID+FLOOR+UNIT+NICE+VIEW+-99491862.htm',\n 'https://www.mudah.my/Maxim+Residence+3+Room+3+Aircond+2+Car+Park+Walking+Distance+MRT-100451825.htm',\n 'https://www.mudah.my/Residensi+Harmoni+2+Cheapest+Rental+Near+Mont+Kiara+Sri+Hartamas+KL-100451718.htm',\n 'https://www.mudah.my/Angkasa+Condo+Taman+Connaught+Cheras+Walking+Distance+To+UCSI-100213869.htm',\n 'https://www.mudah.my/Maxim+Residence+Condo+Taman+Len+Cheras-99852286.htm']\n\n\nThen extract the attributes inside the listing ads in a form of nested dictionary.\n\n\nShow Code\n#extract data from url\ndef get_list_dict(n_page):\n    \"\"\"\n    Description:\n        Function to get dataset (atribut of units) in a form of dictionary. \n\n    Parameters:\n        n_page (int): number of page\n        \n    Returns:\n        a dictionaries of attributes inside a list\n    \n    \"\"\"\n    headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\"}\n    list_html = get_list_url(n_page)\n    list_dict = []\n    for url in tqdm(list_html):\n        try:\n            page = requests.get(url=url, headers=headers)\n            soup1 = bs(page.text, \"html.parser\")\n            soup2 = bs(soup1.prettify(), 'html.parser')\n\n            id_html = re.search(r'(\\d+).htm', url).group(1)\n            title = soup2.find(itemprop='name').text.strip()\n\n            script_tag = soup2.find(\"script\", id=\"__NEXT_DATA__\")\n            script_content = script_tag.text\n            data = json.loads(script_content)\n            props = data.get(\"props\", {})\n            id_listing = re.search(r'-(\\d+)\\.htm', url).group(1)\n\n            dict_id = [{'realValue': '', 'id': 'ads_id', 'value': id_listing, 'label': 'id ads'}]\n            dict_building = props[\"initialState\"][\"adDetails\"][\"byID\"][id_listing][\"attributes\"]['propertyParams'][2]['params']\n            dict_prop = props[\"initialState\"][\"adDetails\"][\"byID\"][id_listing][\"attributes\"]['categoryParams']\n            dict_unit = dict_id + dict_building + dict_prop\n        except:\n            None\n        \n        list_dict.append(dict_unit)\n        \n    return list_dict\n\n#sanity check\nget_list_dict(1)[1]\n\n\n\n\n\n\n\n\n[{'realValue': '', 'id': 'ads_id', 'value': '95301490', 'label': 'id ads'},\n {'realValue': 'PPA1M METROPOLITAN KEPONG',\n  'id': 'prop_name',\n  'value': 'PPA1M METROPOLITAN KEPONG',\n  'label': 'Building Name'},\n {'realValue': '', 'id': 'developer_name', 'value': '', 'label': 'Developer'},\n {'realValue': 'BLOK A PPA1M METROPOLITAN KEPONG MRR2, Kuala Lumpur, Kepong',\n  'id': 'full_address',\n  'value': 'BLOK A PPA1M METROPOLITAN KEPONG MRR2, Kuala Lumpur, Kepong',\n  'label': 'Address'},\n {'realValue': '',\n  'id': 'completion_year',\n  'value': '',\n  'label': 'Completion Year'},\n {'realValue': '', 'id': 'num_floors', 'value': '', 'label': '# of Floors'},\n {'realValue': '', 'id': 'num_units', 'value': '', 'label': 'Total Units'},\n {'realValue': 'RM 1 600 per month',\n  'id': 'monthly_rent',\n  'value': 'RM 1 600 per month',\n  'label': 'Monthly Rent'},\n {'realValue': '2020',\n  'id': 'category_id',\n  'value': 'Apartment / Condominium, For rent',\n  'label': 'Category'},\n {'realValue': '9',\n  'id': 'location',\n  'value': 'Kuala Lumpur - Kepong',\n  'label': 'Location'},\n {'realValue': '1',\n  'id': 'property_type',\n  'value': 'Condominium',\n  'label': 'Property Type'},\n {'realValue': '1',\n  'id': 'floor_range',\n  'value': 'High',\n  'label': 'Floor Range'},\n {'realValue': '5', 'id': 'rooms', 'value': '5', 'label': 'Bedrooms'},\n {'realValue': '2', 'id': 'bathroom', 'value': '2', 'label': 'Bathroom'},\n {'realValue': '1500', 'id': 'size', 'value': '1500 sq.ft.', 'label': 'Size'},\n {'realValue': '1',\n  'id': 'furnished',\n  'value': 'Fully Furnished',\n  'label': 'Furnished'},\n {'realValue': '13,9,12,7,5,16',\n  'id': 'facilities',\n  'value': 'Parking, Security, Lift, Playground, Minimart, Multipurpose hall',\n  'label': 'Facilities'},\n {'realValue': '6200',\n  'id': 'rendepo',\n  'value': 'RM 6200',\n  'label': 'Rental Deposit'},\n {'realValue': '1',\n  'id': 'additional_facilities',\n  'value': 'Air-Cond',\n  'label': 'Other Facilities'},\n {'realValue': 'e', 'id': 'firm_type', 'value': 'E', 'label': 'Firm Type'},\n {'realValue': '10091',\n  'id': 'estate_agent',\n  'value': '10091',\n  'label': 'Firm Number'}]\n\n\nExtracting the values inside the dictionary for each attributes.\n\n\nShow Code\n#getting values out of dictionary\ndef get_values(list_dict):\n    \"\"\"\n    Description:\n        Function to values of the previous dictionary.\n\n    Parameters:\n        list_dict (list): list of dictionary where attributes stored\n        \n    Returns:\n        a list of values (unit/property) attributes\n    \n    \"\"\"\n    keys = [\n        'ads_id',\n        'prop_name',\n        # 'developer_name', \n        # 'address', \n        'completion_year', \n        # 'num_floors', \n        # 'num_units',\n        'monthly_rent', \n        # 'category_id', \n        'location', \n        'property_type', \n        # 'floor_range', \n        'rooms', \n        'parking',\n        'bathroom', \n        'size', \n        'furnished',\n        'facilities', \n        'additional_facilities', \n       ]\n\n    values = {}\n    for key in keys:\n        try:\n            values[key] = next(item['value'] for item in list_dict if item[\"id\"] == key)\n        except StopIteration:\n            values[key] = None\n    return values\n\n#sanity check\nget_values(get_list_dict(1)[1])\n\n\n\n\n\n\n\n\n{'ads_id': '95301490',\n 'prop_name': 'PPA1M METROPOLITAN KEPONG',\n 'completion_year': '',\n 'monthly_rent': 'RM 1 600 per month',\n 'location': 'Kuala Lumpur - Kepong',\n 'property_type': 'Condominium',\n 'rooms': '5',\n 'parking': None,\n 'bathroom': '2',\n 'size': '1500 sq.ft.',\n 'furnished': 'Fully Furnished',\n 'facilities': 'Parking, Security, Lift, Playground, Minimart, Multipurpose hall',\n 'additional_facilities': 'Air-Cond'}\n\n\n\n\nShow Code\n#get df from list\ndef get_df_final(n_page):\n    \"\"\"\n    Description:\n        Function to generate dataframe from the list.\n\n    Parameters:\n        n_page (int): number of page\n        \n    Returns:\n        a dataframe of the list of attributes on each listings.\n    \n    \"\"\"\n    list_data = get_list_dict(n_page)\n    list_new = []\n    for i in range(0,len(list_data)):\n            dic = get_values(list_data[i])\n            list_new.append(dic)\n    \n    df = pd.DataFrame(list_new)\n    return df\n\n\nOf course we won’t scrape 250 pages at first, let’s extract 1 page only:\n\n\nShow Code\n#sanity check\nget_df_final(1).head(2).T\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      ads_id\n      98377671\n      95301490\n    \n    \n      prop_name\n      \n      PPA1M METROPOLITAN KEPONG\n    \n    \n      completion_year\n      \n      \n    \n    \n      monthly_rent\n      RM 2 000 per month\n      RM 1 600 per month\n    \n    \n      location\n      Kuala Lumpur - Cheras\n      Kuala Lumpur - Kepong\n    \n    \n      property_type\n      Condominium\n      Condominium\n    \n    \n      rooms\n      3\n      5\n    \n    \n      parking\n      1\n      None\n    \n    \n      bathroom\n      2\n      2\n    \n    \n      size\n      1285 sq.ft.\n      1500 sq.ft.\n    \n    \n      furnished\n      Fully Furnished\n      Fully Furnished\n    \n    \n      facilities\n      Parking, Security, Playground, Lift, Swimming Pool, Minimart\n      Parking, Security, Lift, Playground, Minimart, Multipurpose hall\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed\n      Air-Cond\n    \n  \n\n\n\n\nFinally, let’s extract dataset from 250 pages. File is then saved into a csv, to be reloaded again.\n\n\nShow Code\n# df_=get_df_final(250)\n# df_.to_csv('mudah-apartment-raw.csv', index=False)\n## already run, and file is saved\n\n\n\n\n\n\n\nReload the original dataset.\n\n\nShow Code\n#read it back\ndf = pd.read_csv('./mudah-apartment-raw.csv')\ndf.head(3).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      ads_id\n      100323185\n      100203973\n      100323128\n    \n    \n      prop_name\n      The Hipster @ Taman Desa\n      Segar Courts\n      Pangsapuri Teratak Muhibbah 2\n    \n    \n      completion_year\n      2022.0\n      NaN\n      NaN\n    \n    \n      monthly_rent\n      RM 4 200 per month\n      RM 2 300 per month\n      RM 1 000 per month\n    \n    \n      location\n      Kuala Lumpur - Taman Desa\n      Kuala Lumpur - Cheras\n      Kuala Lumpur - Taman Desa\n    \n    \n      property_type\n      Condominium\n      Condominium\n      Apartment\n    \n    \n      rooms\n      5\n      3\n      3\n    \n    \n      parking\n      2.0\n      1.0\n      NaN\n    \n    \n      bathroom\n      6.0\n      2.0\n      2.0\n    \n    \n      size\n      1842 sq.ft.\n      1170 sq.ft.\n      650 sq.ft.\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n      Fully Furnished\n    \n    \n      facilities\n      Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track\n      Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna\n      Minimart, Jogging Track, Lift, Swimming Pool\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed, Washing Machine\n      Air-Cond, Cooking Allowed, Near KTM/LRT\n      NaN\n    \n  \n\n\n\n\n\n\n\n\n\nShow Code\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 13 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   ads_id                 10000 non-null  int64  \n 1   prop_name              9492 non-null   object \n 2   completion_year        5623 non-null   float64\n 3   monthly_rent           10000 non-null  object \n 4   location               10000 non-null  object \n 5   property_type          10000 non-null  object \n 6   rooms                  9998 non-null   object \n 7   parking                7368 non-null   float64\n 8   bathroom               9998 non-null   float64\n 9   size                   10000 non-null  object \n 10  furnished              9999 non-null   object \n 11  facilities             9104 non-null   object \n 12  additional_facilities  7167 non-null   object \ndtypes: float64(3), int64(1), object(9)\nmemory usage: 1015.8+ KB\n\n\nThe following feature is available in the dataset:\n\nads_id: ads listing ID, unique to each ads\nprop_name: the building name of the property\ncompletion_year: year of the building/property completed\nmonthly_rent: monthly rent price in Malaysian Ringgit (RM)\nlocation: the location (region) of the property\nproperty_type: property type, such as flat, apartment, etc\nrooms: number of rooms\nparking: number of parking spot\nbathroom: number of bathroom\nsize: total area of the unit in sq.ft\nfurnished: furnishin status of the unit, fully-partial-non\nfacilities: main facilities within the unit\nadditional_facilities: additional facilities\n\n\n\n\n\nShow Code\n#cek duplikat\ndf.duplicated().sum()\n\n#drop duplikat\ndf1 = df.drop_duplicates()\n\n\nSaving the file to csv after remove duplicated values.\n\n\nShow Code\n# #saving to csv\n# df1.to_csv(\"mudah-apartment-clean.csv\", index=False)\n# #saved already\n\n\nReload the data after drop duplicates\n\n\nShow Code\n#reload the data\ndf = pd.read_csv(\"./mudah-apartment-clean.csv\")\n\n\n\n\nShow Code\n#sanity check\ndf.duplicated().sum()\n\n\n0\n\n\n\n\n\n\n\nShow Code\n#removing RM from monthly rent\ndf['monthly_rent'] = df['monthly_rent'].apply(lambda x: int(re.search(r'RM (.*?) per', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'monthly_rent': 'monthly_rent_rm'})\n\n#dropping sq.ft from size\ndf['size'] = df['size'].apply(lambda x: int(re.search(r'(.*?) sq', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'size': 'size_sqft'})\n\n#dropping kuala lumpur from the location\ndf['location'] = df['location'].apply(lambda x: re.findall(\"\\w+$\", x)[0])\ndf.head(4).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n    \n  \n  \n    \n      ads_id\n      100323185\n      100203973\n      100323128\n      100191767\n    \n    \n      prop_name\n      The Hipster @ Taman Desa\n      Segar Courts\n      Pangsapuri Teratak Muhibbah 2\n      Sentul Point Suite Apartment\n    \n    \n      completion_year\n      2022.0\n      NaN\n      NaN\n      2020.0\n    \n    \n      monthly_rent_rm\n      4200\n      2300\n      1000\n      1700\n    \n    \n      location\n      Desa\n      Cheras\n      Desa\n      Sentul\n    \n    \n      property_type\n      Condominium\n      Condominium\n      Apartment\n      Apartment\n    \n    \n      rooms\n      5\n      3\n      3\n      2\n    \n    \n      parking\n      2.0\n      1.0\n      NaN\n      1.0\n    \n    \n      bathroom\n      6.0\n      2.0\n      2.0\n      2.0\n    \n    \n      size_sqft\n      1842\n      1170\n      650\n      743\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n      Fully Furnished\n      Partially Furnished\n    \n    \n      facilities\n      Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track\n      Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna\n      Minimart, Jogging Track, Lift, Swimming Pool\n      Parking, Playground, Swimming Pool, Squash Court, Security, Minimart, Gymnasium, Lift\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed, Washing Machine\n      Air-Cond, Cooking Allowed, Near KTM/LRT\n      NaN\n      Cooking Allowed, Near KTM/LRT, Washing Machine\n    \n  \n\n\n\n\n\n\n\nHypotheses: closer access to KTM/LRT = higher monthly rent\n\n\nShow Code\n#extracting near KTM/LRT from the additional facilities\ndef extract_near_ktm_lrt(text):\n    pattern = re.compile(r'\\bNear KTM/LRT\\b')\n    try:\n        match = pattern.search(text)\n        if match:\n            return 'yes'\n        return 'no'\n    except TypeError:\n        return text\n\n\nExtracting “near KTM/LRT” into its own column.\n\n\nShow Code\ndf['nearby_railways'] = df.additional_facilities.apply(lambda x: extract_near_ktm_lrt(x))\ndf.head(4).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      3\n    \n  \n  \n    \n      ads_id\n      100323185\n      100203973\n      100323128\n      100191767\n    \n    \n      prop_name\n      The Hipster @ Taman Desa\n      Segar Courts\n      Pangsapuri Teratak Muhibbah 2\n      Sentul Point Suite Apartment\n    \n    \n      completion_year\n      2022.0\n      NaN\n      NaN\n      2020.0\n    \n    \n      monthly_rent_rm\n      4200\n      2300\n      1000\n      1700\n    \n    \n      location\n      Desa\n      Cheras\n      Desa\n      Sentul\n    \n    \n      property_type\n      Condominium\n      Condominium\n      Apartment\n      Apartment\n    \n    \n      rooms\n      5\n      3\n      3\n      2\n    \n    \n      parking\n      2.0\n      1.0\n      NaN\n      1.0\n    \n    \n      bathroom\n      6.0\n      2.0\n      2.0\n      2.0\n    \n    \n      size_sqft\n      1842\n      1170\n      650\n      743\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n      Fully Furnished\n      Partially Furnished\n    \n    \n      facilities\n      Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track\n      Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna\n      Minimart, Jogging Track, Lift, Swimming Pool\n      Parking, Playground, Swimming Pool, Squash Court, Security, Minimart, Gymnasium, Lift\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed, Washing Machine\n      Air-Cond, Cooking Allowed, Near KTM/LRT\n      NaN\n      Cooking Allowed, Near KTM/LRT, Washing Machine\n    \n    \n      nearby_railways\n      no\n      yes\n      NaN\n      yes\n    \n  \n\n\n\n\nPlotting the difference between nearby KTM/LRT or not:\n\n\nShow Code\nsns.boxplot(data=df, x='monthly_rent_rm', y='nearby_railways')\nplt.xlim(0,4000);\n\nnear_ktmlrt = df.query(\" nearby_railways == 'yes' \")\nnot_near_ktmlrt = df.query(\" nearby_railways == 'no' \")\n\nprint(f\"\"\" \nMedian:\nNearby KTM/LRT: {near_ktmlrt.monthly_rent_rm.median():.0f}RM\nNot nearby KTM/LRT: {not_near_ktmlrt.monthly_rent_rm.median():.0f}RM\n      \"\"\")\n\n\n \nMedian:\nNearby KTM/LRT: 1650RM\nNot nearby KTM/LRT: 1600RM\n      \n\n\n\n\nFigure 1: Boxplot between Nearby KTM/LRT or Not\n\n\n\n\n\nSanity check:\n\n\nShow Code\ndf[df['prop_name'] == 'Majestic Maxim'][['nearby_railways']].value_counts()\n\n\nnearby_railways\nyes                166\nno                  24\ndtype: int64\n\n\nAs seen above, Figure 1 shows that it sligthly increases the median monthly rent by 50RM. However, near KTM/LRT is not appearing in all row even though the property is the same\nConclusion: Near KTM/LRT may be used, but it can be improved as the listing is inconsistent\n\n\n\n\n\nShow Code\ndf.isna().sum()\n\n\nads_id                      0\nprop_name                 508\ncompletion_year          4373\nmonthly_rent_rm             0\nlocation                    0\nproperty_type               0\nrooms                       2\nparking                  2630\nbathroom                    2\nsize_sqft                   0\nfurnished                   1\nfacilities                895\nadditional_facilities    2831\nnearby_railways          2831\ndtype: int64\n\n\n\n\nShow Code\n#dropping some columns\ndf = df.drop(columns=[\n    'ads_id', \n    'prop_name', \n    'facilities', \n    'additional_facilities',\n    # 'nearby_railways',\n    # 'completion_year'\n])\ndf\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      monthly_rent_rm\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      0\n      2022.0\n      4200\n      Desa\n      Condominium\n      5\n      2.0\n      6.0\n      1842\n      Fully Furnished\n      no\n    \n    \n      1\n      NaN\n      2300\n      Cheras\n      Condominium\n      3\n      1.0\n      2.0\n      1170\n      Partially Furnished\n      yes\n    \n    \n      2\n      NaN\n      1000\n      Desa\n      Apartment\n      3\n      NaN\n      2.0\n      650\n      Fully Furnished\n      NaN\n    \n    \n      3\n      2020.0\n      1700\n      Sentul\n      Apartment\n      2\n      1.0\n      2.0\n      743\n      Partially Furnished\n      yes\n    \n    \n      4\n      NaN\n      1299\n      Kiara\n      Service Residence\n      1\n      1.0\n      1.0\n      494\n      Not Furnished\n      no\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9986\n      2017.0\n      1400\n      Sentul\n      Service Residence\n      3\n      1.0\n      2.0\n      900\n      Not Furnished\n      no\n    \n    \n      9987\n      1998.0\n      1000\n      Desa\n      Apartment\n      3\n      NaN\n      2.0\n      657\n      Fully Furnished\n      no\n    \n    \n      9988\n      2021.0\n      1488\n      Cheras\n      Condominium\n      3\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      9989\n      1988.0\n      2000\n      Desa\n      Condominium\n      3\n      2.0\n      2.0\n      1200\n      Fully Furnished\n      no\n    \n    \n      9990\n      NaN\n      2000\n      Cheras\n      Condominium\n      3\n      2.0\n      3.0\n      1010\n      Fully Furnished\n      yes\n    \n  \n\n9991 rows × 10 columns\n\n\n\n\n\nShow Code\n#checking dtypes from all columns\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9991 entries, 0 to 9990\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   completion_year  5618 non-null   float64\n 1   monthly_rent_rm  9991 non-null   int64  \n 2   location         9991 non-null   object \n 3   property_type    9991 non-null   object \n 4   rooms            9989 non-null   object \n 5   parking          7361 non-null   float64\n 6   bathroom         9989 non-null   float64\n 7   size_sqft        9991 non-null   int64  \n 8   furnished        9990 non-null   object \n 9   nearby_railways  7160 non-null   object \ndtypes: float64(3), int64(2), object(5)\nmemory usage: 780.7+ KB\n\n\n\n\nShow Code\n#converting rooms from object to int64\ndf['rooms'] = pd.to_numeric(df['rooms'], downcast='integer', errors='coerce')\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9991 entries, 0 to 9990\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   completion_year  5618 non-null   float64\n 1   monthly_rent_rm  9991 non-null   int64  \n 2   location         9991 non-null   object \n 3   property_type    9991 non-null   object \n 4   rooms            9987 non-null   float64\n 5   parking          7361 non-null   float64\n 6   bathroom         9989 non-null   float64\n 7   size_sqft        9991 non-null   int64  \n 8   furnished        9990 non-null   object \n 9   nearby_railways  7160 non-null   object \ndtypes: float64(4), int64(2), object(4)\nmemory usage: 780.7+ KB\n\n\n\n\n\nTo remove some unexplainable data such as 0 monthly rent, 0 size, the rent that is way too old (1970), including the monthly rent that is way too high and/or size too big.\n\n\nShow Code\ndf[['size_sqft', 'monthly_rent_rm']].plot(kind='scatter', x='size_sqft', y='monthly_rent_rm');\nplt.ylim(100,5500) #batas harga rent\nplt.xlim(50,3000)  #batas size\nplt.show()\n\n\n\n\nFigure 2: Monthly Rent\n\n\n\n\n\n\n\n\n\nShow Code\nfig, axs = plt.subplots(1,2)\naxs[0].boxplot(data=df, x='monthly_rent_rm')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=df, x='monthly_rent_rm')\naxs[1].set_ylim(0,5000)\naxs[1].set_title('croped at 5,000 RM')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nFigure 3: Comparison between Different Scale\n\n\n\n\n\nBased on EDA on Figure 2 and Figure 3, author decided to filter the data between 100-5500 RM as follows:\n\n\nShow Code\n#removing all rows with monthly rent above 5500 RM and below 100RM\ndfx = df.query(\" monthly_rent_rm > 100 & monthly_rent_rm < 5500 \")\ndfx.describe()\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      monthly_rent_rm\n      rooms\n      parking\n      bathroom\n      size_sqft\n    \n  \n  \n    \n      count\n      5530.000000\n      9841.000000\n      9838.000000\n      7245.000000\n      9840.000000\n      9.841000e+03\n    \n    \n      mean\n      2014.863110\n      1786.840260\n      2.742427\n      1.339268\n      1.928760\n      1.111279e+04\n    \n    \n      std\n      7.436904\n      768.813626\n      0.763700\n      0.517512\n      0.517118\n      1.008037e+06\n    \n    \n      min\n      1980.000000\n      110.000000\n      1.000000\n      1.000000\n      1.000000\n      1.000000e+00\n    \n    \n      25%\n      2011.000000\n      1300.000000\n      2.000000\n      1.000000\n      2.000000\n      8.000000e+02\n    \n    \n      50%\n      2017.000000\n      1600.000000\n      3.000000\n      1.000000\n      2.000000\n      9.080000e+02\n    \n    \n      75%\n      2020.000000\n      2100.000000\n      3.000000\n      2.000000\n      2.000000\n      1.087000e+03\n    \n    \n      max\n      2025.000000\n      5300.000000\n      9.000000\n      10.000000\n      6.000000\n      1.000000e+08\n    \n  \n\n\n\n\nSanity check after removal as shown in Figure 4 belo:\n\n\nShow Code\ndfx.monthly_rent_rm.plot(kind='box', x='monthly_rent_rm');\n\n\n\n\nFigure 4: Data after Outlier Removal\n\n\n\n\n\n\n\n\n\nChecking the dataset in terms of size.\n\n\nShow Code\nfig, axs = plt.subplots(1,2)\naxs[0].boxplot(data=dfx, x='size_sqft')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=dfx, x='size_sqft')\naxs[1].set_ylim(0,2000)\naxs[1].set_title('croped at 0-2,000 square feet')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nFigure 5: Raw Data Size sq.ft\n\n\n\n\n\nStill based on Figure 2, outliers are removed.\n\n\nShow Code\n#removing outliers below 500, and higher than 3000 sqft and below 50 sqft\ndfx = \\\n(dfx.query(\" size_sqft > 50 & size_sqft < 3000 \")\n # .size_sqft\n # .plot(kind='box')\n)\ndfx\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      monthly_rent_rm\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      0\n      2022.0\n      4200\n      Desa\n      Condominium\n      5.0\n      2.0\n      6.0\n      1842\n      Fully Furnished\n      no\n    \n    \n      1\n      NaN\n      2300\n      Cheras\n      Condominium\n      3.0\n      1.0\n      2.0\n      1170\n      Partially Furnished\n      yes\n    \n    \n      2\n      NaN\n      1000\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      650\n      Fully Furnished\n      NaN\n    \n    \n      3\n      2020.0\n      1700\n      Sentul\n      Apartment\n      2.0\n      1.0\n      2.0\n      743\n      Partially Furnished\n      yes\n    \n    \n      4\n      NaN\n      1299\n      Kiara\n      Service Residence\n      1.0\n      1.0\n      1.0\n      494\n      Not Furnished\n      no\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9986\n      2017.0\n      1400\n      Sentul\n      Service Residence\n      3.0\n      1.0\n      2.0\n      900\n      Not Furnished\n      no\n    \n    \n      9987\n      1998.0\n      1000\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      657\n      Fully Furnished\n      no\n    \n    \n      9988\n      2021.0\n      1488\n      Cheras\n      Condominium\n      3.0\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      9989\n      1988.0\n      2000\n      Desa\n      Condominium\n      3.0\n      2.0\n      2.0\n      1200\n      Fully Furnished\n      no\n    \n    \n      9990\n      NaN\n      2000\n      Cheras\n      Condominium\n      3.0\n      2.0\n      3.0\n      1010\n      Fully Furnished\n      yes\n    \n  \n\n9822 rows × 10 columns\n\n\n\nSanity check:\n\n\nShow Code\ndfx.size_sqft.plot(kind='box');\n\n\n\n\n\n\n\nShow Code\nfig, axs = plt.subplots(1,5, figsize=(12,4))\naxs[0].boxplot(data=dfx.dropna(), x='size_sqft')\naxs[1].boxplot(data=dfx.dropna(), x='rooms')\naxs[2].boxplot(data=dfx.dropna(), x='parking')\naxs[3].boxplot(data=dfx.dropna(), x='bathroom')\n# axs[4].boxplot(data=dfx.dropna(), x='completion_year')\n\naxs[0].set_title('Size')\naxs[1].set_title('Rooms')\naxs[2].set_title('Parking')\naxs[3].set_title('Bathrooms')\n# axs[4].set_title('Completion Year')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nFigure 6: Final Data after Outlier Removal\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow Code\ndef extractInputOutput(data,\n                       output_column_name):\n    \"\"\"\n    Fungsi untuk memisahkan data input dan output\n    :param data: <pandas dataframe> data seluruh sample\n    :param output_column_name: <string> nama kolom output\n    :return input_data: <pandas dataframe> data input\n    :return output_data: <pandas series> data output\n    \"\"\"\n    output_data = data[output_column_name]\n    input_data = data.drop(output_column_name,\n                           axis = 1)\n    \n    return input_data, output_data\n\n\n\n\nShow Code\nX, y = extractInputOutput(data=dfx, output_column_name='monthly_rent_rm')\n\n\n\n\nShow Code\nX\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      0\n      2022.0\n      Desa\n      Condominium\n      5.0\n      2.0\n      6.0\n      1842\n      Fully Furnished\n      no\n    \n    \n      1\n      NaN\n      Cheras\n      Condominium\n      3.0\n      1.0\n      2.0\n      1170\n      Partially Furnished\n      yes\n    \n    \n      2\n      NaN\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      650\n      Fully Furnished\n      NaN\n    \n    \n      3\n      2020.0\n      Sentul\n      Apartment\n      2.0\n      1.0\n      2.0\n      743\n      Partially Furnished\n      yes\n    \n    \n      4\n      NaN\n      Kiara\n      Service Residence\n      1.0\n      1.0\n      1.0\n      494\n      Not Furnished\n      no\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9986\n      2017.0\n      Sentul\n      Service Residence\n      3.0\n      1.0\n      2.0\n      900\n      Not Furnished\n      no\n    \n    \n      9987\n      1998.0\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      657\n      Fully Furnished\n      no\n    \n    \n      9988\n      2021.0\n      Cheras\n      Condominium\n      3.0\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      9989\n      1988.0\n      Desa\n      Condominium\n      3.0\n      2.0\n      2.0\n      1200\n      Fully Furnished\n      no\n    \n    \n      9990\n      NaN\n      Cheras\n      Condominium\n      3.0\n      2.0\n      3.0\n      1010\n      Fully Furnished\n      yes\n    \n  \n\n9822 rows × 9 columns\n\n\n\n\n\nShow Code\ny\n\n\n0       4200\n1       2300\n2       1000\n3       1700\n4       1299\n        ... \n9986    1400\n9987    1000\n9988    1488\n9989    2000\n9990    2000\nName: monthly_rent_rm, Length: 9822, dtype: int64\n\n\n\n\n\n\n\nShow Code\n#import libraries\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nShow Code\n# Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size = 0.2,\n                                                    random_state = 123)\n\n\n\n\nShow Code\n#sanity check\nlen(X_test)/len(X)\n\n\n0.20006108735491754\n\n\n\n\nShow Code\n#sanity check\nX_train\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      5978\n      2020.0\n      Sentul\n      Apartment\n      3.0\n      1.0\n      2.0\n      876\n      Partially Furnished\n      yes\n    \n    \n      2151\n      2022.0\n      Setapak\n      Condominium\n      3.0\n      1.0\n      2.0\n      850\n      Fully Furnished\n      yes\n    \n    \n      9714\n      2002.0\n      Cheras\n      Condominium\n      3.0\n      NaN\n      2.0\n      1000\n      Fully Furnished\n      yes\n    \n    \n      8556\n      2021.0\n      Cheras\n      Service Residence\n      2.0\n      1.0\n      2.0\n      680\n      Partially Furnished\n      yes\n    \n    \n      2809\n      2005.0\n      Cheras\n      Condominium\n      3.0\n      1.0\n      2.0\n      920\n      Partially Furnished\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9954\n      2016.0\n      Besi\n      Service Residence\n      3.0\n      2.0\n      2.0\n      1121\n      Partially Furnished\n      yes\n    \n    \n      7901\n      NaN\n      Jalil\n      Flat\n      3.0\n      NaN\n      2.0\n      650\n      Not Furnished\n      yes\n    \n    \n      5322\n      2013.0\n      Kepong\n      Condominium\n      3.0\n      2.0\n      2.0\n      1378\n      Fully Furnished\n      no\n    \n    \n      1363\n      NaN\n      Desa\n      Condominium\n      3.0\n      1.0\n      2.0\n      950\n      Partially Furnished\n      NaN\n    \n    \n      3648\n      2019.0\n      KLCC\n      Service Residence\n      2.0\n      1.0\n      2.0\n      796\n      Fully Furnished\n      NaN\n    \n  \n\n7857 rows × 9 columns\n\n\n\nPreprocessing Original Data for Categorical Dtypes\nOne must paying attention to the number of categorical observation in the original data, with respect to the sampling train-test value. If, the test_size = 0.3, that means any categorical observation with a total of 3 and less, would not be distributed evenly among train and test data.\n\n\nShow Code\nprint(dfx.location.nunique())\nprint(X_train.location.nunique())\nprint(X_test.location.nunique())\n\n\n53\n53\n50\n\n\n\n\nShow Code\nprint(dfx.property_type.nunique())\nprint(X_train.property_type.nunique())\nprint(X_test.property_type.nunique())\n\n\n9\n9\n8\n\n\n\n\nShow Code\nprint(set(X_train.furnished.to_list()) - set(X_test.furnished.to_list()))\nprint(set(X_train.location.to_list()) - set(X_test.location.to_list()))\nprint(set(X_train.property_type.to_list()) - set(X_test.property_type.to_list()))\nprint(set(X_train.nearby_railways.to_list()) - set(X_test.nearby_railways.to_list()))\n\n\nset()\n{'Sentral', 'Lin', 'Penchala'}\n{'Condo / Services residence / Penthouse / Townhouse'}\nset()\n\n\n\nDropping Data\n\n\n\nShow Code\ndfx\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      monthly_rent_rm\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      0\n      2022.0\n      4200\n      Desa\n      Condominium\n      5.0\n      2.0\n      6.0\n      1842\n      Fully Furnished\n      no\n    \n    \n      1\n      NaN\n      2300\n      Cheras\n      Condominium\n      3.0\n      1.0\n      2.0\n      1170\n      Partially Furnished\n      yes\n    \n    \n      2\n      NaN\n      1000\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      650\n      Fully Furnished\n      NaN\n    \n    \n      3\n      2020.0\n      1700\n      Sentul\n      Apartment\n      2.0\n      1.0\n      2.0\n      743\n      Partially Furnished\n      yes\n    \n    \n      4\n      NaN\n      1299\n      Kiara\n      Service Residence\n      1.0\n      1.0\n      1.0\n      494\n      Not Furnished\n      no\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      9986\n      2017.0\n      1400\n      Sentul\n      Service Residence\n      3.0\n      1.0\n      2.0\n      900\n      Not Furnished\n      no\n    \n    \n      9987\n      1998.0\n      1000\n      Desa\n      Apartment\n      3.0\n      NaN\n      2.0\n      657\n      Fully Furnished\n      no\n    \n    \n      9988\n      2021.0\n      1488\n      Cheras\n      Condominium\n      3.0\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      9989\n      1988.0\n      2000\n      Desa\n      Condominium\n      3.0\n      2.0\n      2.0\n      1200\n      Fully Furnished\n      no\n    \n    \n      9990\n      NaN\n      2000\n      Cheras\n      Condominium\n      3.0\n      2.0\n      3.0\n      1010\n      Fully Furnished\n      yes\n    \n  \n\n9822 rows × 10 columns\n\n\n\n\n\nShow Code\ndfx.location.value_counts()\n\n\nCheras         1614\nSetapak         965\nSentul          776\nKepong          662\nJalil           577\nMaju            456\nAmpang          327\nKeramat         300\nRoad            298\nDesa            295\nCity            268\nKiara           264\nKLCC            239\nIpoh            224\nLama            193\nSegambut        178\nPetaling        174\nPandan          173\nBesi            173\nKuching         168\nSouth           143\nPantai          113\nBintang          99\nMelawati         91\nTitiwangsa       83\nHilir            78\nHartamas         75\nDamansara        73\nOUG              63\nIsmail           59\nDutamas          57\nGombak           56\nPerdana          53\nSetiawangsa      50\nParkCity         50\nBangsar          47\nMenjalara        45\nSeputeh          35\nPuchong          33\nIndah            29\nCentre           25\nJaya             24\nBrickfields      24\nPudu             24\nSelatan          19\nHeights          18\nJinjang           9\nSerdang           9\nSentral           5\nOthers            5\nTunku             2\nPenchala          1\nLin               1\nName: location, dtype: int64\n\n\n\n\nShow Code\ndfx.property_type.value_counts()\n\n\nCondominium                                           4698\nService Residence                                     2647\nApartment                                             2123\nFlat                                                   265\nStudio                                                  27\nDuplex                                                  27\nOthers                                                  27\nTownhouse Condo                                          7\nCondo / Services residence / Penthouse / Townhouse       1\nName: property_type, dtype: int64\n\n\n\n\nShow Code\ndfx_new = dfx[\n    (dfx.location != 'Jinjang') \n    & (dfx.location != 'Serdang') & \n    (dfx.location != 'Sentral') & \n    (dfx.location != 'Others') & \n    (dfx.location != 'Tunku') & \n    (dfx.location != 'Penchala') & \n    (dfx.location != 'Lin') &\n    # (dfx.property_type != 'Others') &\n    (dfx.property_type != 'Condo / Services residence / Penthouse / Townhouse') &\n    (dfx.property_type != 'Townhouse Condo')\n]\n\n\n\n\nShow Code\ndfx_new.property_type.value_counts()\n\n\nCondominium          4683\nService Residence    2642\nApartment            2115\nFlat                  263\nDuplex                 27\nStudio                 26\nOthers                 26\nName: property_type, dtype: int64\n\n\n\nRe-split Training-Test\n\n\n\nShow Code\nX, y = extractInputOutput(data=dfx_new, output_column_name='monthly_rent_rm')\n\n\n\n\nShow Code\n#import libraries\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nShow Code\n# Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size = 0.2,\n                                                    random_state = 123)\n\n\n\n\nShow Code\n#sanity check\nlen(X_test)/len(X)\n\n\n0.2000613371498671\n\n\n\n\nShow Code\nX_train\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      8649\n      NaN\n      Maju\n      Condominium\n      2.0\n      1.0\n      1.0\n      800\n      Fully Furnished\n      yes\n    \n    \n      9112\n      1993.0\n      Bangsar\n      Condominium\n      2.0\n      1.0\n      1.0\n      890\n      Fully Furnished\n      yes\n    \n    \n      1472\n      NaN\n      Jalil\n      Condominium\n      1.0\n      NaN\n      1.0\n      1200\n      Fully Furnished\n      yes\n    \n    \n      5536\n      NaN\n      Cheras\n      Condominium\n      3.0\n      2.0\n      2.0\n      893\n      Fully Furnished\n      no\n    \n    \n      8152\n      NaN\n      Pudu\n      Apartment\n      3.0\n      NaN\n      2.0\n      980\n      Partially Furnished\n      yes\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7541\n      2001.0\n      Ampang\n      Apartment\n      3.0\n      NaN\n      2.0\n      828\n      Partially Furnished\n      NaN\n    \n    \n      7927\n      NaN\n      South\n      Flat\n      3.0\n      NaN\n      2.0\n      750\n      Not Furnished\n      NaN\n    \n    \n      5340\n      2023.0\n      Cheras\n      Condominium\n      4.0\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      1369\n      NaN\n      KLCC\n      Condominium\n      1.0\n      NaN\n      1.0\n      473\n      Fully Furnished\n      yes\n    \n    \n      3659\n      2017.0\n      Road\n      Service Residence\n      3.0\n      NaN\n      2.0\n      953\n      Partially Furnished\n      NaN\n    \n  \n\n7825 rows × 9 columns\n\n\n\n\n\nShow Code\nprint(set(X_train.furnished.to_list()) - set(X_test.furnished.to_list()))\nprint(set(X_train.location.to_list()) - set(X_test.location.to_list()))\nprint(set(X_train.property_type.to_list()) - set(X_test.property_type.to_list()))\n# print(set(X_train.nearby_railways.to_list()) - set(X_test.nearby_railways.to_list()))\n\n\nset()\nset()\nset()\n\n\n\n\nShow Code\nprint(dfx_new.location.nunique())\nprint(X_train.location.nunique())\nprint(X_test.location.nunique())\n\n\n46\n46\n46\n\n\n\n\nShow Code\n#sanity check\nX_train\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      location\n      property_type\n      rooms\n      parking\n      bathroom\n      size_sqft\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      8649\n      NaN\n      Maju\n      Condominium\n      2.0\n      1.0\n      1.0\n      800\n      Fully Furnished\n      yes\n    \n    \n      9112\n      1993.0\n      Bangsar\n      Condominium\n      2.0\n      1.0\n      1.0\n      890\n      Fully Furnished\n      yes\n    \n    \n      1472\n      NaN\n      Jalil\n      Condominium\n      1.0\n      NaN\n      1.0\n      1200\n      Fully Furnished\n      yes\n    \n    \n      5536\n      NaN\n      Cheras\n      Condominium\n      3.0\n      2.0\n      2.0\n      893\n      Fully Furnished\n      no\n    \n    \n      8152\n      NaN\n      Pudu\n      Apartment\n      3.0\n      NaN\n      2.0\n      980\n      Partially Furnished\n      yes\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7541\n      2001.0\n      Ampang\n      Apartment\n      3.0\n      NaN\n      2.0\n      828\n      Partially Furnished\n      NaN\n    \n    \n      7927\n      NaN\n      South\n      Flat\n      3.0\n      NaN\n      2.0\n      750\n      Not Furnished\n      NaN\n    \n    \n      5340\n      2023.0\n      Cheras\n      Condominium\n      4.0\n      2.0\n      2.0\n      1000\n      Partially Furnished\n      yes\n    \n    \n      1369\n      NaN\n      KLCC\n      Condominium\n      1.0\n      NaN\n      1.0\n      473\n      Fully Furnished\n      yes\n    \n    \n      3659\n      2017.0\n      Road\n      Service Residence\n      3.0\n      NaN\n      2.0\n      953\n      Partially Furnished\n      NaN\n    \n  \n\n7825 rows × 9 columns\n\n\n\n\n\nShow Code\n#export data training\nX_train.to_csv('X_train.csv', index=False)\ny_train.to_csv('y_train.csv', index=False)\n\n\n\n\nShow Code\n#export data testing\nX_test.to_csv('X_test.csv', index=False)\ny_test.to_csv('y_test.csv', index=False)\n\n\n\n\n\n\n\n\nShow Code\n#checking null data\nX_train.isna().sum()\n\n\ncompletion_year    3438\nlocation              0\nproperty_type         0\nrooms                 2\nparking            2074\nbathroom              0\nsize_sqft             0\nfurnished             0\nnearby_railways    2206\ndtype: int64\n\n\n\n\n\n\nShow Code\nX_train_num =  X_train.select_dtypes(exclude='object')\nX_train_num\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n    \n  \n  \n    \n      8649\n      NaN\n      2.0\n      1.0\n      1.0\n      800\n    \n    \n      9112\n      1993.0\n      2.0\n      1.0\n      1.0\n      890\n    \n    \n      1472\n      NaN\n      1.0\n      NaN\n      1.0\n      1200\n    \n    \n      5536\n      NaN\n      3.0\n      2.0\n      2.0\n      893\n    \n    \n      8152\n      NaN\n      3.0\n      NaN\n      2.0\n      980\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7541\n      2001.0\n      3.0\n      NaN\n      2.0\n      828\n    \n    \n      7927\n      NaN\n      3.0\n      NaN\n      2.0\n      750\n    \n    \n      5340\n      2023.0\n      4.0\n      2.0\n      2.0\n      1000\n    \n    \n      1369\n      NaN\n      1.0\n      NaN\n      1.0\n      473\n    \n    \n      3659\n      2017.0\n      3.0\n      NaN\n      2.0\n      953\n    \n  \n\n7825 rows × 5 columns\n\n\n\n\n\nShow Code\nX_train_num.isna().sum()\n\n\ncompletion_year    3438\nrooms                 2\nparking            2074\nbathroom              0\nsize_sqft             0\ndtype: int64\n\n\n\nWe can fill completion year, rooms, parking and bathroom with mode\n\n\n\nShow Code\nfrom sklearn.impute import SimpleImputer\n\ndef numericalImputation(X_train_num, strategy = 'most_frequent'):\n    \"\"\"\n    Fungsi untuk melakukan imputasi data numerik NaN\n    :param data: <pandas dataframe> sample data input\n\n    :return X_train_numerical: <pandas dataframe> data numerik\n    :return imputer_numerical: numerical imputer method\n    \"\"\"\n    #buat imputer\n    imputer_num = SimpleImputer(missing_values = np.nan, strategy = strategy)\n    \n    #fitting\n    imputer_num.fit(X_train_num)\n\n    # transform\n    imputed_data = imputer_num.transform(X_train_num)\n    X_train_num_imputed = pd.DataFrame(imputed_data)\n\n    #pastikan index dan nama kolom antara imputed dan non-imputed SAMA\n    X_train_num_imputed.columns = X_train_num.columns\n    X_train_num_imputed.index = X_train_num.index\n\n    return X_train_num_imputed, imputer_num\n\n\n\n\nShow Code\nX_train_num, imputer_num = numericalImputation(X_train_num, strategy='most_frequent')\nX_train_num.isna().sum()\n\n\ncompletion_year    0\nrooms              0\nparking            0\nbathroom           0\nsize_sqft          0\ndtype: int64\n\n\n\n\nShow Code\nimputer_num\n\n\nSimpleImputer(strategy='most_frequent')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SimpleImputerSimpleImputer(strategy='most_frequent')\n\n\n\n\n\n\n\nShow Code\nX_train_cat = X_train.select_dtypes(include='object')\nX_train_cat\n\n\n\n\n\n\n  \n    \n      \n      location\n      property_type\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      8649\n      Maju\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      9112\n      Bangsar\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      1472\n      Jalil\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      5536\n      Cheras\n      Condominium\n      Fully Furnished\n      no\n    \n    \n      8152\n      Pudu\n      Apartment\n      Partially Furnished\n      yes\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7541\n      Ampang\n      Apartment\n      Partially Furnished\n      NaN\n    \n    \n      7927\n      South\n      Flat\n      Not Furnished\n      NaN\n    \n    \n      5340\n      Cheras\n      Condominium\n      Partially Furnished\n      yes\n    \n    \n      1369\n      KLCC\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      3659\n      Road\n      Service Residence\n      Partially Furnished\n      NaN\n    \n  \n\n7825 rows × 4 columns\n\n\n\n\n\nShow Code\nX_train_cat.isna().sum()\n\n\nlocation              0\nproperty_type         0\nfurnished             0\nnearby_railways    2206\ndtype: int64\n\n\n\nImpute with mode\n\n\n\nShow Code\nX_train_cat, imputer_num = numericalImputation(X_train_cat, strategy='most_frequent')\nX_train_cat.isna().sum()\n\n\nlocation           0\nproperty_type      0\nfurnished          0\nnearby_railways    0\ndtype: int64\n\n\n\n\n\n\n\nShow Code\nX_train_cat_ohe =  pd.get_dummies(X_train_cat)\nX_train_cat_ohe.head(2)\n\n\n\n\n\n\n  \n    \n      \n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      location_Centre\n      location_Cheras\n      location_City\n      location_Damansara\n      location_Desa\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      8649\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n    \n      9112\n      0\n      1\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n  \n\n2 rows × 58 columns\n\n\n\n\n\nShow Code\nohe_columns = X_train_cat_ohe.columns\nohe_columns\n\n\nIndex(['location_Ampang', 'location_Bangsar', 'location_Besi',\n       'location_Bintang', 'location_Brickfields', 'location_Centre',\n       'location_Cheras', 'location_City', 'location_Damansara',\n       'location_Desa', 'location_Dutamas', 'location_Gombak',\n       'location_Hartamas', 'location_Heights', 'location_Hilir',\n       'location_Indah', 'location_Ipoh', 'location_Ismail', 'location_Jalil',\n       'location_Jaya', 'location_KLCC', 'location_Kepong', 'location_Keramat',\n       'location_Kiara', 'location_Kuching', 'location_Lama', 'location_Maju',\n       'location_Melawati', 'location_Menjalara', 'location_OUG',\n       'location_Pandan', 'location_Pantai', 'location_ParkCity',\n       'location_Perdana', 'location_Petaling', 'location_Puchong',\n       'location_Pudu', 'location_Road', 'location_Segambut',\n       'location_Selatan', 'location_Sentul', 'location_Seputeh',\n       'location_Setapak', 'location_Setiawangsa', 'location_South',\n       'location_Titiwangsa', 'property_type_Apartment',\n       'property_type_Condominium', 'property_type_Duplex',\n       'property_type_Flat', 'property_type_Others',\n       'property_type_Service Residence', 'property_type_Studio',\n       'furnished_Fully Furnished', 'furnished_Not Furnished',\n       'furnished_Partially Furnished', 'nearby_railways_no',\n       'nearby_railways_yes'],\n      dtype='object')\n\n\n\n\nShow Code\nX_train_cat_ohe.isna().sum()\n\n\nlocation_Ampang                    0\nlocation_Bangsar                   0\nlocation_Besi                      0\nlocation_Bintang                   0\nlocation_Brickfields               0\nlocation_Centre                    0\nlocation_Cheras                    0\nlocation_City                      0\nlocation_Damansara                 0\nlocation_Desa                      0\nlocation_Dutamas                   0\nlocation_Gombak                    0\nlocation_Hartamas                  0\nlocation_Heights                   0\nlocation_Hilir                     0\nlocation_Indah                     0\nlocation_Ipoh                      0\nlocation_Ismail                    0\nlocation_Jalil                     0\nlocation_Jaya                      0\nlocation_KLCC                      0\nlocation_Kepong                    0\nlocation_Keramat                   0\nlocation_Kiara                     0\nlocation_Kuching                   0\nlocation_Lama                      0\nlocation_Maju                      0\nlocation_Melawati                  0\nlocation_Menjalara                 0\nlocation_OUG                       0\nlocation_Pandan                    0\nlocation_Pantai                    0\nlocation_ParkCity                  0\nlocation_Perdana                   0\nlocation_Petaling                  0\nlocation_Puchong                   0\nlocation_Pudu                      0\nlocation_Road                      0\nlocation_Segambut                  0\nlocation_Selatan                   0\nlocation_Sentul                    0\nlocation_Seputeh                   0\nlocation_Setapak                   0\nlocation_Setiawangsa               0\nlocation_South                     0\nlocation_Titiwangsa                0\nproperty_type_Apartment            0\nproperty_type_Condominium          0\nproperty_type_Duplex               0\nproperty_type_Flat                 0\nproperty_type_Others               0\nproperty_type_Service Residence    0\nproperty_type_Studio               0\nfurnished_Fully Furnished          0\nfurnished_Not Furnished            0\nfurnished_Partially Furnished      0\nnearby_railways_no                 0\nnearby_railways_yes                0\ndtype: int64\n\n\n\n\nShow Code\nX_train_num.isna().sum()\n\n\ncompletion_year    0\nrooms              0\nparking            0\nbathroom           0\nsize_sqft          0\ndtype: int64\n\n\n\n\n\n\n\nShow Code\nX_train_concat = pd.concat([X_train_num,\n                            X_train_cat_ohe],\n                           axis = 1)\n\n\n\n\nShow Code\nX_train_concat.head(2)\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      8649\n      2021.0\n      2.0\n      1.0\n      1.0\n      800.0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n    \n      9112\n      1993.0\n      2.0\n      1.0\n      1.0\n      890.0\n      0\n      1\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n  \n\n2 rows × 63 columns\n\n\n\n\n\nShow Code\n#sanity check\nX_train_concat.isnull().sum()\n\n\ncompletion_year                  0\nrooms                            0\nparking                          0\nbathroom                         0\nsize_sqft                        0\n                                ..\nfurnished_Fully Furnished        0\nfurnished_Not Furnished          0\nfurnished_Partially Furnished    0\nnearby_railways_no               0\nnearby_railways_yes              0\nLength: 63, dtype: int64\n\n\n\n\n\n\n\nShow Code\nfrom sklearn.preprocessing import StandardScaler\n\n# Buat fungsi\ndef standardizerData(data):\n    \"\"\"\n    Fungsi untuk melakukan standarisasi data\n    :param data: <pandas dataframe> sampel data\n    :return standardized_data: <pandas dataframe> sampel data standard\n    :return standardizer: method untuk standardisasi data\n    \"\"\"\n    data_columns = data.columns  # agar nama kolom tidak hilang\n    data_index = data.index  # agar index tidak hilang\n\n    # buat (fit) standardizer\n    standardizer = StandardScaler()\n    standardizer.fit(data)\n\n    # transform data\n    standardized_data_raw = standardizer.transform(data)\n    standardized_data = pd.DataFrame(standardized_data_raw)\n    standardized_data.columns = data_columns\n    standardized_data.index = data_index\n\n    return standardized_data, standardizer\n\n\n\n\nShow Code\nX_train_clean, standardizer = standardizerData(data = X_train_concat)\n\n\n\n\nShow Code\nX_train_clean.head()\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      8649\n      0.541336\n      -0.971807\n      -0.542258\n      -1.813058\n      -0.530030\n      -0.189407\n      -0.068927\n      -0.137405\n      -0.102909\n      -0.048017\n      ...\n      -0.050621\n      -0.167279\n      -0.049336\n      -0.60979\n      -0.053098\n      1.072803\n      -0.406146\n      -0.805454\n      -0.619460\n      0.619460\n    \n    \n      9112\n      -3.913712\n      -0.971807\n      -0.542258\n      -1.813058\n      -0.190258\n      -0.189407\n      14.508152\n      -0.137405\n      -0.102909\n      -0.048017\n      ...\n      -0.050621\n      -0.167279\n      -0.049336\n      -0.60979\n      -0.053098\n      1.072803\n      -0.406146\n      -0.805454\n      -0.619460\n      0.619460\n    \n    \n      1472\n      0.541336\n      -2.288585\n      -0.542258\n      -1.813058\n      0.980069\n      -0.189407\n      -0.068927\n      -0.137405\n      -0.102909\n      -0.048017\n      ...\n      -0.050621\n      -0.167279\n      -0.049336\n      -0.60979\n      -0.053098\n      1.072803\n      -0.406146\n      -0.805454\n      -0.619460\n      0.619460\n    \n    \n      5536\n      0.541336\n      0.344970\n      1.685126\n      0.150837\n      -0.178932\n      -0.189407\n      -0.068927\n      -0.137405\n      -0.102909\n      -0.048017\n      ...\n      -0.050621\n      -0.167279\n      -0.049336\n      -0.60979\n      -0.053098\n      1.072803\n      -0.406146\n      -0.805454\n      1.614308\n      -1.614308\n    \n    \n      8152\n      0.541336\n      0.344970\n      -0.542258\n      0.150837\n      0.149515\n      -0.189407\n      -0.068927\n      -0.137405\n      -0.102909\n      -0.048017\n      ...\n      -0.050621\n      -0.167279\n      -0.049336\n      -0.60979\n      -0.053098\n      -0.932137\n      -0.406146\n      1.241535\n      -0.619460\n      0.619460\n    \n  \n\n5 rows × 63 columns\n\n\n\n\n\n\n\nSince this is a regression model, R2 score and mean absolute error (MAE) will be used as a performance metrics.\nThe machine learning model will use baseline from average value of the target columns (monthly rent) and also result from linear regression model. After that, author used some of the recommended model based on previous works, which are random forest and gradient boosting to better improve the performance of the model.\n\n\nThe concept here is to use average value of the target as the easiest way to predict the monhtly rent of a unit.\n\n\nShow Code\ny_baseline = np.ones(len(y_train)) * y_train.mean()\ny_baseline\n\n\narray([1780.0086901, 1780.0086901, 1780.0086901, ..., 1780.0086901,\n       1780.0086901, 1780.0086901])\n\n\n\n\nShow Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# Train the linear regression model\nlin_reg = LinearRegression().fit(X_train_clean, y_train)\n\n# Predict using the train data\ny_pred_train = y_baseline\n\n# Calculate R-squared\nr2_baseline = r2_score(y_train, y_pred_train)\n\n#calculate MAE\nmae_baseline = mean_absolute_error(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_baseline:.4f} and MAE score: {mae_baseline:.4f}\")\n\n\nR2-score: 0.0000 and MAE score: 562.3710\n\n\n\n\nShow Code\nplt.scatter(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\n\nThe second method is using linear regression, which simply put is finding the minum total error (distance) between predicted value and the target value, using linear equation.\n\n\nShow Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Train the linear regression model\nlin_reg = LinearRegression().fit(X_train_clean, y_train)\n\n# Predict using the train data\n# y_pred = y_baseline\ny_pred_train = lin_reg.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_linreg = mean_absolute_error(y_train, y_pred_train)\n\n# Calculate R-squared\nr2_linreg = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_linreg:.4f} and MAE score: {mae_linreg:.4f}\")\n\n\nR2-score: 0.6468 and MAE score: 319.2229\n\n\n\n\nShow Code\nsns.jointplot(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\n\nThe gradient boosting, is one of the recommendation from previous works, is a model where each sample would be given a different weights (boosts) depending on its performance in predicting the value/ target.\n\n\nShow Code\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Build random forest\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\n\n\n\nShow Code\n# Fit random forest\ngrad_tree.fit(X_train_clean, y_train)\n\n\nGradientBoostingRegressor(random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GradientBoostingRegressorGradientBoostingRegressor(random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train = grad_tree.predict(X_train_clean)\n# y_pred_test = grad_tree.predict(X_test_clean)\n\n# Calculate mean absolute error\nmae_gb = mean_absolute_error(y_train, y_pred_train)\n\n# Calculate R-squared\nr2_gb = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_gb:.4f} and MAE score: {mae_gb:.4f}\")\n\n\nR2-score: 0.7246 and MAE score: 281.6835\n\n\n\n\nShow Code\nsns.jointplot(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\nShow Code\n#gridsearch\n\nfrom sklearn.model_selection import GridSearchCV \n\n\nparams = {'n_estimators': [100, 200, 300, 400, 500],\n              'learning_rate': [0.1, 0.05, 0.01]}\n\n# Buat gridsearch\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\ngrad_tree_cv = GridSearchCV(estimator = grad_tree,\n                           param_grid = params,\n                           cv = 5,\n                           scoring = \"neg_mean_absolute_error\")\n\n\n\n\nShow Code\n# Fit grid search cv\ngrad_tree_cv.fit(X_train_clean, y_train)\n\n\nGridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=123),\n             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n                         'n_estimators': [100, 200, 300, 400, 500]},\n             scoring='neg_mean_absolute_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=123),\n             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n                         'n_estimators': [100, 200, 300, 400, 500]},\n             scoring='neg_mean_absolute_error')estimator: GradientBoostingRegressorGradientBoostingRegressor(random_state=123)GradientBoostingRegressorGradientBoostingRegressor(random_state=123)\n\n\n\n\nShow Code\n# Best params\ngrad_tree_cv.best_params_\n\n\n{'learning_rate': 0.1, 'n_estimators': 500}\n\n\n\n\nShow Code\n# Refit the Adaboost\ngrad_tree = GradientBoostingRegressor(n_estimators = grad_tree_cv.best_params_[\"n_estimators\"],\n                                      random_state = 123)\n\ngrad_tree.fit(X_train_clean, y_train)\n\n\nGradientBoostingRegressor(n_estimators=500, random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GradientBoostingRegressorGradientBoostingRegressor(n_estimators=500, random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train = grad_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_gb_cv = mean_absolute_error(y_train, y_pred_train)\n\n# Calculate R-squared\nr2_gb_cv = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_gb_cv:.4f} and MAE score: {mae_gb_cv:.4f}\")\n\n\nR2-score: 0.8194 and MAE score: 228.0225\n\n\n\n\nShow Code\nsns.jointplot(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\n\nThe last model, which was also recommended by previous works, is a model where not only it has weights based on its performance, but the feature selection in which the sample is measured was done at random. Therefore, reduces not only the variance, but also the bias.\n\n\nShow Code\nfrom sklearn.ensemble import RandomForestRegressor\n\n\n\n\nShow Code\n# Build random forest\nrf_tree = RandomForestRegressor(n_estimators = 100,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n\n\n\nShow Code\n# Fit random forest\nrf_tree.fit(X_train_clean, y_train)\n\n\nRandomForestRegressor(max_features='sqrt', random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_features='sqrt', random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf = mean_absolute_error(y_train, y_pred_train)\n\n# Calculate R-squared\nr2_rf = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_rf:.4f} and MAE score: {mae_rf:.4f}\")\n\n\nR2-score: 0.9577 and MAE score: 100.8408\n\n\n\n\nShow Code\nsns.jointplot(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\nShow Code\nparams = {\"n_estimators\": [100, 200, 300, 500 ],\n          \"max_features\": [\"sqrt\", \"log2\"]}\n\n# Buat gridsearch\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                random_state = 123)\n\nrf_tree_cv = GridSearchCV(estimator = rf_tree,\n                          param_grid = params,\n                          cv = 5,\n                          scoring = \"neg_mean_absolute_error\")\n\n\n\n\nShow Code\n# Fit grid search cv\nrf_tree_cv.fit(X_train_clean, y_train)\n\n\nGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=123),\n             param_grid={'max_features': ['sqrt', 'log2'],\n                         'n_estimators': [100, 200, 300, 500]},\n             scoring='neg_mean_absolute_error')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GridSearchCVGridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=123),\n             param_grid={'max_features': ['sqrt', 'log2'],\n                         'n_estimators': [100, 200, 300, 500]},\n             scoring='neg_mean_absolute_error')estimator: RandomForestRegressorRandomForestRegressor(random_state=123)RandomForestRegressorRandomForestRegressor(random_state=123)\n\n\n\n\nShow Code\n# Best params\nrf_tree_cv.best_params_\n\n\n{'max_features': 'sqrt', 'n_estimators': 500}\n\n\n\n\nShow Code\n# Refit the Random Forest\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                max_features = rf_tree_cv.best_params_[\"max_features\"],\n                                n_estimators = rf_tree_cv.best_params_[\"n_estimators\"],\n                                random_state = 123)\n\nrf_tree.fit(X_train_clean, y_train)\n\n\nRandomForestRegressor(max_features='sqrt', n_estimators=500, random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_features='sqrt', n_estimators=500, random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf_cv = mean_absolute_error(y_train, y_pred_train)\n\n# # Calculate R-squared\nr2_rf_cv = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_rf_cv:.4f} and MAE score: {mae_rf_cv:.4f}\")\n\n\nR2-score: 0.9585 and MAE score: 99.7989\n\n\n\n\nShow Code\nsns.jointplot(x=y_train, y=y_pred_train);\n\n\n\n\n\n\n\nShow Code\nmae_score = [mae_baseline, mae_linreg, mae_gb, mae_gb_cv, mae_rf, mae_rf_cv]\nr2_score = [r2_baseline, r2_linreg, r2_gb, r2_gb_cv, r2_rf, r2_rf_cv]\nindexes = [\"baseline\", \"linear regression\", \"gradient boosting\", \"gradient boosting with CV\", \"random forest\",  \"random forest with CV\"]\n\nsummary_df = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\nsummary_df.sort_values(by='R2-Score', ascending=False)\n\n\n\n\n\n\n  \n    \n      \n      MAE Train\n      R2-Score\n    \n  \n  \n    \n      random forest with CV\n      99.798879\n      0.958519\n    \n    \n      random forest\n      100.840759\n      0.957661\n    \n    \n      gradient boosting with CV\n      228.022510\n      0.819416\n    \n    \n      gradient boosting\n      281.683477\n      0.724601\n    \n    \n      linear regression\n      319.222873\n      0.646780\n    \n    \n      baseline\n      562.370983\n      0.000000\n    \n  \n\n\n\n\nFrom the above table, it can be seen that Random Forest model performs the best, and Gradient Boosting at the second place. This is similar to the previous work done by others, on house pricing.\n\n\n\n\n\n\nShow Code\n# libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n#setting up\nrf_tree = RandomForestRegressor(n_estimators = 500,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n#fit model train\nrf_tree.fit(X_train_clean, y_train)\n\n# Predict model train\ny_pred_train = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf_cv_train = mean_absolute_error(y_train, y_pred_train)\n\n# # Calculate R-squared\nr2_rf_cv_train = r2_score(y_train, y_pred_train)\n\nprint(f\"R2-score: {r2_rf_cv_train:.3f} and MAE score: +/-{mae_rf_cv_train:.2f} RM\")\n\nsns.scatterplot(x=y_train, y=y_pred_train )\nplt.plot([0, 5500], [0,5500], \"--r\")\nplt.xlim(0, 5500)\nplt.xlabel(\"Actual Monthly Rent\")\nplt.ylim(0,5500)\nplt.ylabel(\"Predicted Monthly Rent\")\nplt.suptitle(\"Random Forest - Best Regression Model\")\nplt.show()\n\n\nR2-score: 0.959 and MAE score: +/-99.80 RM"
  },
  {
    "objectID": "posts/005-webscraping-machinelearning-rent-pricing/index.html#data-prediction",
    "href": "posts/005-webscraping-machinelearning-rent-pricing/index.html#data-prediction",
    "title": "Malaysia Property Pricing - Webscraping & Machine Learning Model",
    "section": "Data Prediction",
    "text": "Data Prediction\n\nTest Data Preprocessing\nSimlar process done in train dataset need to be repeated on test dataset.\n\n\nShow Code\n#checking null data\nX_test.isna().sum()\n\n\ncompletion_year    834\nlocation             0\nproperty_type        0\nrooms                0\nparking            506\nbathroom             0\nsize_sqft            0\nfurnished            0\nnearby_railways    552\ndtype: int64\n\n\n\nNumerical Data\n\n\nShow Code\nX_test_num =  X_test.select_dtypes(exclude='object')\nX_test_num\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n    \n  \n  \n    \n      324\n      NaN\n      3.0\n      NaN\n      2.0\n      1097\n    \n    \n      7209\n      2011.0\n      4.0\n      2.0\n      3.0\n      1200\n    \n    \n      1863\n      NaN\n      2.0\n      NaN\n      1.0\n      560\n    \n    \n      2443\n      2021.0\n      3.0\n      1.0\n      2.0\n      1200\n    \n    \n      9218\n      2023.0\n      1.0\n      2.0\n      2.0\n      300\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7510\n      2008.0\n      3.0\n      1.0\n      2.0\n      1204\n    \n    \n      928\n      2013.0\n      1.0\n      NaN\n      1.0\n      350\n    \n    \n      2181\n      2019.0\n      1.0\n      1.0\n      1.0\n      653\n    \n    \n      4065\n      NaN\n      2.0\n      NaN\n      2.0\n      600\n    \n    \n      9041\n      2021.0\n      3.0\n      NaN\n      2.0\n      800\n    \n  \n\n1957 rows × 5 columns\n\n\n\n\n\nShow Code\nX_test_num.isna().sum()\n\n\ncompletion_year    834\nrooms                0\nparking            506\nbathroom             0\nsize_sqft            0\ndtype: int64\n\n\n\n\nShow Code\nX_test_num, imputer_num = numericalImputation(X_test_num, strategy='most_frequent')\nX_test_num.isna().sum()\n\n\ncompletion_year    0\nrooms              0\nparking            0\nbathroom           0\nsize_sqft          0\ndtype: int64\n\n\n\n\nCategorical Data\n\n\nShow Code\nX_test_cat = X_test.select_dtypes(include='object')\nX_test_cat\n\n\n\n\n\n\n  \n    \n      \n      location\n      property_type\n      furnished\n      nearby_railways\n    \n  \n  \n    \n      324\n      South\n      Condominium\n      Partially Furnished\n      no\n    \n    \n      7209\n      KLCC\n      Condominium\n      Fully Furnished\n      NaN\n    \n    \n      1863\n      Maju\n      Flat\n      Not Furnished\n      NaN\n    \n    \n      2443\n      Lama\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      9218\n      Cheras\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      7510\n      Setiawangsa\n      Condominium\n      Fully Furnished\n      yes\n    \n    \n      928\n      Road\n      Condominium\n      Fully Furnished\n      NaN\n    \n    \n      2181\n      Segambut\n      Service Residence\n      Fully Furnished\n      no\n    \n    \n      4065\n      Lama\n      Apartment\n      Not Furnished\n      no\n    \n    \n      9041\n      Setapak\n      Condominium\n      Partially Furnished\n      yes\n    \n  \n\n1957 rows × 4 columns\n\n\n\n\n\nShow Code\nX_test_cat.isna().sum()\n\n\nlocation             0\nproperty_type        0\nfurnished            0\nnearby_railways    552\ndtype: int64\n\n\n\n\nShow Code\nX_test_cat, imputer_num = numericalImputation(X_test_cat, strategy='most_frequent')\nX_test_cat.isna().sum()\n\n\nlocation           0\nproperty_type      0\nfurnished          0\nnearby_railways    0\ndtype: int64\n\n\n\n\nCategorical OHE\n\n\nShow Code\nX_test_cat_ohe =  pd.get_dummies(X_test_cat)\nX_test_cat_ohe.head(2)\n\n\n\n\n\n\n  \n    \n      \n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      location_Centre\n      location_Cheras\n      location_City\n      location_Damansara\n      location_Desa\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      324\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n    \n    \n      7209\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n  \n\n2 rows × 58 columns\n\n\n\n\n\nShow Code\nohe_columns = X_test_cat_ohe.columns\nohe_columns\n\n\nIndex(['location_Ampang', 'location_Bangsar', 'location_Besi',\n       'location_Bintang', 'location_Brickfields', 'location_Centre',\n       'location_Cheras', 'location_City', 'location_Damansara',\n       'location_Desa', 'location_Dutamas', 'location_Gombak',\n       'location_Hartamas', 'location_Heights', 'location_Hilir',\n       'location_Indah', 'location_Ipoh', 'location_Ismail', 'location_Jalil',\n       'location_Jaya', 'location_KLCC', 'location_Kepong', 'location_Keramat',\n       'location_Kiara', 'location_Kuching', 'location_Lama', 'location_Maju',\n       'location_Melawati', 'location_Menjalara', 'location_OUG',\n       'location_Pandan', 'location_Pantai', 'location_ParkCity',\n       'location_Perdana', 'location_Petaling', 'location_Puchong',\n       'location_Pudu', 'location_Road', 'location_Segambut',\n       'location_Selatan', 'location_Sentul', 'location_Seputeh',\n       'location_Setapak', 'location_Setiawangsa', 'location_South',\n       'location_Titiwangsa', 'property_type_Apartment',\n       'property_type_Condominium', 'property_type_Duplex',\n       'property_type_Flat', 'property_type_Others',\n       'property_type_Service Residence', 'property_type_Studio',\n       'furnished_Fully Furnished', 'furnished_Not Furnished',\n       'furnished_Partially Furnished', 'nearby_railways_no',\n       'nearby_railways_yes'],\n      dtype='object')\n\n\n\n\n\nPenggabungan Numerical dan Categorical data\n\n\nShow Code\nX_test_concat = pd.concat([X_test_num,\n                            X_test_cat_ohe],\n                           axis = 1)\n\n\n\n\nShow Code\nX_test_concat.head(2)\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      324\n      2021.0\n      3.0\n      1.0\n      2.0\n      1097.0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      0\n      0\n      1\n      1\n      0\n    \n    \n      7209\n      2011.0\n      4.0\n      2.0\n      3.0\n      1200.0\n      0\n      0\n      0\n      0\n      0\n      ...\n      0\n      0\n      0\n      0\n      0\n      1\n      0\n      0\n      0\n      1\n    \n  \n\n2 rows × 63 columns\n\n\n\n\n\nShow Code\n#sanity check\nX_test_concat.isnull().sum()\n\n\ncompletion_year                  0\nrooms                            0\nparking                          0\nbathroom                         0\nsize_sqft                        0\n                                ..\nfurnished_Fully Furnished        0\nfurnished_Not Furnished          0\nfurnished_Partially Furnished    0\nnearby_railways_no               0\nnearby_railways_yes              0\nLength: 63, dtype: int64\n\n\n\nStandarisasi\n\n\nShow Code\nfrom sklearn.preprocessing import StandardScaler\n\n# Buat fungsi\ndef standardizerData(data):\n    \"\"\"\n    Fungsi untuk melakukan standarisasi data\n    :param data: <pandas dataframe> sampel data\n    :return standardized_data: <pandas dataframe> sampel data standard\n    :return standardizer: method untuk standardisasi data\n    \"\"\"\n    data_columns = data.columns  # agar nama kolom tidak hilang\n    data_index = data.index  # agar index tidak hilang\n\n    # buat (fit) standardizer\n    standardizer = StandardScaler()\n    standardizer.fit(data)\n\n    # transform data\n    standardized_data_raw = standardizer.transform(data)\n    standardized_data = pd.DataFrame(standardized_data_raw)\n    standardized_data.columns = data_columns\n    standardized_data.index = data_index\n\n    return standardized_data, standardizer\n\n\n\n\nShow Code\nX_test_clean, standardizer = standardizerData(data = X_test_concat)\n\n\n\n\nShow Code\nX_test_clean.head()\n\n\n\n\n\n\n  \n    \n      \n      completion_year\n      rooms\n      parking\n      bathroom\n      size_sqft\n      location_Ampang\n      location_Bangsar\n      location_Besi\n      location_Bintang\n      location_Brickfields\n      ...\n      property_type_Duplex\n      property_type_Flat\n      property_type_Others\n      property_type_Service Residence\n      property_type_Studio\n      furnished_Fully Furnished\n      furnished_Not Furnished\n      furnished_Partially Furnished\n      nearby_railways_no\n      nearby_railways_yes\n    \n  \n  \n    \n      324\n      0.552642\n      0.320875\n      -0.541910\n      0.124936\n      0.555078\n      -0.168453\n      -0.071667\n      -0.120479\n      -0.09361\n      -0.055456\n      ...\n      -0.059914\n      -0.161923\n      -0.059914\n      -0.60234\n      -0.045256\n      -0.949656\n      -0.368524\n      1.208981\n      1.563785\n      -1.563785\n    \n    \n      7209\n      -0.958283\n      1.620985\n      1.505421\n      2.112746\n      0.933643\n      -0.168453\n      -0.071667\n      -0.120479\n      -0.09361\n      -0.055456\n      ...\n      -0.059914\n      -0.161923\n      -0.059914\n      -0.60234\n      -0.045256\n      1.053013\n      -0.368524\n      -0.827143\n      -0.639474\n      0.639474\n    \n    \n      1863\n      0.552642\n      -0.979234\n      -0.541910\n      -1.862873\n      -1.418602\n      -0.168453\n      -0.071667\n      -0.120479\n      -0.09361\n      -0.055456\n      ...\n      -0.059914\n      6.175759\n      -0.059914\n      -0.60234\n      -0.045256\n      -0.949656\n      2.713531\n      -0.827143\n      -0.639474\n      0.639474\n    \n    \n      2443\n      0.552642\n      0.320875\n      -0.541910\n      0.124936\n      0.933643\n      -0.168453\n      -0.071667\n      -0.120479\n      -0.09361\n      -0.055456\n      ...\n      -0.059914\n      -0.161923\n      -0.059914\n      -0.60234\n      -0.045256\n      1.053013\n      -0.368524\n      -0.827143\n      -0.639474\n      0.639474\n    \n    \n      9218\n      0.854826\n      -2.279344\n      1.505421\n      0.124936\n      -2.374201\n      -0.168453\n      -0.071667\n      -0.120479\n      -0.09361\n      -0.055456\n      ...\n      -0.059914\n      -0.161923\n      -0.059914\n      -0.60234\n      -0.045256\n      1.053013\n      -0.368524\n      -0.827143\n      -0.639474\n      0.639474\n    \n  \n\n5 rows × 63 columns\n\n\n\n\n\n\nTest Data Result\n\n\nShow Code\n# libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n#setting up\nrf_tree = RandomForestRegressor(n_estimators = 500,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n#fit model train\nrf_tree.fit(X_train_clean, y_train)\n\n# Predict model\ny_pred_test = rf_tree.predict(X_test_clean)\n\n# Calculate mean absolute error\nmae_rf_cv_test = mean_absolute_error(y_test, y_pred_test)\n\n# # Calculate R-squared\nr2_rf_cv_test = r2_score(y_test, y_pred_test)\n\nprint(f\"R2-score: {r2_rf_cv_test:.3f} and MAE score: +/-{mae_rf_cv_test:.2f} RM\")\n\nsns.scatterplot(x=y_test, y=y_pred_test )\nplt.plot([0, 5500], [0,5500], \"--r\")\nplt.xlim(0, 5500)\nplt.xlabel(\"Actual Monthly Rent\")\nplt.ylim(0,5500)\nplt.ylabel(\"Predicted Monthly Rent\")\nplt.suptitle(\"Random Forest - Best Regression Model\")\nplt.show()\n\n\nR2-score: 0.803 and MAE score: +/-214.08 RM\n\n\n\n\n\n\n\nShow Code\nmae_score = [mae_rf_cv_train, mae_rf_cv_test]\nr2_score = [r2_rf_cv_train, r2_rf_cv_test]\nindexes = [\"train\", \"test\"]\n\nsummary_df_train_test = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\nsummary_df_train_test\n\n\n\n\n\n\n  \n    \n      \n      MAE Train\n      R2-Score\n    \n  \n  \n    \n      train\n      99.798879\n      0.958519\n    \n    \n      test\n      214.084111\n      0.802556\n    \n  \n\n\n\n\n\nFeature Importance\n\n\nShow Code\n# calculate the feature importances\nimportances = rf_tree.feature_importances_\n\n# rescale the importances back to the original scale of the features\nimportances = importances * X_train_clean.std()\n\n# sort the feature importances in descending order\nsorted_index = importances.argsort()[::-1]\n\n# print the feature importances\ndict_feature_importance = {}\nfor i in sorted_index:\n    # print(\"{}: {}\".format(X_train_clean.columns[i], importances[i]))\n    dict_feature_importance.update({X_train_clean.columns[i]: importances[i]})\n    \n# Create a DataFrame from the dictionary\ndf = pd.DataFrame.from_dict(dict_feature_importance, orient='index', columns=['values'])\n\n# Reset the index to become a column\ndf = df.reset_index()\n\n# Rename the columns\ndf.columns = ['feature', 'importance_value']\n\ndf.sort_values(by='importance_value', ascending=False).head(10)\n\n\n\n\n\n\n  \n    \n      \n      feature\n      importance_value\n    \n  \n  \n    \n      0\n      size_sqft\n      0.227595\n    \n    \n      1\n      furnished_Fully Furnished\n      0.106722\n    \n    \n      2\n      completion_year\n      0.073598\n    \n    \n      3\n      bathroom\n      0.059699\n    \n    \n      4\n      rooms\n      0.046285\n    \n    \n      5\n      parking\n      0.045606\n    \n    \n      6\n      location_Kiara\n      0.042962\n    \n    \n      7\n      furnished_Not Furnished\n      0.040320\n    \n    \n      8\n      location_KLCC\n      0.037287\n    \n    \n      9\n      furnished_Partially Furnished\n      0.036137\n    \n  \n\n\n\n\n\n\n\nResults\n\nResult indicates that the best model for prediction is Random Forest with hyperparameter tuning, scoring 95% on R2-score, and a shy 100 RM on MAE. This proves to be a good model since the test dataset gives a scoring of 80% on R2, and 240 RM on MAE.\nThere are some factors that author believed to be affecting the result/ performance of the model:\n\nDropping missing value reduces the performance! Initial model uses half of the data (4-5k rows) and gives poorer performance on R2 and MAE. Imputation and keeping the number of rows close to the original dataset (9k rows) proves to be improving the model. Especially on test dataset.\nFeature selection importance can be seen on the last table, but initially the selection was based on paper and intuition of the author (author lives and work in KL, Malaysia for 5 years). Feature such as completion_year and nearby_railways are important in improving the model.\nLast but not least is the outlier identification. The best practice for me is using jointplot to see not only the distribution of the data in 2-dimension, but also in the third dimension (the density) of the data.\n\nSome of the feature that were believed to be quite important even before doing the modeling is size, furnished and location. All three is available within the 10-most features affecting the modeling. As a context, location in KLCC is like Pondok Indah in South Jakarta. Location in Kiara is like BSD in South Tangerang.\n\n\n\nDiscussions\n\nOne of the feature that author thinks is significant but not appearing on the 10-best important feature is nearby_railways. This column is showing if a certain property has a close proximity to a railways (KTM/LRT). The issue is, half of the data is missing, hence the imputation. Author belives, the proximity to nearby railways line can be approximated using manhanttan distance of railways line to each property unit."
  },
  {
    "objectID": "posts/002-migrating-to-quarto/index.html",
    "href": "posts/002-migrating-to-quarto/index.html",
    "title": "Migrating My Personal Blog to Quarto",
    "section": "",
    "text": "Photo by Kelly Sikkema on Unsplash\n\n\n\n\nStatic Website Triumph\nStatic website is a website built upon a pre-rendered html generated from markdown. Static website triumph because the markdown format makes it easier for writing (at least for me), offered flexibility to write Latex to write equation like \\(\\frac{4}{3}\\pi r^3\\), a code block like this, or below, which makes it suitable for blog about programming/ data science.\n\nprint(\"Hey There!\")\n\nThe simplicity makes it easier to pour your words into sentences, sentences into a paragraph. You can focus about writing the content you want to write, instead of fiddling around about CMS. 1\nMy first personal website was initially built using jekyll-theme. I think the looks of the website is quite nice, given how easy for me to just forking the repo and making it my own. The theme is from al-folio theme, and by default it was designed for academic, supporting CV, list of publications (which handling bibtex better than Quarto at the moment), and of course blogging with categories, etc.\nI was convinced that static website is the way to go for me, but Jekyll-based theme is not as friendly-used as I thought It would be. For once, it uses Ruby Gem, which I am not familiar with and frankly the development is rather behind other languange. That means you have less change of finding answer online, compared to other language.\n\n\n\n\n\n\nTip\n\n\n\nI had multiple occasions where I just undo the whole thing, because when I ran bundle exec jekyll serve, it won’t render. Some dependencies issue, etc. Personally, if you plan to add more content to your blog, I would look the other way.\n\n\n\n\nQuarto by Posit 2\nEnter Rstudio Conference 2022, where a good amount of people gather in annual meeting for R-people. Among other important announcement (including changing their name to Posit, they introduced Quarto, an open source project to bring scientific communications easier and more inclusive.\nWhat is good about Quarto is it combines what was good about Rmarkdown, and make it more inclusive (as it drops the R from its name). Even more, the compatibility to pandoc engine, makes it easier to convert it from and to other format, this includes jupyter notebook, which is a huge plus for me. Mainly because I worked primarily in python, and the fact that I can work on jupyter notebook, do EDA, and when I am ready to post I just have to render the file before upload it to the website is godsend.\n\n\n\n\n\n\nNote\n\n\n\nIn order to make an .ipynb file can be rendered by quarto, it has to provide two things. One is the raw cell where the frontmatter (first cell in the image below) is, and second is the frontmatter has to specify which kernel/ jupyter would it use (mine is set to python3). See example image below, or read the docs for python for details.\n\n\n\n\nJupyter lab Example\n\n\n\nIf you prefer a tutorial video, I highly recommend Isabella’s video, in which she show some practical step-by-step when making a blog using quarto. \nNot only that, quarto allows use to generate multiple format from presentation (revealjs, pptx), article, report in pdf or docx, easily from a single markdown .qmd file. I’d probably write a post explaining about that in the future. Perhaps diagram below would simplify why I liked Quarto flexibility.\n\n\nShow Code\nflowchart LR\n  A[.ipynb] --> B(.qmd)\n  B --> C{quarto render}\n  C --> D[.html]\n  C --> E[.pdf]\n  C --> F[.docx, .revealjs, etc]\n\n\n\n\nflowchart LR\n  A[.ipynb] --> B(.qmd)\n  B --> C{quarto render}\n  C --> D[.html]\n  C --> E[.pdf]\n  C --> F[.docx, .revealjs, etc]\n\n\n\n\n\n\n\n\nLastly, and here is my most favourite part (believe it or not) is the code block allows for copy and paste button! I tried to create a code block in my previous blog, and it just grey rectangular with no copy-paste button. I think this is an essential feature, as the theme is reproducible science. You wanted the minimize the barrier as low as possible, and this will definitely help.\n\n\n\nWhat Quarto Lacks\nThe good thing about quarto (simplicity) can be a cons for some people. When comparing to my previous website built on Jekyll, the default theme quality is still subpar. I need to do some personal tweaks to make it more appealing visually. Luckily, you don’t have to invent the wheel, as there are several blogs I used as inspirations for their custom theme. Below are some of my favourite authors, in no particular order.\n\nIsabella\nDanielle Navvaro\nTom Mock\nMatt Worthington\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use their website repo as inspiration, on how they change the font theme, size, page layout, blog setting, color theme. Pay attention to their _quarto.yml and theme.scss!\n\n\nLast but not least, the quarto project is still under heavy development. Quarto extension, some pre-release build version adding more capability 3, etc.\n\n\nHiccups and Hopes for Future Development\nI still have some issues when rendering a quarto markdown file (.qmd) with both R and python code.\nAnother error I have is when rendering to pdf due to tinytex installation issue 4. Which was apparently solved just by installing new pre-released version.\n\n\n\n\n\n\nTo recap, I extremely happy how my personal website turns out to be, and knowing that the project was supported by one of the most respected company in data-tech industry, I am hopeful about the future. Do try it out when you can!\n\n\n\nTill next time~ Arie\n\n\n\n\n\nFootnotes\n\n\nThis is one of the thing I am struggling when trying wordpress.↩︎\nPreviously R Studio. Read the announcement↩︎\nQuarto 1.2 pre-released version supports embedding video from Youtube.↩︎\nIssue in Quarto 1.1↩︎\n\nCitationBibTeX citation:@online{ariewijaya2022,\n  author = {Aditya Arie Wijaya},\n  title = {Migrating {My} {Personal} {Blog} to {Quarto}},\n  date = {2022-10-21},\n  url = {ariewjy.github.io/posts/002-migrating-to-quarto},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAditya Arie Wijaya. 2022. “Migrating My Personal Blog to\nQuarto.” October 21, 2022. ariewjy.github.io/posts/002-migrating-to-quarto."
  },
  {
    "objectID": "posts/004-webscraping-indonesia-national-exam/index.html",
    "href": "posts/004-webscraping-indonesia-national-exam/index.html",
    "title": "Webscraping National Exams of Indonesia",
    "section": "",
    "text": "Photo by Ed Us on Unsplash"
  },
  {
    "objectID": "posts/004-webscraping-indonesia-national-exam/index.html#the-role-of-national-exam",
    "href": "posts/004-webscraping-indonesia-national-exam/index.html#the-role-of-national-exam",
    "title": "Webscraping National Exams of Indonesia",
    "section": "The Role of National Exam",
    "text": "The Role of National Exam\nFor the longest time, national exam, like many other countries in the world is used as one of the metric to measure how well our future would be (re: children). The concept is simple, each and every children in the country will be given a set of questions/ tasks, that has to be completed for a given time, on different subjects (likely to be Math, Language, Science).\n\n\nIndonesia Minister of Education\n\n\n\nIn Indonesia, this was used to be the sole metric to say if one student passed the exam or not. This has been changed ever since the newly appointed education minister of Indonesia, Nadiem Makarim (also the co-founder of SE Asia Decacorn- Gojek, Now GoTo). Nevertheless, it is interesting to see how this metric pan out over the course of 2015-2019, to see if the decentralized quality of education still persist in Java, Bali and its surrounding only. Leaving out Kalimantan, Sulawesi, Sumatra, NTT, and Papua."
  },
  {
    "objectID": "posts/004-webscraping-indonesia-national-exam/index.html#data-gathering",
    "href": "posts/004-webscraping-indonesia-national-exam/index.html#data-gathering",
    "title": "Webscraping National Exams of Indonesia",
    "section": "Data Gathering",
    "text": "Data Gathering\n\nWebscraping using Pandas\nWe’re taking a look on the data from Ministry of Education (Kemendikbud), from 2019 on national exams as follows.\nFor this use we will need to scrape the data from the website, but the catch is–we are using just pandas library!\n\n\nShow Code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\nEnter pandas.read_html()\n\n\nShow Code\nun_2019= \\\n(pd\n .read_html('https://npd.kemdikbud.go.id/?appid=hasilun&tahun=2019')\n [1][0:547]\n)\n\nun_2019.head()\n\n\n\n\n\n\n  \n    \n      \n      No.\n      Kode Wilayah\n      Nama Wilayah\n      Propinsi\n      Persentase Anggaran Pendidikan tanpa Transfer Daerah (%)\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n      UN SMA BAHASA\n      UN SMK\n      IIUN SMP\n      IIUN SMA IPA\n      IIUN SMA IPS\n      IIUN SMA BAHASA\n      IIUN SMK\n    \n  \n  \n    \n      0\n      1\n      010000\n      Prov. D.K.I. Jakarta\n      Prov. D.K.I. Jakarta\n      18.96\n      62.17\n      67.99\n      63.75\n      0\n      51.41\n      100\n      100\n      100\n      0\n      100\n    \n    \n      1\n      2\n      010100\n      Kab. Kepulauan Seribu\n      Prov. D.K.I. Jakarta\n      0.00\n      45.26\n      0\n      0\n      0\n      0\n      100\n      0\n      0\n      0\n      0\n    \n    \n      2\n      3\n      016000\n      Kota Jakarta Pusat\n      Prov. D.K.I. Jakarta\n      0.00\n      60.97\n      69.43\n      64.01\n      0\n      55.13\n      100\n      100\n      100\n      0\n      100\n    \n    \n      3\n      4\n      016100\n      Kota Jakarta Utara\n      Prov. D.K.I. Jakarta\n      0.00\n      60.09\n      66.59\n      61.53\n      0\n      48.85\n      100\n      100\n      100\n      0\n      100\n    \n    \n      4\n      5\n      016200\n      Kota Jakarta Barat\n      Prov. D.K.I. Jakarta\n      0.00\n      60.42\n      69.31\n      63.85\n      0\n      49.65\n      100\n      100\n      100\n      0\n      100\n    \n  \n\n\n\n\nLet’s see what features do we have, and which one do we really care about in this project.\n\n\nShow Code\nun_2019.columns\n\n\nIndex(['No.', 'Kode Wilayah', 'Nama Wilayah', 'Propinsi',\n       'Persentase Anggaran Pendidikan tanpa Transfer Daerah (%)', 'UN SMP',\n       'UN SMA IPA', 'UN SMA IPS', 'UN SMA BAHASA', 'UN SMK', 'IIUN SMP',\n       'IIUN SMA IPA', 'IIUN SMA IPS', 'IIUN SMA BAHASA', 'IIUN SMK'],\n      dtype='object')\n\n\nWe will leave some columns and just using region information (‘Nama Wilayah’, ‘Propinsi’), and national exams score (‘UN SMP’,‘UN SMA IPA’, ‘UN SMA IPS’)\n\n\nShow Code\nun_2019 = un_2019[['Nama Wilayah', 'Propinsi', 'UN SMP','UN SMA IPA', 'UN SMA IPS']]\nun_2019.head()\n\n\n\n\n\n\n  \n    \n      \n      Nama Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n    \n  \n  \n    \n      0\n      Prov. D.K.I. Jakarta\n      Prov. D.K.I. Jakarta\n      62.17\n      67.99\n      63.75\n    \n    \n      1\n      Kab. Kepulauan Seribu\n      Prov. D.K.I. Jakarta\n      45.26\n      0\n      0\n    \n    \n      2\n      Kota Jakarta Pusat\n      Prov. D.K.I. Jakarta\n      60.97\n      69.43\n      64.01\n    \n    \n      3\n      Kota Jakarta Utara\n      Prov. D.K.I. Jakarta\n      60.09\n      66.59\n      61.53\n    \n    \n      4\n      Kota Jakarta Barat\n      Prov. D.K.I. Jakarta\n      60.42\n      69.31\n      63.85\n    \n  \n\n\n\n\nLet’s also check if the dtypes is already correct e.g. digit would be float64 or int64 dtype.\n\n\nShow Code\nun_2019.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 547 entries, 0 to 546\nData columns (total 5 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   Nama Wilayah  547 non-null    object\n 1   Propinsi      547 non-null    object\n 2   UN SMP        547 non-null    object\n 3   UN SMA IPA    547 non-null    object\n 4   UN SMA IPS    547 non-null    object\ndtypes: object(5)\nmemory usage: 21.5+ KB\n\n\nLet’s make some amendments on dtypes, to allow plotting.\n\n\nShow Code\nun_2019 = \\\nun_2019.astype({\n    'UN SMP': float,\n    'UN SMA IPA': float,\n    'UN SMA IPS': float,\n})\nun_2019.dtypes\n\n\nNama Wilayah     object\nPropinsi         object\nUN SMP          float64\nUN SMA IPA      float64\nUN SMA IPS      float64\ndtype: object\n\n\nJust me, but I dont like redundant information, so let’s remove some of the words in the column.\n\n\nShow Code\nun_2019 = un_2019.rename(columns={\n    'Nama Wilayah': 'Wilayah'})\nun_2019.head()\n\n\n\n\n\n\n  \n    \n      \n      Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n    \n  \n  \n    \n      0\n      Prov. D.K.I. Jakarta\n      Prov. D.K.I. Jakarta\n      62.17\n      67.99\n      63.75\n    \n    \n      1\n      Kab. Kepulauan Seribu\n      Prov. D.K.I. Jakarta\n      45.26\n      0.00\n      0.00\n    \n    \n      2\n      Kota Jakarta Pusat\n      Prov. D.K.I. Jakarta\n      60.97\n      69.43\n      64.01\n    \n    \n      3\n      Kota Jakarta Utara\n      Prov. D.K.I. Jakarta\n      60.09\n      66.59\n      61.53\n    \n    \n      4\n      Kota Jakarta Barat\n      Prov. D.K.I. Jakarta\n      60.42\n      69.31\n      63.85\n    \n  \n\n\n\n\nSimilarly, let’s remove ‘Prov’ from each data in ‘Propinsi’ column.\n\n\nShow Code\nun_2019['Propinsi'] = \\\nun_2019['Propinsi'].str.replace('Prov. ', '', regex=False)\n\nun_2019.head()\n\n\n\n\n\n\n  \n    \n      \n      Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n    \n  \n  \n    \n      0\n      Prov. D.K.I. Jakarta\n      D.K.I. Jakarta\n      62.17\n      67.99\n      63.75\n    \n    \n      1\n      Kab. Kepulauan Seribu\n      D.K.I. Jakarta\n      45.26\n      0.00\n      0.00\n    \n    \n      2\n      Kota Jakarta Pusat\n      D.K.I. Jakarta\n      60.97\n      69.43\n      64.01\n    \n    \n      3\n      Kota Jakarta Utara\n      D.K.I. Jakarta\n      60.09\n      66.59\n      61.53\n    \n    \n      4\n      Kota Jakarta Barat\n      D.K.I. Jakarta\n      60.42\n      69.31\n      63.85\n    \n  \n\n\n\n\n\n\nQuick DataViz…\nLet’s plot senior high school (SMA) data:\n\n\nShow Code\n#making the barchart\nplt.style.use('ggplot')\n\n\n(un_2019.groupby('Propinsi')\n [[\n     # 'UN SMP',\n     'UN SMA IPA', \n     'UN SMA IPS'\n ]]\n .median()\n .sort_values(\n     by='UN SMA IPA',\n     ascending=True,\n )\n .plot(\n     kind='barh',\n     # ax=axs[0],\n     figsize=(6,10),\n ));\n\n\n\n\n\nSo, from the look of it, 2019 seems to be the year of our capital city: D.K.I. Jakarta, followed by Yogyakarta, Jawa Tengah, Timur, Bali etc. Excluding Bangka Belitung, the big five is all from Java and Bali.\nDecentralized? From 2019- YES.\nBut of course this won’t do it justice, we need more data right?\n\n\nScrape More Data\nLet’s all be human, not abusive towards our notebook, and create a function to scrape our data-change the dtypes-change the column name etc.\n\n\nShow Code\ndef webscrap(tahun):\n    df = pd.read_html(f'https://npd.kemdikbud.go.id/?appid=hasilun&tahun={tahun}')[1][0:547] #ambil data dari web\n    df = df[['Nama Wilayah', 'Propinsi', 'UN SMP','UN SMA IPA', 'UN SMA IPS']] #extract kolom\n    df = df.astype({'UN SMP': float, 'UN SMA IPA': float, 'UN SMA IPS': float}) #ubah dtypes\n    df = df.rename(columns={'Nama Wilayah': 'Wilayah'}) #rename kolom 'Nama Wilayah' jadi 'Wilayah'\n    df['Propinsi'] = df['Propinsi'].str.replace('Prov. ', '', regex=False) #menghapus 'Prov.' \n    df['Tahun'] = tahun #menambahkan kolom tahun\n    return df\n\n\nThen let’s scrap all years data from 2015-2019.\n\n\nShow Code\nun_2015 = webscrap(2015)\nun_2016 = webscrap(2016)\nun_2017 = webscrap(2017)\nun_2018 = webscrap(2018)\nun_2019 = webscrap(2019)\n\n\nLet’s do quick sanity check:\n\n\nShow Code\nun_2015.head()\n\n\n\n\n\n\n  \n    \n      \n      Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n      Tahun\n    \n  \n  \n    \n      0\n      Prov. D.K.I. Jakarta\n      D.K.I. Jakarta\n      73.96\n      72.99\n      66.05\n      2015\n    \n    \n      1\n      Kab. Kepulauan Seribu\n      D.K.I. Jakarta\n      62.80\n      0.00\n      0.00\n      2015\n    \n    \n      2\n      Kota Jakarta Pusat\n      D.K.I. Jakarta\n      74.02\n      72.82\n      63.99\n      2015\n    \n    \n      3\n      Kota Jakarta Utara\n      D.K.I. Jakarta\n      71.22\n      69.54\n      63.31\n      2015\n    \n    \n      4\n      Kota Jakarta Barat\n      D.K.I. Jakarta\n      71.86\n      71.79\n      63.71\n      2015\n    \n  \n\n\n\n\n\n\nShow Code\nun_2019.head()\n\n\n\n\n\n\n  \n    \n      \n      Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n      Tahun\n    \n  \n  \n    \n      0\n      Prov. D.K.I. Jakarta\n      D.K.I. Jakarta\n      62.17\n      67.99\n      63.75\n      2019\n    \n    \n      1\n      Kab. Kepulauan Seribu\n      D.K.I. Jakarta\n      45.26\n      0.00\n      0.00\n      2019\n    \n    \n      2\n      Kota Jakarta Pusat\n      D.K.I. Jakarta\n      60.97\n      69.43\n      64.01\n      2019\n    \n    \n      3\n      Kota Jakarta Utara\n      D.K.I. Jakarta\n      60.09\n      66.59\n      61.53\n      2019\n    \n    \n      4\n      Kota Jakarta Barat\n      D.K.I. Jakarta\n      60.42\n      69.31\n      63.85\n      2019\n    \n  \n\n\n\n\nEven better, let’s combine all of the data into one big data:\n\n\nShow Code\n#merge data\nlist_df = [un_2015, un_2016, un_2017, un_2018, un_2019]\nun_2015_2019 = pd.concat(list_df, axis='rows')\n\n#sanity check\nun_2015_2019.Tahun.value_counts()\n\n\n2015    547\n2016    547\n2017    547\n2018    547\n2019    547\nName: Tahun, dtype: int64\n\n\nData looks good, but just to be safe, let’s save it before we do anything stupid.\n\n\nShow Code\nun_2015_2019.to_csv(\"un_2015_2019.csv\", index=False)\n\n\n\n\nMore DataViz…\nLet’s see which 10 regions have the highest mean national exams.\n\n\nShow Code\norder_new = \\\n(un_2019\n [['Propinsi', 'UN SMA IPA']]\n .groupby(\"Propinsi\")\n .mean()\n .sort_values(by='UN SMA IPA', ascending=False)\n .reset_index()\n)\n\norder_new.head(10)\n\n\n\n\n\n\n  \n    \n      \n      Propinsi\n      UN SMA IPA\n    \n  \n  \n    \n      0\n      D.I. Yogyakarta\n      65.650000\n    \n    \n      1\n      Jawa Tengah\n      61.510000\n    \n    \n      2\n      D.K.I. Jakarta\n      58.410000\n    \n    \n      3\n      Jawa Timur\n      57.377949\n    \n    \n      4\n      Bali\n      55.901000\n    \n    \n      5\n      Bangka Belitung\n      55.407500\n    \n    \n      6\n      Sumatera Barat\n      54.978500\n    \n    \n      7\n      Kalimantan Timur\n      54.211818\n    \n    \n      8\n      Jawa Barat\n      53.813929\n    \n    \n      9\n      Banten\n      53.695556\n    \n  \n\n\n\n\nLet’s do some plotting for all years.\n\n\nShow Code\nfig, axs = plt.subplots(figsize=(10,12))\n\n(sns\n .barplot(\n     data=un_2015_2019.query(\" Tahun>2014 \"), \n     x='UN SMA IPA', \n     y='Propinsi', \n     hue='Tahun',\n     ax=axs, \n     errorbar=('ci', False),\n     palette='viridis_r',\n     order=order_new['Propinsi']\n )\n);\n\n\n\n\n\nFrom the above figure, it looks like the Bali, D.I. Yogyakarta, similar to 2019 dataset is indeed appearing at the top-5.\nBut, let’s exclude year 2015 and 2016, as I think it is a bit an outlier in terms of value here.\n\n\nShow Code\nfig, axs = plt.subplots(figsize=(10,12))\n\n(sns\n .barplot(\n     data=un_2015_2019.query(\" Tahun>2016 \"), \n     x='UN SMA IPA', \n     y='Propinsi', \n     hue='Tahun',\n     ax=axs, \n     errorbar=('ci', False),\n     palette='viridis_r',\n     order=order_new['Propinsi']\n )\n);\n\n\n\n\n\nJust by looking at it, the big-five are from Java and Bali. Not until we reach rank 6 and below we see Bangka Belitung, Sumatera, and Kalimantan. Region outside Java and Bali.\nNow let’s see if our thinking is right, by getting a top region on each national exams from junior to senior high schools.\n\n\nShow Code\ndef get_max_prop(df):\n    max_un_smp = df.groupby(['Propinsi'])['UN SMP'].mean().nlargest(1).index[0]\n    max_un_sma_ipa = df.groupby(['Propinsi'])['UN SMA IPA'].mean().nlargest(1).index[0]\n    max_un_sma_ips = df.groupby(['Propinsi'])['UN SMA IPS'].mean().nlargest(1).index[0]\n    return [max_un_smp, max_un_sma_ipa, max_un_sma_ips]\n\n\nLet’s do a loop over years;\n\n\nShow Code\nyears = [un_2015, un_2016, un_2017, un_2018, un_2019]\nfor year in years:\n    print(get_max_prop(year))\n\n\n['D.K.I. Jakarta', 'Bali', 'Bali']\n['D.I. Yogyakarta', 'Bali', 'Sumatera Utara']\n['D.I. Yogyakarta', 'Sulawesi Tenggara', 'D.I. Yogyakarta']\n['D.I. Yogyakarta', 'D.I. Yogyakarta', 'D.I. Yogyakarta']\n['D.I. Yogyakarta', 'D.I. Yogyakarta', 'D.I. Yogyakarta']\n\n\nFrom the above result, it was clear that excluding Sulawesi Tenggara, all of provinces here is coming from Java and Bali. Most notably D.I. Yogyakarta, D.K.I. Jakarta and Bali."
  },
  {
    "objectID": "posts/004-webscraping-indonesia-national-exam/index.html#lets-talk-about-kalimantan-timur",
    "href": "posts/004-webscraping-indonesia-national-exam/index.html#lets-talk-about-kalimantan-timur",
    "title": "Webscraping National Exams of Indonesia",
    "section": "Let’s Talk about Kalimantan Timur",
    "text": "Let’s Talk about Kalimantan Timur\nWhy? Cause I was raised in Tenggarong, Kutai Kartanegara region, Kalimantan Timur Province. I spent my senior high school here, so I have my own thinking here.\nMy theory is even if Kalimantan Timur was up there at rank 8, it was not from Tenggarong.\n\n\nShow Code\n(un_2015_2019.query(\"Propinsi == 'Kalimantan Timur'\")\n .sort_values(by='UN SMA IPA', ascending=False, ignore_index=True)\n .head(10)\n\n)\n\n\n\n\n\n\n  \n    \n      \n      Wilayah\n      Propinsi\n      UN SMP\n      UN SMA IPA\n      UN SMA IPS\n      Tahun\n    \n  \n  \n    \n      0\n      Kab. Kutai Barat\n      Kalimantan Timur\n      67.48\n      67.03\n      66.30\n      2015\n    \n    \n      1\n      Kota Bontang\n      Kalimantan Timur\n      61.46\n      66.26\n      58.32\n      2019\n    \n    \n      2\n      Kota Bontang\n      Kalimantan Timur\n      57.47\n      63.93\n      61.97\n      2017\n    \n    \n      3\n      Kota Bontang\n      Kalimantan Timur\n      58.06\n      63.40\n      58.75\n      2018\n    \n    \n      4\n      Kab. Kutai Kartanegara\n      Kalimantan Timur\n      55.74\n      62.27\n      61.03\n      2015\n    \n    \n      5\n      Kota Balikpapan\n      Kalimantan Timur\n      59.49\n      61.71\n      53.79\n      2019\n    \n    \n      6\n      Kota Balikpapan\n      Kalimantan Timur\n      57.87\n      61.30\n      51.25\n      2015\n    \n    \n      7\n      Kota Bontang\n      Kalimantan Timur\n      60.51\n      61.16\n      56.19\n      2016\n    \n    \n      8\n      Kota Balikpapan\n      Kalimantan Timur\n      55.50\n      60.94\n      53.81\n      2017\n    \n    \n      9\n      Kota Balikpapan\n      Kalimantan Timur\n      56.65\n      60.51\n      51.45\n      2018\n    \n  \n\n\n\n\n\n\n\n\n\n\nWhy Bontang and Balikpapan?\n\n\n\nWelp, no surprise there, I was right. My hometown (Kab. Kutai Kartanegara) did a good one in 2015, but that was it. The rest is Bontang, Balikpapan. Bontang, has a big industry from Pupuk Kaltim (PKT), and Balikpapan is a big Oil City with Airport, etc."
  },
  {
    "objectID": "posts/004-webscraping-indonesia-national-exam/index.html#what-do-we-get",
    "href": "posts/004-webscraping-indonesia-national-exam/index.html#what-do-we-get",
    "title": "Webscraping National Exams of Indonesia",
    "section": "What do We Get?",
    "text": "What do We Get?\nI think it was clear now that education still very much an exclusive trait, owned by province, and place where there is an industry like Pupuk Kaltim Bontang, and Oil companies in Balikpapan. Places where not so much happening like Tenggarong, is very much stay behind the rest of Kalimantan Timur, and further behind the rest of the big cities in Java and Bali.\nWith the exclusion of National Exams as the only metric for student passing the bar, I wonder how could we as a nation measure the level of education on every province of Indonesia. For that, I wish my country the best - TIme will tell..I guess."
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html",
    "href": "posts/003-project-insurance-cost-part-1/index.html",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "",
    "text": "Photo by Towfiqu barbhuiya on Unsplash"
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#introduction-objectives",
    "href": "posts/003-project-insurance-cost-part-1/index.html#introduction-objectives",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Introduction & Objectives",
    "text": "Introduction & Objectives\nHealth insurance plays an important role in future financial planning. Insurance members are required to pay a routine payment (insurance rates) to the insurance company. This rate will be used to pay medical bill of the insurance members. therefore, determination of insurance rate becomes a critical component to ensure the sustainability of the insurance.\nIn this project, the author wanted to do an exploratory analysis based on known variable that may correlate with the medical bill of the said members. This project will be using personal medical bills dataset (insurance.zip) as the main source1, along with the included metadata below:\n\nage: age of primary beneficiary\nsex: insurance contractor gender, female, male\nbmi: body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg/m2) using the ratio of height to weight, ideally 18.5 to 24.9\nchildren: number of children covered by health insurance / number of dependents\nsmoker: smoking\nregion: the beneficiary’s residential area in the US, northeast, southeast, southwest, northwest.\ncharges: individual medical costs billed by health insurance\n\nAt glance, bmi and smoker would likely to induce a high medical cost of a person, while age, sex, children and region may contribute in some senses or the others.\nObjectives:\n\nAnalyze the relationship between multiple variables to medical charges\nCharacterize the risk profile of members, based on the said analysis\nDetermine if the insurance rate can be optimized for each risk profile"
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#setting-up",
    "href": "posts/003-project-insurance-cost-part-1/index.html#setting-up",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Setting-up",
    "text": "Setting-up\n\n#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport altair as alt\n# import hvplot.pandas\n\n#setting default theme\nsns.set_theme(style='white', palette='tab20')"
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#importing-dataset",
    "href": "posts/003-project-insurance-cost-part-1/index.html#importing-dataset",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Importing Dataset",
    "text": "Importing Dataset\n\ninsurance = pd.read_csv('insurance.zip')\ninsurance.head()\n\n\n\n\n\n  \n    \n      \n      age\n      sex\n      bmi\n      children\n      smoker\n      region\n      charges\n    \n  \n  \n    \n      0\n      19\n      female\n      27.900\n      0\n      yes\n      southwest\n      16884.92400\n    \n    \n      1\n      18\n      male\n      33.770\n      1\n      no\n      southeast\n      1725.55230\n    \n    \n      2\n      28\n      male\n      33.000\n      3\n      no\n      southeast\n      4449.46200\n    \n    \n      3\n      33\n      male\n      22.705\n      0\n      no\n      northwest\n      21984.47061\n    \n    \n      4\n      32\n      male\n      28.880\n      0\n      no\n      northwest\n      3866.85520"
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#feature-engineering",
    "href": "posts/003-project-insurance-cost-part-1/index.html#feature-engineering",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nIn this dataset, the BMI is a numeric data. In order to better analyze the dataset, the bmi data can be grouped into different class/group. The classification in this project will be using BMI classification below:\n\n\n\nBMI\nWeight Status\n\n\n\n\nBelow 18.5\nUnderweight\n\n\n18.5 – 24.9\nHealthy Weight\n\n\n25.0 – 29.9\nOverweight\n\n\n30.0 and Above\nObesity\n\n\n\n\nWe can use pandas.cut method to create a quick binning over bmi column.\n\nbins= [0,18.49,24.9,30,100] #setting up the group based on bmi bins \nlabels = [\n         'underweight',\n         'healthy',\n         'overweight',\n         'obese'\n         ] #setting up the label on each group\n\ninsurance['bmi_class']= pd.cut(\n   insurance['bmi'], \n   bins=bins, \n   labels=labels,\n   include_lowest=False\n   ) #making the new column called bmi_class\n\n#sanity check on bmi_class\n(insurance\n .groupby('bmi_class')\n [['bmi', 'bmi_class']]\n .agg(['min', 'max', 'count'])\n # .style.background_gradient()\n # .style.text_gradient()\n#  .T\n)\n\n\n\n\n\nTable 1:  BMI Class \n  \n    \n      \n      bmi\n      bmi_class\n    \n    \n      \n      min\n      max\n      count\n      min\n      max\n      count\n    \n    \n      bmi_class\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      underweight\n      15.96\n      18.335\n      20\n      underweight\n      underweight\n      20\n    \n    \n      healthy\n      18.50\n      24.890\n      222\n      healthy\n      healthy\n      222\n    \n    \n      overweight\n      24.97\n      30.000\n      391\n      overweight\n      overweight\n      391\n    \n    \n      obese\n      30.02\n      53.130\n      705\n      obese\n      obese\n      705\n    \n  \n\n\n\n\n\nTable 1 shows a new column bmi_class as the result of grouping the bmi data into different categories."
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#quicklook",
    "href": "posts/003-project-insurance-cost-part-1/index.html#quicklook",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Quicklook",
    "text": "Quicklook\n\ninsurance.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1338 entries, 0 to 1337\nData columns (total 8 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   age        1338 non-null   int64   \n 1   sex        1338 non-null   object  \n 2   bmi        1338 non-null   float64 \n 3   children   1338 non-null   int64   \n 4   smoker     1338 non-null   object  \n 5   region     1338 non-null   object  \n 6   charges    1338 non-null   float64 \n 7   bmi_class  1338 non-null   category\ndtypes: category(1), float64(2), int64(2), object(3)\nmemory usage: 74.8+ KB\n\n\nThe data appears to be clean, with no null row, and dftypes appear to be correct. However, the format appears to be a non-tidy format.\n\n(insurance\n .select_dtypes(include=object) #includes all column with object dtypes\n .value_counts() #counting unique value\n)\n\nsex     smoker  region   \nfemale  no      southwest    141\n                southeast    139\n                northwest    135\nmale    no      southeast    134\nfemale  no      northeast    132\nmale    no      northwest    132\n                southwest    126\n                northeast    125\n        yes     southeast     55\n                northeast     38\n                southwest     37\nfemale  yes     southeast     36\n                northeast     29\n                northwest     29\nmale    yes     northwest     29\nfemale  yes     southwest     21\ndtype: int64\n\n\nSome observations:\n\n2 categorical data in sex column: female and male\n2 categorical data in the smoker column, yes or no\n4 categorical data in the region column: southwest, northwest, southeast, and northeast\n\n\n\n\n\n\n\nImportant\n\n\n\nThe first attempt is to see the distribution on each variable relative to each other, depending on different categories. For example, comparing mean age between smoker and non-smoker group, age between low and high bmi class, etc.\nThen trying to understand the relationship of each variable with respect to the medical charges"
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#exploratory-data-analysis",
    "href": "posts/003-project-insurance-cost-part-1/index.html#exploratory-data-analysis",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nAs many people know, smoking is highly linked to clinical disease such as TBC, lung cancer, hypertension, etc. People with smoking history, may be considered a high risk profile, and as the likely outcome the medical charges may be higher than a non-smoker people.\n\nOverall Mean age of insurance member\n\n\nShow Code\n(sns\n .displot(\n     data=insurance, \n     x='age', \n     hue='smoker',\n     kind='hist',\n     height=3,\n     aspect=1.2,\n )\n);\n\n\n\n\nFigure 1: Overall Mean Age\n\n\n\n\n\nBased on distribution at Figure 1, the mean age for all insurance members is around 39 years old. There is also higher number of non-smoker compared to the total data (2 times higher) compared to smoker. There is an anomaly frequency around age of 20 that has up to 4 times higher counts. May need further check.\n\n\nMean age, bmi and charges of smoker at different sex\n\n\nShow Code\n(insurance\n .groupby([\n     'smoker',\n     'sex'\n ])\n \n [[\n     'age',\n     'bmi',\n     'charges'\n  ]]\n \n .agg([\n     'mean', \n ])\n#  .style.background_gradient(\n#      axis=0,\n#      cmap=\"Blues\"\n#  )\n)\n\n\n\n\n\n\nTable 2:  Statistic of Age, BMI, and Charges by Smoker and Sex \n  \n    \n      \n      \n      age\n      bmi\n      charges\n    \n    \n      \n      \n      mean\n      mean\n      mean\n    \n    \n      smoker\n      sex\n      \n      \n      \n    \n  \n  \n    \n      no\n      female\n      39.691042\n      30.539525\n      8762.297300\n    \n    \n      male\n      39.061896\n      30.770580\n      8087.204731\n    \n    \n      yes\n      female\n      38.608696\n      29.608261\n      30678.996276\n    \n    \n      male\n      38.446541\n      31.504182\n      33042.005975\n    \n  \n\n\n\n\n\nCalculating the ratio of smoker to non-smoker group\n\n\nShow Code\n(insurance\n .groupby('smoker')\n [['charges']]\n .agg([np.mean])/8434.268298 #to calculate how high the smoker medical charges\n)\n\n\n\n\n\n\nTable 3:  Ratio of Charges based on Smoker profile \n  \n    \n      \n      charges\n    \n    \n      \n      mean\n    \n    \n      smoker\n      \n    \n  \n  \n    \n      no\n      1.000000\n    \n    \n      yes\n      3.800001\n    \n  \n\n\n\n\n\nBased on the above Table 2, the male bmi is always higher than the female counterpart, irrespective of its sex. Furthermore, the average bmi for smoker is slightly higher than non-smoker group.\nOn the other hand, the average age for female is always higher than its male counterpart, regardless of smoker or non-smoker.\nAs indicated by Table 3, the medical charges for is much higher in the smoker member, compared to non-smoker member, with up to 4 times higher for smoker\n\n\nShow Code\n(insurance\n .groupby('sex')\n [['charges']]\n .agg([np.mean])/12569.578844 #to calculate how high the smoker medical charges\n)\n\n\n\n\n\n\nTable 4:  Ratio of Charges based on Sex profile \n  \n    \n      \n      charges\n    \n    \n      \n      mean\n    \n    \n      sex\n      \n    \n  \n  \n    \n      female\n      1.000000\n    \n    \n      male\n      1.110359\n    \n  \n\n\n\n\n\nFurthermore, Table 4 shows that male has 10% higher medical charges compared to female counterpart.\n\nDistribution of age categorized based on sex, smoker, and bmi_class\n\n\nShow Code\n(sns\n .catplot\n (data=insurance,\n  kind='box',\n  x='age', \n  y='smoker',\n  hue='bmi_class',\n  col='sex',\n  # col_wrap=1,\n  height=4,\n  aspect=0.7,\n  # showmeans=True,\n  palette='Blues',\n )\n);\n\n\n\n\nFigure 2: Age distribution based on Categorical values\n\n\n\n\n\nThe above Figure 2 age shows a the distribution of age between smoker, bmi_class and different sex in the data. As can be seen, there is a clear trend of non-smoker where as the age increases, the bmi increases also, in both male and female group.\nWhereas in the smoker group, there is no clear trend of age vs bmi. This can be further checked when using scatterplot between age and bmi vs charges.\n\n\n\nDoes region affecting the age distribution?\n\n\nShow Code\n(sns\n .catplot\n (data=insurance,\n  kind='box',\n  x='age', \n  y='smoker',\n  hue='bmi_class',\n  col='region',\n  col_wrap=2,\n  height=4,\n  aspect=0.7,\n  showmeans=True,\n  palette='Blues',\n )\n);\n\n\n\n\nFigure 3: Age distribution based on region\n\n\n\n\n\nAs can be seen in Figure 3, the region category does not seem to bring any value to the analysis, as the pattern with/ without region data is unclear. May need further check.\n\nInspecting the age vs charges based on smoker, sex, and bmi_class profile\n\n\nShow Code\ng=(sns\n.relplot\n (data=insurance,\n  x='age',\n  y='charges',\n  hue='smoker',\n  size='bmi_class',\n  style='sex',\n  # legend='full',\n  # col='bmi_class',\n  # col_wrap=1,\n  height=3.5, \n  aspect=1.2,\n  markers=[\"8\",\"P\"],\n  palette='tab10',\n  size_order=['obese', 'overweight', 'healthy', 'underweight']\n )\n);\n\n#setting up annotations\n\ng.fig.text(0.6, 0.25, \"I\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\ng.fig.text(0.6, 0.45, \"II\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\ng.fig.text(0.6, 0.7, \"III\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\nplt.suptitle('age vs charges', y = 1.05);\n\n\n\n\nFigure 4: Age vs Charges\n\n\n\n\n\nFigure 4 shows at least three groups of trend with a strong relationship between medical charges and age. As the age increases, the medical charges increases.\nThe three group of medical charges are as follows:\n\ngroup I: 16000 and below\ngroup II: 16000-30000\ngroup III: above 30000\n\nThe three group of trends were heavily affected by the smoker/ non-smoker group, as the highest group III appears to have more points with obese bmi_class. This can be further checked if we exclude non-smoker group and hue it by bmi_class, and we can put sex as the column category.\n\n\n\nDoes sex affects age vs charges distribution/trend?\n\n\nShow Code\n(sns\n.relplot\n (data=insurance\n  # .query(\"smoker=='yes'\")\n  ,\n  x='age',\n  y='charges',\n  hue='bmi_class',\n  size='bmi_class',\n  style='smoker',\n  # legend='full',\n  col='sex',\n#   col_wrap=1,\n  # row='smoker',\n  height=4, \n  aspect=0.7,\n  markers=[\"8\",\"P\"],\n  s=300,\n  palette='tab10',\n  alpha=0.7,\n  size_order=['obese', 'overweight', 'healthy', 'underweight'],\n  \n )\n)\n\nplt.suptitle('age vs charges | separated by male vs female', y = 1.05);\n\n\n\n\nFigure 5: Age vs Charges based on Sex\n\n\n\n\n\nCouple conclusions can be drawn from these Figure 4 and Figure 5:\n\nThat the male is likely to have higher medical charges compared to female, with relatively small difference (Table 4).\nThere are three groups of strong trend between age vs charges, where as the age increases in all trends, the medical charges is likely to increases as well.\nThe three groups can be characterized from low-high charges as follows:\n\nGroup I: medical charges between 0-16,000, predominantly non-smoker,and a mix between all bmi_class.\nGroup II: medical charges between 12,000-30,000, a mix between smoker and non-smoker group, and bmi_class of healthy and overweight.\nGroup III: medical charges above 30,000, predominantly obese bmi_class and smoker.\n\n\n\n\nSome observed outlier (group I-a) between group I and II?\n\n\nShow Code\ng = (sns\n.relplot\n (data=insurance,\n  x='age',\n  y='charges',\n  hue='bmi_class',\n  size='bmi_class',\n  style='smoker',\n  # legend='full',\n  col='smoker',\n  # col_wrap=1,\n  # row='smoker',\n  height=4, \n  aspect=0.7,\n  markers=[\"8\",\"P\"],\n  s=300,\n  palette='tab10',\n  alpha=0.7,\n  size_order=['obese', 'overweight', 'healthy', 'underweight'],\n )\n);\n\n#annotations\n\ng.fig.text(0.6, 0.22, \"I\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\ng.fig.text(0.3, 0.4, \"II\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\ng.fig.text(0.3, 0.63, \"III\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\ng.fig.text(0.65, 0.4, \"I-a\",\n   color=\"black\", fontdict=dict(size=20), fontweight='bold'\n          )\n\n\nplt.suptitle('age vs charges | separated by smoker vs non-smoker', y = 1.05);\n\n\n\n\nFigure 6: Outliers?\n\n\n\n\n\nIf we look at the above Figure 6, in the non-smoker group, there is a cloud of data below the group II is. This needs further check, as what would affect the scattered data across this category, as it looks like there is another factor (aside from what was plotted already) that affects the data “moves up” (increased medical charges)\n\n\nWhat affects the outlier/ I-a group?\n\n\nShow Code\n(sns\n.relplot\n (data=insurance.query('smoker == \"no\"'),\n  x='age',\n  y='charges',\n  hue='bmi_class',\n  # size='children',\n  style='sex',\n  legend='full',\n  col='children',\n  col_wrap=2,\n  # row='region',\n  height=3, \n  aspect=1,\n#   markers=[\"8\",\"P\"],\n  # s=400,\n  palette='tab10',\n  alpha=0.7,\n  # size_order=['obese', 'overweight', 'healthy', 'underweight'],\n )\n);\n\n\n\n\nFigure 7: Outliers vs number of Children\n\n\n\n\n\nFigure 7 shows just group I and I-a where we see through zero to six number of childrens, colored by bmi_class and styled by sex. As can be seen, there is no clear differentiator between group I and I-a, as the number of children increases, it affects both group I and I-a also.\n\n\n\n\n\n\nImportant\n\n\n\nIt is unclear as to why this is happening. Perhaps other factors plays a role. At the time of this writing, author decided to categorized the group I-a as the outlier.\n\n\n\n\nShow Code\ng = (sns\n.relplot\n (data=insurance,\n  x='bmi',\n  y='charges',\n  hue='smoker',\n  size='children',\n  # style='sex',\n  # legend='full',\n  # col='bmi_class',\n  # col_wrap=1,\n  height=3.5, \n  aspect=1,\n  markers=[\"8\",\"P\"],\n  palette='tab10',\n  size_order=[1,2,3,4,5,6]\n )\n)\n\n#annotations\ng.fig.text(0.35, 0.25, \"I\",\n   color=\"black\", fontdict=dict(size=18), fontweight='bold'\n          )\n\ng.fig.text(0.35, 0.45, \"II\",\n   color=\"black\", fontdict=dict(size=18), fontweight='bold'\n          )\n\ng.fig.text(0.6, 0.65, \"III\",\n   color=\"black\", fontdict=dict(size=18), fontweight='bold'\n          )\n\ng.fig.text(0.5, 0.45, \"I-a\",\n   color=\"black\", fontdict=dict(size=18), fontweight='bold'\n          )\n\nplt.suptitle('bmi vs charges', y = 1.05);\n\n\n\n\nFigure 8: BMI vs Charges\n\n\n\n\n\nSimilar to the previous Figure 5, in Figure 8 we can see that the non-smoker group overlaps with the smoker group at around 16,000-30,000 medical charge range."
  },
  {
    "objectID": "posts/003-project-insurance-cost-part-1/index.html#conclusions-and-outcomes",
    "href": "posts/003-project-insurance-cost-part-1/index.html#conclusions-and-outcomes",
    "title": "Medical Insurance Cost [Part-1]",
    "section": "Conclusions and Outcomes",
    "text": "Conclusions and Outcomes\n\nThe insurance member can be characterzed based on the smoker profile, age, bmi/ bmi_class, and sex profile.\nThe critical factor for a high medical charges is whether member is a smoker or not, followed by age and then bmi2.\nOther variable such as the number of children/ dependant is not playing a role, whereas sex profile affect the charges slightly3.\nThere is a strong relationship between age and medical charges, with 3 strong group categorized by smoker and bmi profile. The big three groups are:\n\nGroup I: medical charges below 16k, related to a group of non-smoker4.\nGroup II: medical charges between 16k-30k, related to a group of smoker and overweight.\nGroup III: medical charges above 30k, related to a group of smoker and obese.\n\nThese three groups have its own trendline which can be later determined (trendline).\nThere is also one outlier or group I-a, where it is unclear as to what affects the medical charges increase to be between group I and II.\n\nThe above groups (I, II, III) can be used for risk profiling, where based on its profile, the associated risk related to medical charges can be determined. Since each group forms a trendline (simple linear regression), and can be categorized based on its smoker, and bmi profile. Based on this approach, one can estimate the optimum pricing for each risk profile (based on its medical charges).\nSee below flowchart for simple ilustration.\n\n\n\n\nflowchart LR\n    A[Member] --> B{Smoking}\n    B --> |No| C[trendline Group I]\n    B --> |Yes| D{BMI Class}\n    D --> |Overweight| E[trendline Group II]\n    D --> |Obese| F[trendline Group III]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe next step would be using some of these knowledge to further investigate the likelihood (probability) of each risk profile based on its numeric (age-bmi) and categorical variable (smoker-bmi-region-sex).\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThis article was made as a replacement for medium article as part of Pacmann Data Science bootcamp assignment for Linear Algebra batch 8. The EDA notebook can be found in this notebook. Inside there will be a Youtube link as part of the assignment also."
  },
  {
    "objectID": "posts/001-my-first-gig/index.html",
    "href": "posts/001-my-first-gig/index.html",
    "title": "My First Interview in 500 Fortune Company",
    "section": "",
    "text": "Image by Unsplash\n\n\n\nIn the early 2013, around March, I was getting an interview on the 500 Fortune company, where my interviewer asked me a difficult question and I said I don’t know, but somehow I got the Job.\nMy career started even before that. In 2011-2012, during my last year of studies and close to graduation day I spent around a year to do side projects with my lecturers, from geological mapping, seismic interpretation, joint-study field evaluation, basin modeling, to petrophysical analysis.\nNot until 2013-2014, where I got my first industrial role in Jakarta, the capital city of Indonesia, moving away from freelance project in Yogyakarta. Here I mostly worked on petrophysical analysis, evaluating more than 100 wells in clastics and carbonate reefal reservoir, helping the team to update their static model. We planned to do EOR (waterflooding) at the time, so simulation is very critical before economical decision was made.\nFast forward to March 2014, through some luck and intentional effort, I managed to secure an interview with my current employer for an entry level position as petrophysicist/ geoscientist. The interview was a bit “drama” at first, cause the interviewer was changed at the last minute. Nerveousness was at its peak.\nHowever, somehow I got to meet the interviewer, answer few tehnical questions and non-technical questions. Right before we end the interview, she asked me the final technical questions. The question is about intutitive meaning of when density and neutron log is overlayed each other. She said she just need a straightforward answer, two words not more.\nI knew at that time that I have no idea what was supposed to be the answer to the question, but I was too afraid that I would mess my chance to get the gig. I was not esactly remembered how long I take the time to answer, but eventually I come to a conclusion – I should be honest.\nI said:\n\n“I Do Not Know”.\n\nIt took her 5 seconds, and as she smiled she said:\n\n“Well, I Do Not Expect you to be able to Answer the question given the limited experience you have with well logs”\n\nShe explained to me that the question is to test me. She knew that I would probably did not know the answer to the question, her target was to know whether I will spit out my honest truth (that I dont know), or try to be smart by spitting some BS. I was glad I choose the first.\nTo me this was one of the biggest moment in my career, where you should always try to be honest with yourself in an interview. At the end of the day, you would not want to be in the same team with a person who you cannot trust.\nCredibility, given how “small” the world of energy industry, should not be treated lightly. Furthermore, connection, was built upon trusts. You will be surprised, how many times I have seen “a guy/girl” got the gig just by “knowing someone”.\n\n\n\nCitationBibTeX citation:@online{ariewijaya2022,\n  author = {Aditya Arie Wijaya},\n  title = {My {First} {Interview} in 500 {Fortune} {Company}},\n  date = {2022-08-29},\n  url = {ariewjy.github.io/posts/001-my-first-gig},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nAditya Arie Wijaya. 2022. “My First Interview in 500 Fortune\nCompany.” August 29, 2022. ariewjy.github.io/posts/001-my-first-gig."
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html",
    "href": "posts/007-quarto-python-tutorial/index.html",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "",
    "text": "Quarto to me is one of the best thing ever from Rstudioconf 2022 last year, POSIT (previously Rstudio) marketed it as an open source tool to create documents, presentation, books, website easy and inclusive for python users. This is huge, cause for the longest time, there is not an easy way to create website out of a notebook, nbdev might be one of those people to facilitate this, but not at the support and scale of which R-people get (Xaringan, Blogdown for Hugo, or Distill for Rmarkdown, etc)."
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#pay-gate-wall",
    "href": "posts/007-quarto-python-tutorial/index.html#pay-gate-wall",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "1. Pay Gate Wall",
    "text": "1. Pay Gate Wall\nIt is good if you are getting paid for what you were sharing on, but if your main purpose is for branding yourself (like me), then a pay gate wall would not do you any good (Figure 1). Especially, when you have just started on. Though it is fairly cheap, it is just another stopper for your first audience. Worse, the paid-subscription is only available for certain countries, Indonesia for example is not supported.\n\n\nFigure 1: Pay Gate in medium.com"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#reproducibility",
    "href": "posts/007-quarto-python-tutorial/index.html#reproducibility",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "2. Reproducibility",
    "text": "2. Reproducibility\nWhen I do my first data-science project, I wanted to make sure that someone can just follow along and then get the same result as I was. Using platform like medium, I could not really do that, and I believe it was not meant for tutorial in details. Rather it was for an explanatory writing, rather than exploratory writing. Quarto with its rendered codes as an output, makes it easier to do just that. The below code cell is me importing libraries, importing a dataset, and displaying the table.\n\n\nShow Code\n#importing libraries\nimport pandas as pd\nimport hvplot.pandas\nfrom bokeh.sampledata.penguins import data as penguins\n\n#displaying first 5 rows\npenguins.head()\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      0\n      Adelie\n      Torgersen\n      39.1\n      18.7\n      181.0\n      3750.0\n      MALE\n    \n    \n      1\n      Adelie\n      Torgersen\n      39.5\n      17.4\n      186.0\n      3800.0\n      FEMALE\n    \n    \n      2\n      Adelie\n      Torgersen\n      40.3\n      18.0\n      195.0\n      3250.0\n      FEMALE\n    \n    \n      3\n      Adelie\n      Torgersen\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      Adelie\n      Torgersen\n      36.7\n      19.3\n      193.0\n      3450.0\n      FEMALE\n    \n  \n\n\n\n\nWhat if I want to show the last 6 rows? I can just change the code.\n\n\nShow Code\n#importing libraries\nimport pandas as pd\nimport hvplot.pandas\nfrom bokeh.sampledata.penguins import data as penguins\n\n#displaying first 5 rows\npenguins.tail(6)\n\n\n\n\n\n\n  \n    \n      \n      species\n      island\n      bill_length_mm\n      bill_depth_mm\n      flipper_length_mm\n      body_mass_g\n      sex\n    \n  \n  \n    \n      338\n      Gentoo\n      Biscoe\n      47.2\n      13.7\n      214.0\n      4925.0\n      FEMALE\n    \n    \n      339\n      Gentoo\n      Biscoe\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      340\n      Gentoo\n      Biscoe\n      46.8\n      14.3\n      215.0\n      4850.0\n      FEMALE\n    \n    \n      341\n      Gentoo\n      Biscoe\n      50.4\n      15.7\n      222.0\n      5750.0\n      MALE\n    \n    \n      342\n      Gentoo\n      Biscoe\n      45.2\n      14.8\n      212.0\n      5200.0\n      FEMALE\n    \n    \n      343\n      Gentoo\n      Biscoe\n      49.9\n      16.1\n      213.0\n      5400.0\n      MALE"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#contents-ownership",
    "href": "posts/007-quarto-python-tutorial/index.html#contents-ownership",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "3. Contents Ownership",
    "text": "3. Contents Ownership\nIf one day the platform (medium) goes bankrupt, I have no worry because I kept all my posts in a github, and my local folder. If the domain is somehow being hacked, I can just changed it. I own the content, and nobody else.\nThis gives you not only a total control, but also a freedom to experiment to your heart desires.\n\n\n\nvia GIPHY\n\n\nOf course there are benefits of using low-code platform, but for my use case, I much prefer to have my own personal website."
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#creating-a-repo",
    "href": "posts/007-quarto-python-tutorial/index.html#creating-a-repo",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Creating a repo",
    "text": "Creating a repo\nMake a new repository with the same name as your github account. For example, if your github account is johndoe, then make a new repository named john.github.io (see Figure 2).\n\n\nFigure 2: Creating a New Repo\n\n\n\nWhat’s cool about this repo is it will be accessible later on as a domain for your personal website, completely free, and secure (https). This of course can be customized with a domain of your choice, but for now, we want to make this as easy as possible."
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#starting-from-a-notebook",
    "href": "posts/007-quarto-python-tutorial/index.html#starting-from-a-notebook",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Starting from a notebook",
    "text": "Starting from a notebook\nLet’s make a content, using jupyter notebook, with a combination of code cells and markdown cells. I am gonna use the content in this post, where I load a libraries, dataset from palmerpenguins, and then I will do some plotting using altair to spice things up, cause why not. See below Figure 3 for example.\n\n\nShow Code\n#importing libraries\nimport altair as alt\nfrom bokeh.sampledata.penguins import data as penguins\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n#plotting\nbrush = alt.selection(type='interval')\n\npoints = alt.Chart(\n  data=penguins, \n  title=\"Palmer Penguins Dataset\",\n  ).mark_circle(size=60).encode(\n  alt.X('bill_length_mm', scale=alt.Scale(domain=[30,60])),\n  alt.Y('bill_depth_mm', scale=alt.Scale(domain=[12,22])),\n  color='species',\n  ).add_selection(\n    brush\n)\n\nbars = alt.Chart(penguins).mark_bar().encode(\n    y='island',\n    color='island',\n    x='count(island)'\n).transform_filter(\n    brush\n)\n\npoints & bars\n\n\n\n\n\n\n\n\n\nFigure 3: Example Notebook"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#create-a-project",
    "href": "posts/007-quarto-python-tutorial/index.html#create-a-project",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Create a Project",
    "text": "Create a Project\nThe first step is to create a set of folders for website project, using quarto by executing the following command inside the project folder:\nmkdir posts\nquarto create-project . --type website\nwhich will output the following Figure 4, essentially the post folder would be where we keep our blogpost files.\n\n\nFigure 4: Output Projects"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#convert-notebook-to-quarto-markdown",
    "href": "posts/007-quarto-python-tutorial/index.html#convert-notebook-to-quarto-markdown",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Convert Notebook to Quarto Markdown",
    "text": "Convert Notebook to Quarto Markdown\nThe second step is to convert the jupyter notebook file (example.ipynb) to quarto markdown file (example.qmd) by running the following command:\nquarto convert ./example.ipynb\nwhich will create an output of qmd file which is important, because this would then be rendered to html (as shown in Figure 5) by running the following command:\nquarto render\n\n\nFigure 5: Output Render"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#setting-the-website",
    "href": "posts/007-quarto-python-tutorial/index.html#setting-the-website",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Setting the Website",
    "text": "Setting the Website\nYAML file is basically where we fine tune our website settings. For this case, we need to move the example.qmd file to post folder, and add the qmd file inside the navbar, below the about.qmd as shown in Figure 6\n\n\nFigure 6: YAML setting"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#previewing-the-website",
    "href": "posts/007-quarto-python-tutorial/index.html#previewing-the-website",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Previewing The Website",
    "text": "Previewing The Website\nAll things set, now all we need to do is preview our website by running the following command:\nquarto preview\nwhich will output our new website inside a browser as shown in the following Figure 7. This is a preview mode which means, any changes made to the website, it will be rendered and displayed real-time.\n\n\nFigure 7: Website Preview\n\n\n\nVoila! You got it done! Congrats!"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#deploying-the-website",
    "href": "posts/007-quarto-python-tutorial/index.html#deploying-the-website",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "Deploying the Website",
    "text": "Deploying the Website\nThere is a documentation on Quarto to do this, but in layman terms, there are essentially three things to do:\n\nCreate a docs folder and set the output to be that folder in _quarto.yml file as shown in Figure 8 below\n\n\n\nFigure 8: docs settting\n\n\n\n\nSet the website repo setting to use the docs folder as the branch source as shown in Figure 9 below\n\n\n\nFigure 9: repo settting\n\n\n\n\nPush your local Repo to the Github!\n\ngit add .\ngit commit -m \"my first website\"\ngit push\nand you should see your website is up and running after the builds and deployment as shown in Figure 10 finished!\n\n\nFigure 10: Builds Up and Deployment\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nSince this is a static pages, we will have to run quarto-render everytime before pushing it to the github. Otherwise, it may appear in our preview-mode, but will not show up in the website online."
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#make-a-homepage",
    "href": "posts/007-quarto-python-tutorial/index.html#make-a-homepage",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "1. Make A Homepage",
    "text": "1. Make A Homepage\nIf you have your website deployed, congrats! However, if you stay, I can assure you that it will make your website much better.\nSome nicer things to do for your website is to render the index.qmd in the root folder as a listing, so any post in your post folder will be listed as a content, as shown in Figure 11 below:\n\n\nFigure 11: Setting Up the Website\n\n\n\nHere is what I did to the initial website:\n\nMake a folder inside posts, create a 001-first-post folder, and change the filename to index.qmd\nEdit the index.qmd in the root folder to list the contents\nEdit the _quarto.yml file back to its original setting.\n\nWith this setting, you will have a nicer homepage like Figure 12 below:\n\n\nFigure 12: Homepage"
  },
  {
    "objectID": "posts/007-quarto-python-tutorial/index.html#use-quarto-in-vscode",
    "href": "posts/007-quarto-python-tutorial/index.html#use-quarto-in-vscode",
    "title": "Personal Website using Jupyter Notebook and Quarto",
    "section": "2. Use Quarto in VSCode",
    "text": "2. Use Quarto in VSCode\nAlthough so far we can get by just by using jupyter notebook, we were missing out (big time) in quarto extension capabilities. Autocompletion, autosuggestions, which are available in VSCode but not the jupyter notebook.\nUsing VSCode and Quarto, we can easily shift between visual-mode and source-mode, for a nicer GUI. You can just right-click and select edit in visual-mode and it will automatically brings you to a GUI version of the markdown.\n\nFrom there, we can change the heading-style, bold, italic, add numbers, lists, picture, callnote, a very powerful GUI for markdown! Loved it!\n\nHere is the comparison side-by-side in Figure 13:\n\n\nFigure 13: Source-mode vs Visual-mode\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nOne of the nicest things that I used A LOT is the ability to just copy-paste an image from clipboard to a qmd file via visual-mode, and it will automatically create a folder named images, save the image we pasted into the folder, and displayed it (by referencing) into the qmd file. All happen instaneously!"
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html",
    "href": "posts/006-easy-report-machine-learning/index.html",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "",
    "text": "Photo by Esmonde Yong on Unsplash\n\n\n\nThis is a machine learning project to predict unit/property monthly rent price in Kuala Lumpur region, Malaysia. The project uses a dataset from an online ads listing for property mudah.my. This project outlines the process of web-scraping/ data gathering, data cleaning-wrangling, and machine learning modeling.\nThis project aims to answers question about how much a unit monthly rent would be if given information such as location, number of bedrooms, parking, furnished, etc? This would help potential tenant and also the owner to get the best price of their rental unit, comparable to the market value.\nSome previous work about house pricing was listed below, however most of them are targeting a dataset of house pricing or an Airbnb pricing. There are difference such as in Airbnb, the booking rarely took more than 2 weeks, let alone a year. Therefore the pricing may be different. Additionally, in Airbnb, there is text feature coming from the review given by the tenant and the owner.The better the review, the higher the rent prices – which was not available in this current project dataset."
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#who-is-this-for",
    "href": "posts/006-easy-report-machine-learning/index.html#who-is-this-for",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Who is this for?",
    "text": "Who is this for?\n\n\n\n\n\n\nNote\n\n\n\nThis project was the TLDR-version of the complete article where author explained in much more details about the process of webscraping-data cleaning-data wrangling-feature engineering, etc. This was made also as a mandatory terms for me to pass the Pacmann bootcamp intro to machine learning class. Video of me explaining the whole project is also available here or in the video below"
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#related-work",
    "href": "posts/006-easy-report-machine-learning/index.html#related-work",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Related work",
    "text": "Related work\nPrevious work by Madhuri, Anuradha, and Pujitha (2019), Xu and Nguyen (2022), and Zhao et al. (2022) highlight the importance feature selection, and the choice of machine learning model. Based on the previous works, the most consistently performed machine learning model are Random Forest and Gradient boosting, and the MAE and R2 score usually used in evaluating the performance of the model. Although the above work are all not about apartment rent pricing, similar method can be applied to this project."
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#dataset-features",
    "href": "posts/006-easy-report-machine-learning/index.html#dataset-features",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Dataset & features",
    "text": "Dataset & features\nThe dataset is using the scraped dataset from ads listing website, particularly property-to-rent surrounding Kuala Lumpur, Malaysia.\n\n\n\n\n\n\nWhy Webscraping?\n\n\n\nAs 80% of data science process is about data engineering, from collection (gathering) to wrangling/ cleaning, author fells the need to brush up the skill, from available online data, relevant to the author (location: Kuala Lumpur), using webscraping tool such as BeaufifulSoup.\nDetail of the web-scraping process on this project can be found in this article.\n\n\nThere are over 10k ads listed at the time of this project as can be seen below:\n\n\nData Description\n\n\nShow Code\n#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_colwidth', 200)\nimport re\n\n#reload the data\ndf = pd.read_csv(\"./mudah-apartment-clean.csv\")\ndf.head(2).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      ads_id\n      100323185\n      100203973\n    \n    \n      prop_name\n      The Hipster @ Taman Desa\n      Segar Courts\n    \n    \n      completion_year\n      2022.0\n      NaN\n    \n    \n      monthly_rent\n      RM 4 200 per month\n      RM 2 300 per month\n    \n    \n      location\n      Kuala Lumpur - Taman Desa\n      Kuala Lumpur - Cheras\n    \n    \n      property_type\n      Condominium\n      Condominium\n    \n    \n      rooms\n      5\n      3\n    \n    \n      parking\n      2.0\n      1.0\n    \n    \n      bathroom\n      6.0\n      2.0\n    \n    \n      size\n      1842 sq.ft.\n      1170 sq.ft.\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n    \n    \n      facilities\n      Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track\n      Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed, Washing Machine\n      Air-Cond, Cooking Allowed, Near KTM/LRT\n    \n  \n\n\n\n\nThere are 13 features with one unique ids (ads_id) and one target feature (monthly_rent)\n\nads_id: the listing ids (unique)\nprop_name: name of the building/ property\ncompletion_year: completion/ established year of the property\nmonthly_rent: monthly rent in ringgit malaysia (RM)\nlocation: property location in Kuala Lumpur region\nproperty_type:property type such as apartment, condominium, flat, duplex, studio, etc\nrooms: number of rooms in the unit\nparking: number of parking space for the unit\nbathroom: number of bathrooms in the unit\nsize: total area of the unit in square feet\nfurnished: furnishing status of the unit (fully, partial, non-furnished)\nfacilities: main facilities available\nadditional_facilities: additional facilities (proximity to attraction area, mall, school, shopping, railways, etc)\n\n\n\nData Cleaning\nThe cleaning process mainly related to extracting the value out of column. E.g. extracting monthly rent of 1400 from a string of “1400 RM”, etc.\n\n\nShow Code\n#removing RM from monthly rent\ndf['monthly_rent'] = df['monthly_rent'].apply(lambda x: int(re.search(r'RM (.*?) per', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'monthly_rent': 'monthly_rent_rm'})\n\n#dropping sq.ft from size\ndf['size'] = df['size'].apply(lambda x: int(re.search(r'(.*?) sq', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'size': 'size_sqft'})\n\n#dropping kuala lumpur from the location\ndf['location'] = df['location'].apply(lambda x: re.findall(\"\\w+$\", x)[0])\ndf.head(2).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      ads_id\n      100323185\n      100203973\n    \n    \n      prop_name\n      The Hipster @ Taman Desa\n      Segar Courts\n    \n    \n      completion_year\n      2022.0\n      NaN\n    \n    \n      monthly_rent_rm\n      4200\n      2300\n    \n    \n      location\n      Desa\n      Cheras\n    \n    \n      property_type\n      Condominium\n      Condominium\n    \n    \n      rooms\n      5\n      3\n    \n    \n      parking\n      2.0\n      1.0\n    \n    \n      bathroom\n      6.0\n      2.0\n    \n    \n      size_sqft\n      1842\n      1170\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n    \n    \n      facilities\n      Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track\n      Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna\n    \n    \n      additional_facilities\n      Air-Cond, Cooking Allowed, Washing Machine\n      Air-Cond, Cooking Allowed, Near KTM/LRT"
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#methods",
    "href": "posts/006-easy-report-machine-learning/index.html#methods",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Methods",
    "text": "Methods\nFollowing the works from others, author will be focusing on using Random Forest and Gradient Boosting for the two main machine learning model to try to compare to baseline (average, and linear regression).\n\nBaseline using average means that the prediction will be using average value of the train target value. This yield a zero R2-score and the highest MAE value which will not be used as comparison in the following discussion.\n\nThe author will mainly talking about baseline using linear regression. Linear regression is one of the machine learning model, where the model objective is to minimize the total error (distance) of each predicted value against the actual value.\nThe comparable model will be using Random Forest and Gradient Boosting.\nA gradient boosting uses iterative process to assign weights to different sample, until the model predicts the target correctly. Meanwhile, Random Forest use similar concept, but the sampling and feature selection are random, therefore reduces both bias and variance in the model."
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#experiments",
    "href": "posts/006-easy-report-machine-learning/index.html#experiments",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Experiments",
    "text": "Experiments\nThe experiments mostly related to the data preparation before getting into modeling. The most author spent time with is feature selection and outlier removal. One of the insight when doing feature selection is the proximity to nearby railways (KTM/LRT) is likely to affect the increase of rent price. However, the finding is that the listing is inconsistent, the same property may listed to be ‘near KTM/LRT’, but the other rows were not.\n\nExtracting Near KTM/LRT\n\n\nShow Code\n#extracting near KTM/LRT from the additional facilities\ndef extract_near_ktm_lrt(text):\n    pattern = re.compile(r'\\bNear KTM/LRT\\b')\n    try:\n        match = pattern.search(text)\n        if match:\n            return 'yes'\n        return 'no'\n    except TypeError:\n        return text\n\n\n\n\nShow Code\ndf['nearby_railways'] = df.additional_facilities.apply(lambda x: extract_near_ktm_lrt(x))\n\nfig, axs = plt.subplots(figsize=(6,4))\nsns.boxplot(data=df, x='monthly_rent_rm', y='nearby_railways', ax=axs)\nplt.xlim(0,4000);\n\nnear_ktmlrt = df.query(\" nearby_railways == 'yes' \")\nnot_near_ktmlrt = df.query(\" nearby_railways == 'no' \")\n\nprint(f\"\"\" \nMedian:\nNearby KTM/LRT: {near_ktmlrt.monthly_rent_rm.median():.0f}RM\nNot nearby KTM/LRT: {not_near_ktmlrt.monthly_rent_rm.median():.0f}RM\n      \"\"\")\n\n\n \nMedian:\nNearby KTM/LRT: 1650RM\nNot nearby KTM/LRT: 1600RM\n      \n\n\n\n\n\n\n\nShow Code\ndf[df['prop_name'] == 'Majestic Maxim'][['nearby_railways']].value_counts()\n\n\nnearby_railways\nyes                166\nno                  24\ndtype: int64\n\n\nAs seen above, nearby KTM/LRT is slightly increases the median monthly rent by 50RM, however near KTM/LRT is not appearing in all row even though the unit is the same building.\n\n\nDrop Unnecessary Missing Values\nSome features such as ads_id, prop_name, facilities and additional_facilities would no longer needed after the previous process.\n\n\nShow Code\ndf = df.drop(columns=[\n    'ads_id', \n    'prop_name', \n    'facilities', \n    'additional_facilities',\n    # 'nearby_railways',\n    # 'completion_year'\n])\ndf.head(2).T\n\n\n\n\n\n\n  \n    \n      \n      0\n      1\n    \n  \n  \n    \n      completion_year\n      2022.0\n      NaN\n    \n    \n      monthly_rent_rm\n      4200\n      2300\n    \n    \n      location\n      Desa\n      Cheras\n    \n    \n      property_type\n      Condominium\n      Condominium\n    \n    \n      rooms\n      5\n      3\n    \n    \n      parking\n      2.0\n      1.0\n    \n    \n      bathroom\n      6.0\n      2.0\n    \n    \n      size_sqft\n      1842\n      1170\n    \n    \n      furnished\n      Fully Furnished\n      Partially Furnished\n    \n    \n      nearby_railways\n      no\n      yes\n    \n  \n\n\n\n\n\n\nShow Code\n#converting rooms from object to int64 for plotting\ndf['rooms'] = pd.to_numeric(df['rooms'], downcast='integer', errors='coerce')\ndf.info()\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9991 entries, 0 to 9990\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   completion_year  5618 non-null   float64\n 1   monthly_rent_rm  9991 non-null   int64  \n 2   location         9991 non-null   object \n 3   property_type    9991 non-null   object \n 4   rooms            9987 non-null   float64\n 5   parking          7361 non-null   float64\n 6   bathroom         9989 non-null   float64\n 7   size_sqft        9991 non-null   int64  \n 8   furnished        9990 non-null   object \n 9   nearby_railways  7160 non-null   object \ndtypes: float64(4), int64(2), object(4)\nmemory usage: 780.7+ KB\n\n\n\n\nOutlier Removal\nRemoving the outlier is extremely important, as some of these observation e.g. monthly rent, have astronomical rent value, far exceeding the median. After multiple iteration, below is the most-ideal limit for size_sqft and monthly_rent_rm.\n\n\nShow Code\nf, axs = plt.subplots(1,1, figsize=(6,4))\ndf[['size_sqft', 'monthly_rent_rm']].plot(kind='scatter', \n                                          x='size_sqft', \n                                          y='monthly_rent_rm', \n                                          ax=axs);\nplt.ylim(100,5500) #batas harga rent\nplt.xlim(50,3000)  #batas size\nplt.show()\n\n\n\n\n\n\nMonthly Rent\n\n\nShow Code\nfig, axs = plt.subplots(1,2, figsize=(6,4))\naxs[0].boxplot(data=df, \n               x='monthly_rent_rm')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=df, \n               x='monthly_rent_rm')\naxs[1].set_ylim(100,5500)\naxs[1].set_title('100-5,500 RM')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nShow Code\n#removing all rows with monthly rent above 5500 RM and below 100RM\ndfx = df.query(\" monthly_rent_rm > 100 & monthly_rent_rm < 5500 \")\n\n\n\n\nSize\n\n\nShow Code\nfig, axs = plt.subplots(1,2, figsize=(5,4))\naxs[0].boxplot(data=dfx, x='size_sqft')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=dfx, x='size_sqft')\naxs[1].set_ylim(0,2000)\naxs[1].set_title('50-3,000 square feet')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nShow Code\n#removing outliers below 500, and higher than 3000 sqft and below 50 sqft\ndfx = dfx.query(\" size_sqft > 50 & size_sqft < 3000 \")\n\n\n\n\n\nData Preparation\n\nPreprocessing Original Data for Categorical Dtypes\nOne must paying attention to the number of categorical observation in the original data, with respect to the sampling train-test value. If, the test_size = 0.3, that means any categorical observation with a total of 3 and less, would not be distributed evenly among train and test data. Below is the process of removing some observation in which appearing only in one of the dataset (train/ test).\n\n\nShow Code\ndfx_new = dfx[\n    (dfx.location != 'Jinjang') \n    & (dfx.location != 'Serdang') & \n    (dfx.location != 'Sentral') & \n    (dfx.location != 'Others') & \n    (dfx.location != 'Tunku') & \n    (dfx.location != 'Penchala') & \n    (dfx.location != 'Lin') &\n    # (dfx.property_type != 'Others') &\n    (dfx.property_type != 'Condo / Services residence / Penthouse / Townhouse') &\n    (dfx.property_type != 'Townhouse Condo')\n]\n\n\n\n\nInput-Output\n\n\nShow Code\ndef extractInputOutput(data,\n                       output_column_name):\n    \"\"\"\n    Fungsi untuk memisahkan data input dan output\n    :param data: <pandas dataframe> data seluruh sample\n    :param output_column_name: <string> nama kolom output\n    :return input_data: <pandas dataframe> data input\n    :return output_data: <pandas series> data output\n    \"\"\"\n    output_data = data[output_column_name]\n    input_data = data.drop(output_column_name,\n                           axis = 1)\n    \n    return input_data, output_data\n\n\n\n\nShow Code\nX, y = extractInputOutput(data=dfx_new, \n                          output_column_name='monthly_rent_rm')\n\n\n\n\nTrain-Test Split Data\n\n\nShow Code\n#import libraries\nfrom sklearn.model_selection import train_test_split\n\n# Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size = 0.2,\n                                                    random_state = 123)\n\n\n\n\nTraining Data Imputation\n\nNumerical Data\n\n\nShow Code\nfrom sklearn.impute import SimpleImputer\n\ndef numericalImputation(X_train_num, \n                        strategy = 'most_frequent'):\n    \"\"\"\n    Fungsi untuk melakukan imputasi data numerik NaN\n    :param data: <pandas dataframe> sample data input\n\n    :return X_train_numerical: <pandas dataframe> data numerik\n    :return imputer_numerical: numerical imputer method\n    \"\"\"\n    #buat imputer\n    imputer_num = SimpleImputer(missing_values = np.nan, \n                                strategy = strategy)\n    \n    #fitting\n    imputer_num.fit(X_train_num)\n\n    # transform\n    imputed_data = imputer_num.transform(X_train_num)\n    X_train_num_imputed = pd.DataFrame(imputed_data)\n\n    #pastikan index dan nama kolom antara imputed dan non-imputed SAMA\n    X_train_num_imputed.columns = X_train_num.columns\n    X_train_num_imputed.index = X_train_num.index\n\n    return X_train_num_imputed, imputer_num\n\n\n\n\nShow Code\nX_train_num =  X_train.select_dtypes(exclude='object')\nX_train_num, imputer_num = numericalImputation(X_train_num, \n                                               strategy='most_frequent')\n\n\n\n\nCategorical Data\n\n\nShow Code\nX_train_cat = X_train.select_dtypes(include='object')\nX_train_cat, imputer_num = numericalImputation(X_train_cat, \n                                               strategy='most_frequent')\n\n\n\n\nOHE Categorical Data\n\n\nShow Code\ndef get_dum_n_concat(df_num, df_cat):\n    df_cat_ohe = pd.get_dummies(df_cat)\n    ohe_columns = df_cat_ohe.columns\n    df_concat = pd.concat([df_num, df_cat_ohe], axis=1)\n    print(f\"Number of Cols: {df_concat.shape[1]},\\nNumber of Null Rows: {df_concat.isna().sum()}\")\n    return ohe_columns, df_concat\n\n\n\n\nShow Code\nohe_col, X_train_concat = get_dum_n_concat(X_train_num, \n                                           X_train_cat)\n\n\nNumber of Cols: 63,\nNumber of Null Rows: completion_year                  0\nrooms                            0\nparking                          0\nbathroom                         0\nsize_sqft                        0\n                                ..\nfurnished_Fully Furnished        0\nfurnished_Not Furnished          0\nfurnished_Partially Furnished    0\nnearby_railways_no               0\nnearby_railways_yes              0\nLength: 63, dtype: int64\n\n\n\n\nStandarisasi\n\n\nShow Code\nfrom sklearn.preprocessing import StandardScaler\n\n# Buat fungsi\ndef standardizerData(data):\n    \"\"\"\n    Fungsi untuk melakukan standarisasi data\n    :param data: <pandas dataframe> sampel data\n    :return standardized_data: <pandas dataframe> sampel data standard\n    :return standardizer: method untuk standardisasi data\n    \"\"\"\n    data_columns = data.columns  # agar nama kolom tidak hilang\n    data_index = data.index  # agar index tidak hilang\n\n    # buat (fit) standardizer\n    standardizer = StandardScaler()\n    standardizer.fit(data)\n\n    # transform data\n    standardized_data_raw = standardizer.transform(data)\n    standardized_data = pd.DataFrame(standardized_data_raw)\n    standardized_data.columns = data_columns\n    standardized_data.index = data_index\n\n    return standardized_data, standardizer\n\n\n\n\nShow Code\nX_train_clean, standardizer = standardizerData(data = X_train_concat)\n\n\n\n\n\nTraining Machine Learning\n\nBaseline with Mean value\n\n\nShow Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n#baseline\ny_baseline = np.ones(len(y_train)) * y_train.mean()\n\n# Predict using the train data\ny_pred_train_mean = y_baseline\n\n# Calculate R-squared\nr2_baseline = r2_score(y_train, \n                       y_pred_train_mean)\n\n#calculate MAE\nmae_baseline = mean_absolute_error(y_train, \n                                   y_pred_train_mean)\n\n\n\n\nLinear Regression\n\n\nShow Code\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Train the linear regression model\nlin_reg = LinearRegression().fit(X_train_clean, \n                                 y_train)\n\n# Predict using the train data\ny_pred_train_linreg = lin_reg.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_linreg = mean_absolute_error(y_train, \n                                 y_pred_train_linreg)\n\n# Calculate R-squared\nr2_linreg = r2_score(y_train, \n                     y_pred_train_linreg)\n\n\n\n\nGradientBoosting\n\n\nShow Code\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Build random forest\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\n# Fit random forest\ngrad_tree.fit(X_train_clean, y_train)\n\n# Predict\ny_pred_train_gb = grad_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_gb = mean_absolute_error(y_train, \n                             y_pred_train_gb)\n\n# Calculate R-squared\nr2_gb = r2_score(y_train, \n                 y_pred_train_gb)\n\n\n\n\nShow Code\n#gridsearch\nfrom sklearn.model_selection import GridSearchCV \n\nparams = {'n_estimators': [100, 200, 300, 400, 500],\n              'learning_rate': [0.1, 0.05, 0.01]}\n\n# Buat gridsearch\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\ngrad_tree_cv = GridSearchCV(estimator = grad_tree,\n                           param_grid = params,\n                           cv = 5,\n                           scoring = \"neg_mean_absolute_error\")\n# Fit grid search cv\ngrad_tree_cv.fit(X_train_clean, \n                 y_train)\n\n# Best params\ngrad_tree_cv.best_params_\n\n\n{'learning_rate': 0.1, 'n_estimators': 500}\n\n\n\n\nShow Code\n# Refit the GB\ngrad_tree = GradientBoostingRegressor(n_estimators = 500,\n                                      learning_rate=0.1,\n                                      random_state = 123)\n\ngrad_tree.fit(X_train_clean, \n              y_train)\n\n\nGradientBoostingRegressor(n_estimators=500, random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GradientBoostingRegressorGradientBoostingRegressor(n_estimators=500, random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train_gbcv = grad_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_gb_cv = mean_absolute_error(y_train, \n                                y_pred_train_gbcv)\n\n# Calculate R-squared\nr2_gb_cv = r2_score(y_train, \n                    y_pred_train_gbcv)\n\n\n\n\nRandom Forest\n\n\nShow Code\n# Build random forest\nfrom sklearn.ensemble import RandomForestRegressor\nrf_tree = RandomForestRegressor(n_estimators = 100,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n# Fit random forest\nrf_tree.fit(X_train_clean, \n            y_train)\n\n\nRandomForestRegressor(max_features='sqrt', random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_features='sqrt', random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train_rf = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf = mean_absolute_error(y_train, \n                             y_pred_train_rf)\n\n# Calculate R-squared\nr2_rf = r2_score(y_train, \n                 y_pred_train_rf)\n\nprint(f\"R2-score: {r2_rf:.4f} and MAE score: {mae_rf:.4f}\")\n\n\nR2-score: 0.9577 and MAE score: 100.8408\n\n\n\n\nShow Code\n#gridsearch\nparams = {\"n_estimators\": [100, 200, 300, 500 ],\n          \"max_features\": [\"sqrt\", \"log2\"]}\n\n# Buat gridsearch\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                random_state = 123)\n\nrf_tree_cv = GridSearchCV(estimator = rf_tree,\n                          param_grid = params,\n                          cv = 5,\n                          scoring = \"neg_mean_absolute_error\")\n# Fit grid search cv\nrf_tree_cv.fit(X_train_clean, \n               y_train)\n\n# Best params\nrf_tree_cv.best_params_\n\n\n{'max_features': 'sqrt', 'n_estimators': 500}\n\n\n\n\nShow Code\n# Refit the Random Forest\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                max_features = 'sqrt',\n                                n_estimators = 500,\n                                random_state = 123)\n\n#refit\nrf_tree.fit(X_train_clean, \n            y_train)\n\n\nRandomForestRegressor(max_features='sqrt', n_estimators=500, random_state=123)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.RandomForestRegressorRandomForestRegressor(max_features='sqrt', n_estimators=500, random_state=123)\n\n\n\n\nShow Code\n# Predict\ny_pred_train_rfcv = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf_cv = mean_absolute_error(y_train, \n                                y_pred_train_rfcv)\n\n# # Calculate R-squared\nr2_rf_cv = r2_score(y_train, \n                    y_pred_train_rfcv)"
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#results",
    "href": "posts/006-easy-report-machine-learning/index.html#results",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Results",
    "text": "Results\nFigure 6 shows the result of all model tested on train dataset.\n\n\nShow Code\nsns.scatterplot(x=y_train, \n                y=y_pred_train_mean)\nplt.show()\nsns.scatterplot(x=y_train, \n                y=y_pred_train_linreg)\nplt.show()\nsns.scatterplot(x=y_train, \n                y=y_pred_train_gb)\nplt.show()\nsns.scatterplot(x=y_train, \n                y=y_pred_train_gbcv)\nplt.show()\nsns.scatterplot(x=y_train, \n                y=y_pred_train_rf)\nplt.show()\nsns.scatterplot(x=y_train, \n                y=y_pred_train_rfcv)\nplt.show()\n\n\n\n\n\n\nFigure 1: Mean\n\n\n\n\n\n\n\nFigure 2: Linear Regression\n\n\n\n\n\n\n\n\n\nFigure 3: Gradient Boosting\n\n\n\n\n\n\n\nFigure 4: Gradient Boosting with CV\n\n\n\n\n\n\n\n\n\nFigure 5: Random Forest\n\n\n\n\n\n\n\nFigure 6: Random Forest with CV\n\n\n\n\n\n\n\n\nBest Model from Train Dataset\n\n\nShow Code\nmae_score = [mae_baseline, mae_linreg, \n             mae_gb, mae_gb_cv,\n             mae_rf, mae_rf_cv]\n\nr2_score = [r2_baseline, r2_linreg, \n            r2_gb, r2_gb_cv, \n            r2_rf, r2_rf_cv]\n\nindexes = [\"baseline\", \"linear regression\", \n           \"gradient boosting\", \"gradient boosting with CV\",\n           \"random forest\",  \"random forest with CV\"]\n\nsummary_df = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\n#plotting\nfig, axs = plt.subplots(ncols=2, \n                        nrows=1, \n                        figsize=(6,4), \n                        sharey=True)\n\nsummary_df.sort_values(by='R2-Score', \n                       ascending=False).plot(kind='barh', \n                                             y='R2-Score', \n                                             ax=axs[0])\n\nsummary_df.sort_values(by='R2-Score', \n                       ascending=False).plot(kind='barh', \n                                             y='MAE Train', \n                                             ax=axs[1])\nplt.show()\n\n\n\n\nFigure 7: Comparison Chart of R2 and MAE for all Models\n\n\n\n\n\n\n\nShow Code\nsummary_df.applymap(lambda x: round(x, 2))\n\n\n\n\n\n\n  \n    \n      \n      MAE Train\n      R2-Score\n    \n  \n  \n    \n      baseline\n      562.37\n      0.00\n    \n    \n      linear regression\n      319.22\n      0.65\n    \n    \n      gradient boosting\n      281.68\n      0.72\n    \n    \n      gradient boosting with CV\n      228.02\n      0.82\n    \n    \n      random forest\n      100.84\n      0.96\n    \n    \n      random forest with CV\n      99.80\n      0.96\n    \n  \n\n\n\n\nAfter several model tested on the train dataset, Random Forest with Hyperparameter tuning has the best R2-score and MAE value as shown in the Figure 7. The best model plotted below as reference:\n\n\nBest Model - RF with CV\n\n\n\n\n\nApplied Model on Test Dataset\n\n\nShow Code\n# libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n#setting up\nrf_tree = RandomForestRegressor(n_estimators = 500,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n#read cleaned test data\nX_test_clean = pd.read_csv(\"./X_test_clean.csv\")\n\n#fit model train\nrf_tree.fit(X_train_clean, \n            y_train)\n\n# Predict model test\ny_pred_test = rf_tree.predict(X_test_clean)\n\n# Calculate mean absolute error\nmae_rf_cv_test = mean_absolute_error(y_test, \n                                     y_pred_test)\n\n# # Calculate R-squared\nr2_rf_cv_test = r2_score(y_test, \n                         y_pred_test)\n\nprint(f\"R2-score: {r2_rf_cv_test:.3f} and MAE score: +/-{mae_rf_cv_test:.2f} RM\")\n\nsns.scatterplot(x=y_test, y=y_pred_test )\nplt.plot([0, 5500], [0,5500], \"--r\")\nplt.xlim(0, 5500)\nplt.xlabel(\"Actual Monthly Rent\")\nplt.ylim(0,5500)\nplt.ylabel(\"Predicted Monthly Rent\")\nplt.suptitle(\"Random Forest - Test Dataset\")\nplt.show()\n\n\nR2-score: 0.803 and MAE score: +/-214.08 RM\n\n\n\n\n\n\n\nShow Code\nmae_score = [mae_rf_cv,\n             mae_rf_cv_test]\n\nr2_score = [r2_rf_cv, \n            r2_rf_cv_test]\n\nindexes = [\"train\", \"test\"]\n\nsummary_df_train_test = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\nsummary_df_train_test.applymap(lambda x: round(x, 2)) \n\n\n\n\n\n\n  \n    \n      \n      MAE Train\n      R2-Score\n    \n  \n  \n    \n      train\n      99.80\n      0.96\n    \n    \n      test\n      214.08\n      0.80\n    \n  \n\n\n\n\n\n\nFeature Importance\n\n\nShow Code\n# calculate the feature importances\nimportances = rf_tree.feature_importances_\n\n# rescale the importances back to the original scale of the features\nimportances = importances * X_train_clean.std()\n\n# sort the feature importances in descending order\nsorted_index = importances.argsort()[::-1]\n\n# print the feature importances\ndict_feature_importance = {}\nfor i in sorted_index:\n    # print(\"{}: {}\".format(X_train_clean.columns[i], importances[i]))\n    dict_feature_importance.update({X_train_clean.columns[i]: importances[i]})\n    \n# Create a DataFrame from the dictionary\ndf = pd.DataFrame.from_dict(dict_feature_importance, orient='index', columns=['values'])\n\n# Reset the index to become a column\ndf = df.reset_index()\n\n# Rename the columns\ndf.columns = ['feature', 'importance_value']\n\n#plot\nfig, axs = plt.subplots(figsize=(6,4))\n(df\n .sort_values(by='importance_value', ascending=False)\n .head(10)\n .sort_index(ascending=False)\n .plot(kind='barh', x='feature', ax=axs)\n);"
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#conclusions",
    "href": "posts/006-easy-report-machine-learning/index.html#conclusions",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Conclusions",
    "text": "Conclusions\n\nResult indicates that the best model for prediction is Random Forest with hyperparameter tuning, scoring 95% on R2-score, and a shy 100 RM on MAE. This proves to be a good model since the test dataset gives a scoring of 80% on R2, and 240 RM on MAE.\nThere are some factors that author believed to be affecting the result/ performance of the model:\n\nDropping missing value reduces the performance! Initial model uses half of the data (4-5k rows) and gives poorer performance on R2 and MAE. Imputation and keeping the number of rows close to the original dataset (9k rows) proves to be improving the model. Especially on test dataset.\nFeature selection importance can be seen on the last table, but initially the selection was based on paper and intuition of the author (author lives and work in KL, Malaysia for 5 years). Feature such as completion_year and nearby_railways are important in improving the model.\nLast but not least is the outlier identification. The best practice for me is using jointplot to see not only the distribution of the data in 2-dimension, but also in the third dimension (the density) of the data.\n\nSome insights after feature importance are the size plays a big role in determining the unit price, following size, the furniture availability apparently makes a big impact on the price. This gives an insight to owner of a unit to equip their unit with furniture to fully_furnished should they want to increase their unit market value.\nSome of the feature that were believed to be quite important even before doing the modeling is size_sqft, furnished and location. All three is available within the 10-most features affecting the modeling. As a context, location in KLCC is like Pondok Indah in South Jakarta and location in Kiara is like BSD in South Tangerang, therefore it makes senses to see those locations increasing the price of a rent."
  },
  {
    "objectID": "posts/006-easy-report-machine-learning/index.html#future-works",
    "href": "posts/006-easy-report-machine-learning/index.html#future-works",
    "title": "Easy Report: Malaysia Property Pricing",
    "section": "Future works",
    "text": "Future works\n\nOne of the feature that author thinks is significant but not appearing on the 10-best important feature is nearby_railways. This column is showing if a certain property has a close proximity to a railways (KTM/LRT). The issue is, half of the data is missing, hence the imputation. Author believes, the proximity to nearby railways line can be approximated using Manhanttan distance of railways line to each property unit."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geoscientist Codes",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\n\n\n\n\n\nPersonal Website using Jupyter Notebook and Quarto\n\n\n6 min\n\n\n\ntutorial\n\n\nquarto\n\n\npython\n\n\nvscode\n\n\n\nA Long But Worth It, tutorial on how to make a personal website out of a jupyter notebook, github account, and quarto.\n\n\n\nMar 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEasy Report: Malaysia Property Pricing\n\n\n24 min\n\n\n\nproject\n\n\ndata-science\n\n\npython\n\n\nwebscraping\n\n\nreport\n\n\n\nTLDR version of web-scraping property ads listing in Kuala Lumpur, Malaysia, and built a machine learning model to predict the rent price.\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMalaysia Property Pricing - Webscraping & Machine Learning Model\n\n\n26 min\n\n\n\nproject\n\n\ndata-science\n\n\npython\n\n\nwebscraping\n\n\n\nFull details on creating property dataset using webscraping, and building machine learning model to predict the rent price\n\n\n\nFeb 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWebscraping National Exams of Indonesia\n\n\n5 min\n\n\n\nproject\n\n\nwebscraping\n\n\ndata-science\n\n\npython\n\n\n\nNational Exams 2015-2019. Is Education still decentralized in Java island and its surroundings?\n\n\n\nJan 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedical Insurance Cost [Part-1]\n\n\n13 min\n\n\n\nproject\n\n\ndata-science\n\n\npython\n\n\n\nUnderstanding Insurance Medical dataset to answer if smoking, sex, body mass index (BMI) affects the medical charges.\n\n\n\nOct 27, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating My Personal Blog to Quarto\n\n\n4 min\n\n\n\nblog\n\n\nquarto\n\n\n\nSome pros and cons that I learnt when I moved my personal website to Quarto from Jekyll-based theme. Difficulties along the way, and what I hoped to be the future of Quarto.\n\n\n\nOct 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy First Interview in 500 Fortune Company\n\n\n2 min\n\n\n\ncareer\n\n\n\nDuring the interview, the user asked me a question that was attempted to test my honesty. I said I don’t know, so I got the job.\n\n\n\nAug 29, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "2022\n\nCritical Porosity in Understanding Acoustic Porosity Anomalies. A Case Study in Complex Carbonate Reservoir in Indonesia. Wijaya, Aditya Arie, Kunaifi, Sunawar, Laya, Krishna Pratama, Luqman, Ramadhan, Dimmas. Proceedings, Indonesia Petroleum Association. 46th Annual Convention & Exhibition Sep 2022. Paper\n\n\n\n2021\n\nThru-Tubing Integrity Assurance in CO2-Injection Well Using Electromagnetic Corrosion Logging Tool: A Case Study in Far East Test Field, Japan. Aditya Arie Wijaya and Akira Endo and Sarvagya Parashar. SPWLA Japan JFES 26th, Virtual Event, 2021. https://doi.org/10.30632/SPWLA-2021-0043\nIntegrated Evaluation of Laminated Sand-Shale Gas-Bearing Reservoir Using Tensor Model: A Case Study Combining Data from Triaxial Resistivity, Image, Sonic, and Reservoir Testing in B-Field, Malaysia. Aditya Arie Wijaya, Ivan Zhia Ming Wu, Sarvagya Parashar, Mohammad Iffwad, Amirul Afiq B Yaakob, William Amelio Tolioe, Adib Akmal Che Sidid and Nadhirah Bt. Ahmad. SPWLA 62nd Annual Logging Symposium, Virtual Event. https://doi.org/10.30632/SPWLA-2021-0043, Paper.\nFull Well Corrosion Insight – Case Studies in the Added Value of Electromagnetic Thickness Measurements During Well Interventions. Andrew Imrie, Maciej Kozlowski, Omar Torky, and Aditya Arie Wijaya. SPE/ICoTA Well Intervention Conference and Exhibition, Virtual. 2021. https://doi.org/10.2118/204431-MS, Paper.\n\n\n\n2020\n\nMulti-Detector Pulsed Neutron Tool Application in Low Porosity Reservoir — A Case Study in Mutiara Field, Indonesia. Aditya Arie Wijaya, Rama Aulianagara, Weijun Guo, Fetty Maria Naibaho, Fransiscus Xaverius Asriwan and Usman Amirudin. SPWLA 61st Annual Logging Symposium, Virtual Online Webinar and Featured in the SPWLA Journal Dec 2020. https://doi.org/10.30632/SPWLA-5082, Paper, SPWLA Journal Article.\n\n\n\n2019\n\nPractical Application of Tensor Model in Laminated Sand Shale Analysis. Aditya Arie Wijaya. Abu Dhabi International Petroleum Exhibition & Conference, Abu Dhabi, UAE, 2019. https://doi.org/10.2118/197208-MS, Paper.\nBehind Casing Gas Identification Using Ultrasonic Wireline Logs: An Overview of Multiwell Field Plug and Abandonment Study, Offshore Malaysia. Andrew Imrie, Mohd Hazwan Zainal Abidin, Aditya Arie Wijaya, Ping Ting, Ulimaz Dhania, Ekky Nugroho Mahardika, Li Juan Saw, Siti Najmi Farhan Bt Zulkipli. SPE Symposium: Decommissioning and Abandonment, Malaysia, 2019. https://doi.org/10.2118/199180-MS, Paper.\nWhere’s the Water Coming from? — A Combined Formation Saturation, Production Logging, Water Flow, and Leak Detection Diagnosis Deployed on Coiled Tubing. Andrew Imrie, Muhammad Bagir, Glen Ricky Himawan, Mahadevan S Iyer and Aditya Arie Wijaya. SPE/IATMI Asia Pacific Oil & Gas Conference and Exhibition, Bali, Indonesia, 2019. https://doi.org/10.2118/196544-MS, Paper.\n\n\n\n2018\n\nSuccess Novel of Integrating Pulsed Neutron and Comprehensive Production Data Analysis to Optimize Well Production, Indonesia. Aditya Arie Wijaya and Muhammad Bagir. SPWLA Asia Pacific Symposium Bogor, Indonesia, 2018. SPWLA-2018-1841, Paper."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Aditya Arie Wijaya",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n    \n     Twitter\nHi there 👋 I am Arie!\nI am currently working as a Geoscientist in the Multi-national Service company in the field of Energy, i.e. subsurface analytics, energy exploration, and geoscience analytics, in Kuala Lumpur, Malaysia.\nI have developed a web application to load well-log data in LAS file format and do basic petrophysical analysis at plotpetrophysics.streamlit.app, and particularly interested in finding an intersection between geoscience/ subsurface with data analytics/ science.\nIn my spare time, I also enjoy sitting in silence, reading a book, or just let my mind wandering around the universe of thoughts.\nHave a look at my data science resume."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Aditya Arie Wijaya",
    "section": "Education",
    "text": "Education\n\nB.Eng. in Geological Engineering (Specialised in Energy, and Reservoir Analysis), 2012\nUniversity Gadjah Mada, Indonesia"
  },
  {
    "objectID": "about.html#interests",
    "href": "about.html#interests",
    "title": "Aditya Arie Wijaya",
    "section": "Interests",
    "text": "Interests\n\nCooking\nRudimental Drums\nData Visualisation\nHiking\nFishing"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "© Copyright Aditya Arie Wijaya\nThis is my personal website. Nothing here is endorsed by my employer or any organizations of which I am become a part of. Every content in this website can be used without restriction as long as you provide a citation back to the original material. The website is provided under a Creative Commons (CC-BY) 4.0 license and source code of the site is provided under the MIT license and may be reused without restriction."
  }
]