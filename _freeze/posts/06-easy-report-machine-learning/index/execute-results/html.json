{
  "hash": "cd3b03f38c9555584cbd7272f8ca8e2d",
  "result": {
    "markdown": "---\ntitle: ' Easy Report: Malaysia Property Pricing'\ndescription: |\n  Web-scraping property ads listing in Kuala Lumpur, Malaysia, and built a machine learning model to predict the rent price.\ntitle-block-banner: true\ndate: '2023-02-10'\ncategories:\n  - project\n  - data-science\n  - python\n  - webscraping\n  - report\ncode-fold: show\ndraft: false\ncitation-location: document\nbibliography: references.bib\n---\n\n## Background\n\n![Photo by <a href=\"https://unsplash.com/@esmonde?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Esmonde Yong</a> on <a href=\"https://unsplash.com/photos/-9B08uduMyY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>](kuala_lumpur_twin_owers.jpg)\n\nThis is a machine learning project to predict unit/property monthly rent price in Kuala Lumpur region, Malaysia. The project uses a dataset from an online ads listing for property [mudah.my](https://www.mudah.my/). This project outlines the process of web-scraping/ data gathering, data cleaning-wrangling, and machine learning modeling.\n\nThis project aims to answers question about how much a unit monthly rent would be if given information such as location, number of bedrooms, parking, furnished, etc? This would help potential tenant and also the owner to get the best price of their rental unit, comparable to the market value.\n\nSome previous work about house pricing was listed below, however most of them are targeting a dataset of house pricing or an Airbnb pricing. There are difference such as in Airbnb, the booking rarely took more than 2 weeks, let alone a year. Therefore the pricing may be different. Additionally, in Airbnb, there is text feature coming from the review given by the tenant and the owner.The better the review, the higher the rent prices -- which was not available in this current project dataset.\n\n## Who is this for?\n\n::: callout-note\nThis project was the TLDR-version of the [complete article](https://ariewjy.github.io/posts/05-webscraping-machinelearning-house-pricing/ \"EDA and more details\") where author explained in much more details about the process of webscraping-data cleaning-data wrangling-feature engineering, etc. This was made also as a mandatory terms for me to pass the Pacmann bootcamp intro to machine learning class. Video of me explaining the whole project is also available under this l[link](https://youtu.be/T8D2afmxuOY).\n:::\n\n## Related work\n\nPrevious work by @madhuri2019, @xu2022, and @zhao2022 highlight the importance feature selection, and the choice of machine learning model. Based on the previous works, the most consistently performed machine learning model are Random Forest and Gradient boosting, and the MAE and R2 score usually used in evaluating the performance of the model. Although the above work are all not about apartment rent pricing, similar method can be applied to this project.\n\n## Dataset & features\n\nThe dataset is using the scraped dataset from ads listing website, particularly property-to-rent surrounding Kuala Lumpur, Malaysia.\n\n::: callout-important\n## Why Webscraping?\n\nAs 80% of data science process is about data engineering, from collection (gathering) to wrangling/ cleaning, author fells the need to brush up the skill, from available online data, relevant to the author (location: Kuala Lumpur), using webscraping tool such as BeaufifulSoup.\n\nDetail of the web-scraping process on this project can be found in this [article](https://ariewjy.github.io/posts/05-webscraping-machinelearning-house-pricing/ \"EDA and more details\").\n:::\n\nThere are over 10k ads listed at the time of this project as can be seen below:\n\n<img src=\"mudah_my.png\" width=\"100%\"/>\n\n### Data Description\n\nThere are 13 features with one unique ids (`ads_id`) and one target feature (`monthly_rent`)\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n#importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option('max_colwidth', 200)\nimport re\n\n#reload the data\ndf = pd.read_csv(\"./mudah-apartment-clean.csv\")\ndf.head(3).T\n```\n\n::: {.cell-output .cell-output-display execution_count=157}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ads_id</th>\n      <td>100323185</td>\n      <td>100203973</td>\n      <td>100323128</td>\n    </tr>\n    <tr>\n      <th>prop_name</th>\n      <td>The Hipster @ Taman Desa</td>\n      <td>Segar Courts</td>\n      <td>Pangsapuri Teratak Muhibbah 2</td>\n    </tr>\n    <tr>\n      <th>completion_year</th>\n      <td>2022.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>monthly_rent</th>\n      <td>RM 4 200 per month</td>\n      <td>RM 2 300 per month</td>\n      <td>RM 1 000 per month</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>Kuala Lumpur - Taman Desa</td>\n      <td>Kuala Lumpur - Cheras</td>\n      <td>Kuala Lumpur - Taman Desa</td>\n    </tr>\n    <tr>\n      <th>property_type</th>\n      <td>Condominium</td>\n      <td>Condominium</td>\n      <td>Apartment</td>\n    </tr>\n    <tr>\n      <th>rooms</th>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>parking</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>bathroom</th>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>size</th>\n      <td>1842 sq.ft.</td>\n      <td>1170 sq.ft.</td>\n      <td>650 sq.ft.</td>\n    </tr>\n    <tr>\n      <th>furnished</th>\n      <td>Fully Furnished</td>\n      <td>Partially Furnished</td>\n      <td>Fully Furnished</td>\n    </tr>\n    <tr>\n      <th>facilities</th>\n      <td>Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track</td>\n      <td>Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna</td>\n      <td>Minimart, Jogging Track, Lift, Swimming Pool</td>\n    </tr>\n    <tr>\n      <th>additional_facilities</th>\n      <td>Air-Cond, Cooking Allowed, Washing Machine</td>\n      <td>Air-Cond, Cooking Allowed, Near KTM/LRT</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n-   `ads_id`: the listing ids (unique)\n-   `prop_name`: name of the building/ property\n-   `completion_year`: completion/ established year of the property\n-   `monthly_rent`: monthly rent in ringgit malaysia (RM)\n-   `location`: property location in Kuala Lumpur region\n-   `property_type`:property type such as apartment, condominium, flat, duplex, studio, etc\n-   `rooms`: number of rooms in the unit\n-   `parking`: number of parking space for the unit\n-   `bathroom`: number of bathrooms in the unit\n-   `size`: total area of the unit in square feet\n-   `furnished`: furnishing status of the unit (fully, partial, non-furnished)\n-   `facilities`: main facilities available\n-   `additional_facilities`: additional facilities (proximity to attraction area, mall, school, shopping, railways, etc)\n\n### Data Cleaning\n\nThe cleaning process mainly related to extracting the value out of column. E.g. extracting monthly rent of 1400 from a string of \"1400 RM\", etc.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n#removing RM from monthly rent\ndf['monthly_rent'] = df['monthly_rent'].apply(lambda x: int(re.search(r'RM (.*?) per', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'monthly_rent': 'monthly_rent_rm'})\n\n#dropping sq.ft from size\ndf['size'] = df['size'].apply(lambda x: int(re.search(r'(.*?) sq', x).group(1).replace(' ', '')))\ndf = df.rename(columns={'size': 'size_sqft'})\n\n#dropping kuala lumpur from the location\ndf['location'] = df['location'].apply(lambda x: re.findall(\"\\w+$\", x)[0])\ndf.head(4).T\n```\n\n::: {.cell-output .cell-output-display execution_count=158}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ads_id</th>\n      <td>100323185</td>\n      <td>100203973</td>\n      <td>100323128</td>\n      <td>100191767</td>\n    </tr>\n    <tr>\n      <th>prop_name</th>\n      <td>The Hipster @ Taman Desa</td>\n      <td>Segar Courts</td>\n      <td>Pangsapuri Teratak Muhibbah 2</td>\n      <td>Sentul Point Suite Apartment</td>\n    </tr>\n    <tr>\n      <th>completion_year</th>\n      <td>2022.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020.0</td>\n    </tr>\n    <tr>\n      <th>monthly_rent_rm</th>\n      <td>4200</td>\n      <td>2300</td>\n      <td>1000</td>\n      <td>1700</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>Desa</td>\n      <td>Cheras</td>\n      <td>Desa</td>\n      <td>Sentul</td>\n    </tr>\n    <tr>\n      <th>property_type</th>\n      <td>Condominium</td>\n      <td>Condominium</td>\n      <td>Apartment</td>\n      <td>Apartment</td>\n    </tr>\n    <tr>\n      <th>rooms</th>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>parking</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>bathroom</th>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>size_sqft</th>\n      <td>1842</td>\n      <td>1170</td>\n      <td>650</td>\n      <td>743</td>\n    </tr>\n    <tr>\n      <th>furnished</th>\n      <td>Fully Furnished</td>\n      <td>Partially Furnished</td>\n      <td>Fully Furnished</td>\n      <td>Partially Furnished</td>\n    </tr>\n    <tr>\n      <th>facilities</th>\n      <td>Minimart, Gymnasium, Security, Playground, Swimming Pool, Parking, Lift, Barbeque area, Multipurpose hall, Jogging Track</td>\n      <td>Playground, Parking, Barbeque area, Security, Jogging Track, Swimming Pool, Gymnasium, Lift, Sauna</td>\n      <td>Minimart, Jogging Track, Lift, Swimming Pool</td>\n      <td>Parking, Playground, Swimming Pool, Squash Court, Security, Minimart, Gymnasium, Lift</td>\n    </tr>\n    <tr>\n      <th>additional_facilities</th>\n      <td>Air-Cond, Cooking Allowed, Washing Machine</td>\n      <td>Air-Cond, Cooking Allowed, Near KTM/LRT</td>\n      <td>NaN</td>\n      <td>Cooking Allowed, Near KTM/LRT, Washing Machine</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Methods\n\nFollowing the works from others, author will be focusing on using Random Forest and Gradient Boosting for the two main machine learning model to try to compare to baseline (average, and linear regression).\n\n-   Baseline using average means that the prediction will be using average value of the train target value. This yield a zero R2-score and the highest MAE value which will not be used as comparison in the following discussion.\n\nThe author will mainly talking about baseline using linear regression. Linear regression is one of the machine learning model, where the model objective is to minimize the total error (distance) of each predicted value against the actual value.\n\nThe comparable model will be using Random Forest and Gradient Boosting.\n\nA gradient boosting uses iterative process to assign weights to different sample, until the model predicts the target correctly. Meanwhile, Random Forest use similar concept, but the sampling and feature selection are random, therefore reduces both bias and variance in the model.\n\n## Experiments\n\nThe experiments mostly related to the data preparation before getting into modeling. The most author spent time with is feature selection and outlier removal. One of the insight when doing feature selection is the proximity to nearby railways (KTM/LRT) is likely to affect the increase of rent price. However, the finding is that the listing is inconsistent, the same property may listed to be 'near KTM/LRT', but the other rows were not.\n\n### Extracting Near KTM/LRT\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n#extracting near KTM/LRT from the additional facilities\ndef extract_near_ktm_lrt(text):\n    pattern = re.compile(r'\\bNear KTM/LRT\\b')\n    try:\n        match = pattern.search(text)\n        if match:\n            return 'yes'\n        return 'no'\n    except TypeError:\n        return text\n```\n:::\n\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ndf['nearby_railways'] = df.additional_facilities.apply(lambda x: extract_near_ktm_lrt(x))\n\nfig, axs = plt.subplots(figsize=(6,4))\nsns.boxplot(data=df, x='monthly_rent_rm', y='nearby_railways', ax=axs)\nplt.xlim(0,4000);\n\nnear_ktmlrt = df.query(\" nearby_railways == 'yes' \")\nnot_near_ktmlrt = df.query(\" nearby_railways == 'no' \")\n\nprint(f\"\"\" \nMedian:\nNearby KTM/LRT: {near_ktmlrt.monthly_rent_rm.median():.0f}RM\nNot nearby KTM/LRT: {not_near_ktmlrt.monthly_rent_rm.median():.0f}RM\n      \"\"\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n \nMedian:\nNearby KTM/LRT: 1650RM\nNot nearby KTM/LRT: 1600RM\n      \n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-2.png){width=533 height=356}\n:::\n:::\n\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf[df['prop_name'] == 'Majestic Maxim'][['nearby_railways']].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=161}\n```\nnearby_railways\nyes                166\nno                  24\ndtype: int64\n```\n:::\n:::\n\n\nAs seen above, nearby KTM/LRT is slightly increases the median monthly rent by 50RM, however near KTM/LRT is not appearing in all row even though the unit is the same building.\n\n### Drop Unnecessary Missing Values\n\nSome features such as `ads_id`, `prop_name`, `facilities` and `additional_facilities` would no longer needed after the previous process.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndf = df.drop(columns=[\n    'ads_id', \n    'prop_name', \n    'facilities', \n    'additional_facilities',\n    # 'nearby_railways',\n    # 'completion_year'\n])\ndf.head(3).T\n```\n\n::: {.cell-output .cell-output-display execution_count=162}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>completion_year</th>\n      <td>2022.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>monthly_rent_rm</th>\n      <td>4200</td>\n      <td>2300</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>Desa</td>\n      <td>Cheras</td>\n      <td>Desa</td>\n    </tr>\n    <tr>\n      <th>property_type</th>\n      <td>Condominium</td>\n      <td>Condominium</td>\n      <td>Apartment</td>\n    </tr>\n    <tr>\n      <th>rooms</th>\n      <td>5</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>parking</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>bathroom</th>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>size_sqft</th>\n      <td>1842</td>\n      <td>1170</td>\n      <td>650</td>\n    </tr>\n    <tr>\n      <th>furnished</th>\n      <td>Fully Furnished</td>\n      <td>Partially Furnished</td>\n      <td>Fully Furnished</td>\n    </tr>\n    <tr>\n      <th>nearby_railways</th>\n      <td>no</td>\n      <td>yes</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n#converting rooms from object to int64 for plotting\ndf['rooms'] = pd.to_numeric(df['rooms'], downcast='integer', errors='coerce')\ndf.info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 9991 entries, 0 to 9990\nData columns (total 10 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   completion_year  5618 non-null   float64\n 1   monthly_rent_rm  9991 non-null   int64  \n 2   location         9991 non-null   object \n 3   property_type    9991 non-null   object \n 4   rooms            9987 non-null   float64\n 5   parking          7361 non-null   float64\n 6   bathroom         9989 non-null   float64\n 7   size_sqft        9991 non-null   int64  \n 8   furnished        9990 non-null   object \n 9   nearby_railways  7160 non-null   object \ndtypes: float64(4), int64(2), object(4)\nmemory usage: 780.7+ KB\n```\n:::\n:::\n\n\n### Outlier Removal\n\nRemoving the outlier is extremely important, as some of these observation e.g. monthly rent, have astronomical rent value, far exceeding the median. After multiple iteration, below is the most-ideal limit for `size_sqft` and `monthly_rent_rm`.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nf, axs = plt.subplots(1,1, figsize=(6,4))\ndf[['size_sqft', 'monthly_rent_rm']].plot(kind='scatter', x='size_sqft', y='monthly_rent_rm', ax=axs);\nplt.ylim(100,5500) #batas harga rent\nplt.xlim(50,3000)  #batas size\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.png){width=544 height=356}\n:::\n:::\n\n\n#### Monthly Rent\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfig, axs = plt.subplots(1,2, figsize=(6,4))\naxs[0].boxplot(data=df, x='monthly_rent_rm')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=df, x='monthly_rent_rm')\naxs[1].set_ylim(100,5500)\naxs[1].set_title('100-5,500 RM')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=566 height=373}\n:::\n:::\n\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n#removing all rows with monthly rent above 5500 RM and below 100RM\ndfx = df.query(\" monthly_rent_rm > 100 & monthly_rent_rm < 5500 \")\n```\n:::\n\n\n#### Size\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfig, axs = plt.subplots(1,2, figsize=(5,4))\naxs[0].boxplot(data=dfx, x='size_sqft')\naxs[0].set_ylim(0,20000)\naxs[0].set_title('all data')\n\naxs[1].boxplot(data=dfx, x='size_sqft')\naxs[1].set_ylim(0,2000)\naxs[1].set_title('50-3,000 square feet')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=470 height=373}\n:::\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n#removing outliers below 500, and higher than 3000 sqft and below 50 sqft\ndfx = dfx.query(\" size_sqft > 50 & size_sqft < 3000 \")\n```\n:::\n\n\n### Data Preparation\n\n#### Preprocessing Original Data for Categorical Dtypes\n\nOne must paying attention to the number of categorical observation in the original data, with respect to the sampling train-test value. If, the test_size = 0.3, that means any categorical observation with a total of 3 and less, would not be distributed evenly among train and test data. Below is the process of removing some observation in which appearing only in one of the dataset (train/ test).\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ndfx_new = dfx[\n    (dfx.location != 'Jinjang') \n    & (dfx.location != 'Serdang') & \n    (dfx.location != 'Sentral') & \n    (dfx.location != 'Others') & \n    (dfx.location != 'Tunku') & \n    (dfx.location != 'Penchala') & \n    (dfx.location != 'Lin') &\n    # (dfx.property_type != 'Others') &\n    (dfx.property_type != 'Condo / Services residence / Penthouse / Townhouse') &\n    (dfx.property_type != 'Townhouse Condo')\n]\n```\n:::\n\n\n#### Input-Output\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\ndef extractInputOutput(data,\n                       output_column_name):\n    \"\"\"\n    Fungsi untuk memisahkan data input dan output\n    :param data: <pandas dataframe> data seluruh sample\n    :param output_column_name: <string> nama kolom output\n    :return input_data: <pandas dataframe> data input\n    :return output_data: <pandas series> data output\n    \"\"\"\n    output_data = data[output_column_name]\n    input_data = data.drop(output_column_name,\n                           axis = 1)\n    \n    return input_data, output_data\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nX, y = extractInputOutput(data=dfx_new, output_column_name='monthly_rent_rm')\n```\n:::\n\n\n#### Train-Test Split Data\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n#import libraries\nfrom sklearn.model_selection import train_test_split\n\n# Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y,\n                                                    test_size = 0.2,\n                                                    random_state = 123)\n```\n:::\n\n\n#### Training Data Imputation\n\n##### Numerical Data\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom sklearn.impute import SimpleImputer\n\ndef numericalImputation(X_train_num, strategy = 'most_frequent'):\n    \"\"\"\n    Fungsi untuk melakukan imputasi data numerik NaN\n    :param data: <pandas dataframe> sample data input\n\n    :return X_train_numerical: <pandas dataframe> data numerik\n    :return imputer_numerical: numerical imputer method\n    \"\"\"\n    #buat imputer\n    imputer_num = SimpleImputer(missing_values = np.nan, strategy = strategy)\n    \n    #fitting\n    imputer_num.fit(X_train_num)\n\n    # transform\n    imputed_data = imputer_num.transform(X_train_num)\n    X_train_num_imputed = pd.DataFrame(imputed_data)\n\n    #pastikan index dan nama kolom antara imputed dan non-imputed SAMA\n    X_train_num_imputed.columns = X_train_num.columns\n    X_train_num_imputed.index = X_train_num.index\n\n    return X_train_num_imputed, imputer_num\n```\n:::\n\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nX_train_num =  X_train.select_dtypes(exclude='object')\nX_train_num, imputer_num = numericalImputation(X_train_num, strategy='most_frequent')\n```\n:::\n\n\n##### Categorical Data\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nX_train_cat = X_train.select_dtypes(include='object')\nX_train_cat, imputer_num = numericalImputation(X_train_cat, strategy='most_frequent')\n```\n:::\n\n\n##### OHE Categorical Data\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\ndef get_dum_n_concat(df_num, df_cat):\n    df_cat_ohe = pd.get_dummies(df_cat)\n    ohe_columns = df_cat_ohe.columns\n    df_concat = pd.concat([df_num, df_cat_ohe], axis=1)\n    print(f\"Number of Cols: {df_concat.shape[1]},\\nNumber of Null Rows: {df_concat.isna().sum()}\")\n    return ohe_columns, df_concat\n```\n:::\n\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nohe_col, X_train_concat = get_dum_n_concat(X_train_num, X_train_cat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of Cols: 63,\nNumber of Null Rows: completion_year                  0\nrooms                            0\nparking                          0\nbathroom                         0\nsize_sqft                        0\n                                ..\nfurnished_Fully Furnished        0\nfurnished_Not Furnished          0\nfurnished_Partially Furnished    0\nnearby_railways_no               0\nnearby_railways_yes              0\nLength: 63, dtype: int64\n```\n:::\n:::\n\n\n##### Standarisasi\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nfrom sklearn.preprocessing import StandardScaler\n\n# Buat fungsi\ndef standardizerData(data):\n    \"\"\"\n    Fungsi untuk melakukan standarisasi data\n    :param data: <pandas dataframe> sampel data\n    :return standardized_data: <pandas dataframe> sampel data standard\n    :return standardizer: method untuk standardisasi data\n    \"\"\"\n    data_columns = data.columns  # agar nama kolom tidak hilang\n    data_index = data.index  # agar index tidak hilang\n\n    # buat (fit) standardizer\n    standardizer = StandardScaler()\n    standardizer.fit(data)\n\n    # transform data\n    standardized_data_raw = standardizer.transform(data)\n    standardized_data = pd.DataFrame(standardized_data_raw)\n    standardized_data.columns = data_columns\n    standardized_data.index = data_index\n\n    return standardized_data, standardizer\n```\n:::\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nX_train_clean, standardizer = standardizerData(data = X_train_concat)\n```\n:::\n\n\n#### Training Machine Learning\n\n##### Baseline with Mean value\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n#baseline\ny_baseline = np.ones(len(y_train)) * y_train.mean()\n\n# Predict using the train data\ny_pred_train_mean = y_baseline\n\n# Calculate R-squared\nr2_baseline = r2_score(y_train, y_pred_train_mean)\n\n#calculate MAE\nmae_baseline = mean_absolute_error(y_train, y_pred_train_mean)\n```\n:::\n\n\n##### Linear Regression\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Train the linear regression model\nlin_reg = LinearRegression().fit(X_train_clean, y_train)\n\n# Predict using the train data\ny_pred_train_linreg = lin_reg.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_linreg = mean_absolute_error(y_train, y_pred_train_linreg)\n\n# Calculate R-squared\nr2_linreg = r2_score(y_train, y_pred_train_linreg)\n```\n:::\n\n\n##### GradientBoosting\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nfrom sklearn.ensemble import GradientBoostingRegressor\n# Build random forest\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\n# Fit random forest\ngrad_tree.fit(X_train_clean, y_train)\n\n# Predict\ny_pred_train_gb = grad_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_gb = mean_absolute_error(y_train, y_pred_train_gb)\n\n# Calculate R-squared\nr2_gb = r2_score(y_train, y_pred_train_gb)\n```\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n#gridsearch\nfrom sklearn.model_selection import GridSearchCV \n\nparams = {'n_estimators': [100, 200, 300, 400, 500],\n              'learning_rate': [0.1, 0.05, 0.01]}\n\n# Buat gridsearch\ngrad_tree = GradientBoostingRegressor(random_state = 123)\n\ngrad_tree_cv = GridSearchCV(estimator = grad_tree,\n                           param_grid = params,\n                           cv = 5,\n                           scoring = \"neg_mean_absolute_error\")\n# Fit grid search cv\ngrad_tree_cv.fit(X_train_clean, y_train)\n\n# Best params\ngrad_tree_cv.best_params_\n```\n\n::: {.cell-output .cell-output-display execution_count=183}\n```\n{'learning_rate': 0.1, 'n_estimators': 500}\n```\n:::\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n# Refit the GB\ngrad_tree = GradientBoostingRegressor(n_estimators = 500,\n                                      learning_rate=0.1,\n                                      random_state = 123)\n\ngrad_tree.fit(X_train_clean, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=184}\n```{=html}\n<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(n_estimators=500, random_state=123)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n# Predict\ny_pred_train_gbcv = grad_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_gb_cv = mean_absolute_error(y_train, y_pred_train_gbcv)\n\n# Calculate R-squared\nr2_gb_cv = r2_score(y_train, y_pred_train_gbcv)\n```\n:::\n\n\n##### Random Forest\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\n# Build random forest\nfrom sklearn.ensemble import RandomForestRegressor\nrf_tree = RandomForestRegressor(n_estimators = 100,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n# Fit random forest\nrf_tree.fit(X_train_clean, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=186}\n```{=html}\n<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, random_state=123)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n# Predict\ny_pred_train_rf = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf = mean_absolute_error(y_train, y_pred_train_rf)\n\n# Calculate R-squared\nr2_rf = r2_score(y_train, y_pred_train_rf)\nprint(f\"R2-score: {r2_rf:.4f} and MAE score: {mae_rf:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR2-score: 0.9577 and MAE score: 100.8408\n```\n:::\n:::\n\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\n#gridsearch\nparams = {\"n_estimators\": [100, 200, 300, 500 ],\n          \"max_features\": [\"sqrt\", \"log2\"]}\n\n# Buat gridsearch\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                random_state = 123)\n\nrf_tree_cv = GridSearchCV(estimator = rf_tree,\n                          param_grid = params,\n                          cv = 5,\n                          scoring = \"neg_mean_absolute_error\")\n# Fit grid search cv\nrf_tree_cv.fit(X_train_clean, y_train)\n\n# Best params\nrf_tree_cv.best_params_\n```\n\n::: {.cell-output .cell-output-display execution_count=188}\n```\n{'max_features': 'sqrt', 'n_estimators': 500}\n```\n:::\n:::\n\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n# Refit the Random Forest\nrf_tree = RandomForestRegressor(criterion = \"squared_error\",\n                                max_features = 'sqrt',\n                                n_estimators = 500,\n                                random_state = 123)\n\n#refit\nrf_tree.fit(X_train_clean, y_train)\n```\n\n::: {.cell-output .cell-output-display execution_count=189}\n```{=html}\n<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=500, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_features=&#x27;sqrt&#x27;, n_estimators=500, random_state=123)</pre></div></div></div></div></div>\n```\n:::\n:::\n\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n# Predict\ny_pred_train_rfcv = rf_tree.predict(X_train_clean)\n\n# Calculate mean absolute error\nmae_rf_cv = mean_absolute_error(y_train, y_pred_train_rfcv)\n\n# # Calculate R-squared\nr2_rf_cv = r2_score(y_train, y_pred_train_rfcv)\n```\n:::\n\n\n## Results\n\n@fig-model-comparison shows the result of all model tested on train dataset.\n\n::: {.cell layout-ncol='2' execution_count=35}\n``` {.python .cell-code}\nsns.scatterplot(x=y_train, y=y_pred_train_mean)\nplt.show()\nsns.scatterplot(x=y_train, y=y_pred_train_linreg)\nplt.show()\nsns.scatterplot(x=y_train, y=y_pred_train_gb)\nplt.show()\nsns.scatterplot(x=y_train, y=y_pred_train_gbcv)\nplt.show()\nsns.scatterplot(x=y_train, y=y_pred_train_rf)\nplt.show()\nsns.scatterplot(x=y_train, y=y_pred_train_rfcv)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Mean](index_files/figure-html/fig-model-comparison-output-1.png){#fig-model-comparison width=583 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![Linear Regression](index_files/figure-html/fig-model-comparison-output-2.png){#fig-model-comparison width=583 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![Gradient Boosting](index_files/figure-html/fig-model-comparison-output-3.png){#fig-model-comparison width=583 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![Gradient Boosting with CV](index_files/figure-html/fig-model-comparison-output-4.png){#fig-model-comparison width=583 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![Random Forest](index_files/figure-html/fig-model-comparison-output-5.png){#fig-model-comparison width=583 height=429}\n:::\n\n::: {.cell-output .cell-output-display}\n![Random Forest with CV](index_files/figure-html/fig-model-comparison-output-6.png){#fig-model-comparison width=583 height=429}\n:::\n:::\n\n\n### Best Model from Train Dataset\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nmae_score = [mae_baseline, mae_linreg, mae_gb, mae_gb_cv, mae_rf, mae_rf_cv]\nr2_score = [r2_baseline, r2_linreg, r2_gb, r2_gb_cv, r2_rf, r2_rf_cv]\nindexes = [\"baseline\", \"linear regression\", \"gradient boosting\", \"gradient boosting with CV\", \"random forest\",  \"random forest with CV\"]\n\nsummary_df = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\n#plotting\nfig, axs = plt.subplots(ncols=2, nrows=1, figsize=(6,4), sharey=True)\nsummary_df.sort_values(by='R2-Score', ascending=False).plot(kind='barh', y='R2-Score', ax=axs[0])\nsummary_df.sort_values(by='R2-Score', ascending=False).plot(kind='barh', y='MAE Train', ax=axs[1])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Comparison Chart of R2 and MAE for all Models](index_files/figure-html/fig-r2-mae-output-1.png){#fig-r2-mae width=648 height=337}\n:::\n:::\n\n\nAfter several model tested on the train dataset, Random Forest with Hyperparameter tuning has the best R2-score and MAE value as shown in the @fig-r2-mae. The best model plotted below as reference:\n\n![Best Model - RF with CV](best_model.png)\n\n### Applied Model on Test Dataset\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# libraries\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n#setting up\nrf_tree = RandomForestRegressor(n_estimators = 500,\n                                criterion = \"squared_error\",\n                                max_features = \"sqrt\",\n                                random_state = 123)\n\n#read cleaned test data\nX_test_clean = pd.read_csv(\"./X_test_clean.csv\")\n\n#fit model train\nrf_tree.fit(X_train_clean, y_train)\n\n# Predict model TEST\ny_pred_test = rf_tree.predict(X_test_clean)\n\n# Calculate mean absolute error\nmae_rf_cv_test = mean_absolute_error(y_test, y_pred_test)\n\n# # Calculate R-squared\nr2_rf_cv_test = r2_score(y_test, y_pred_test)\n\nprint(f\"R2-score: {r2_rf_cv_test:.3f} and MAE score: +/-{mae_rf_cv_test:.2f} RM\")\n\nsns.scatterplot(x=y_test, y=y_pred_test )\nplt.plot([0, 5500], [0,5500], \"--r\")\nplt.xlim(0, 5500)\nplt.xlabel(\"Actual Monthly Rent\")\nplt.ylim(0,5500)\nplt.ylabel(\"Predicted Monthly Rent\")\nplt.suptitle(\"Random Forest - Test Dataset\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR2-score: 0.803 and MAE score: +/-214.08 RM\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-38-output-2.png){width=602 height=477}\n:::\n:::\n\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nmae_score = [mae_rf_cv, mae_rf_cv_test]\nr2_score = [r2_rf_cv, r2_rf_cv_test]\nindexes = [\"train\", \"test\"]\n\nsummary_df_train_test = pd.DataFrame({\n    \"MAE Train\": mae_score,\n    \"R2-Score\": r2_score,\n},index = indexes)\n\nsummary_df_train_test\n```\n\n::: {.cell-output .cell-output-display execution_count=194}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAE Train</th>\n      <th>R2-Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>99.798879</td>\n      <td>0.958519</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>214.084111</td>\n      <td>0.802556</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Conclusions\n\n1.  Result indicates that the best model for prediction is Random Forest with hyperparameter tuning, scoring 95% on R2-score, and a shy 100 RM on MAE. This proves to be a good model since the test dataset gives a scoring of 80% on R2, and 240 RM on MAE.\n\n2.  There are some factors that author believed to be affecting the result/ performance of the model:\n\n    1.  Dropping missing value reduces the performance! Initial model uses half of the data (4-5k rows) and gives poorer performance on R2 and MAE. Imputation and keeping the number of rows close to the original dataset (9k rows) proves to be improving the model. Especially on test dataset.\n    2.  Feature selection importance can be seen on the last table, but initially the selection was based on paper and intuition of the author (author lives and work in KL, Malaysia for 5 years). Feature such as `completion_year` and `nearby_railways` are important in improving the model.\n    3.  Last but not least is the outlier identification. The best practice for me is using jointplot to see not only the distribution of the data in 2-dimension, but also in the third dimension (the density) of the data.\n\n3.  Some of the feature that were believed to be quite important even before doing the modeling is `size_sqft`, `furnished` and `location`. All three is available within the 10-most features affecting the modeling. As a context, location in KLCC is like Pondok Indah in South Jakarta and location in Kiara is like BSD in South Tangerang, therefore it makes senses to see those locations increasing the price of a rent.\n\n## Discussion\n\n### Feature Importance\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\n# calculate the feature importances\nimportances = rf_tree.feature_importances_\n\n# rescale the importances back to the original scale of the features\nimportances = importances * X_train_clean.std()\n\n# sort the feature importances in descending order\nsorted_index = importances.argsort()[::-1]\n\n# print the feature importances\ndict_feature_importance = {}\nfor i in sorted_index:\n    # print(\"{}: {}\".format(X_train_clean.columns[i], importances[i]))\n    dict_feature_importance.update({X_train_clean.columns[i]: importances[i]})\n    \n# Create a DataFrame from the dictionary\ndf = pd.DataFrame.from_dict(dict_feature_importance, orient='index', columns=['values'])\n\n# Reset the index to become a column\ndf = df.reset_index()\n\n# Rename the columns\ndf.columns = ['feature', 'importance_value']\n\n#plot\nfig, axs = plt.subplots(figsize=(6,4))\n(df\n .sort_values(by='importance_value', ascending=False)\n .head(10)\n .sort_index(ascending=False)\n .plot(kind='barh', x='feature', ax=axs)\n);\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-40-output-1.png){width=685 height=337}\n:::\n:::\n\n\n## Future works\n\n1.  One of the feature that author thinks is significant but not appearing on the 10-best important feature is nearby_railways. This column is showing if a certain property has a close proximity to a railways (KTM/LRT). The issue is, half of the data is missing, hence the imputation. Author believes, the proximity to nearby railways line can be approximated using Manhanttan distance of railways line to each property unit.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}